[TOC]

# 消费者

与生产者对应的是消费者，应用程序可以通过 `KafkaConsumer` 来订阅主题，并从订阅的主题中拉取消息。

## 1. 消费者与消费者组

**消费者（Consumer）负责订阅 Kafka 中的主题（Topic），并且从订阅的主题上拉取消息**。

与其他一些消息中间件不同的是，在 Kafka 的消费理念中还有一层消费者组（ConsunmerGroup）的概念：**每个消费者都有一个对应的消费者组，当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者**。

如下图所示：

![image-20220727084457177](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220727084457177.png)

如图所示，某个主题中共有 4 个分区（Partition）：P0、P1、P2、P3。有两个消费组 A 和 B 都订阅了这个主题，消费组 A 中有 4 个消费者（C0、C1、C2 和 C3），消费组 B 中有2个消费者（C4 和 C5）。

按照 Kafka 默认的规则，最后的分配结果是消费者组 A 中的每一个消费者分配到 1 个分区，消费者组 B 中的每一个消费者分配到 2 个分区，两个消费者组之间互不影响。

**每个消费者只能消费所分配到的分区中的消息，换言之，每一个分区只能被一个消费者组中的一个消费者所消费**。

我们再来看一下消费组内的消费者个数变化时所对应的分区分配的演变。假设目前某消费组内只有一个消费者 C0，订阅了一个主题，这个主题包含 7 个分区：P0、P1、P2、P3、P4、P5、P6。也就是说，这个消费者 C0 订阅了 7 个分区，具体分配情形如下图：

![image-20220727090411848](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220727090411848.png)

此时消费组内又加入了一个新的消费者 C1，按照既定的逻辑，需要将原来消费者 C0 的部分分区分配给消费者 C1 消费，如图所示：

![image-20220727090431072](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220727090431072.png)

消费者 C0 和 C1 各自负责消费所分配到的分区，彼此之间并无逻辑上的干扰。

紧接着消费组内又加入了一个新的消费者 C2，消费者 C0、C1 和 C2 按照下图中的方式各自负责消费所分配到的分区：

![image-20220727090530626](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220727090530626.png)

消费者与消费组这种模型可以让整体的消费能力具备**横向伸缩性**，我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力。

**对于分区数固定的情况，一味地增加消费者并不会让消费能力一直得到提升**，如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有**消费者分配不到任何分区**。如下图所示：

![image-20220727090621593](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220727090621593.png)

以上分配逻辑都是基于**默认的分区分配策略**进行分析的，可以通过消费者客户端参数 `partition.assignment.strategy` 来设置消费者与订阅主题之间的分区分配策略，有关分区分配的更多细节我们之后再详细讲述。

### 1.1 消费者组对消息队列两种模式的支持

对于消息中间件而言，一般有两种消息投递模式：点对点（P2P）以及发布-订阅（Pub-Sub）模式。

* 点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。

* 发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。

  主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。

Kafka 同时支持两种模式，这得益于消费者和消费者组模型：

* 如果**所有的消费者都隶属于同一个消费组**，那么所有的消息都会被均衡地投递给每一个消费者，即**每条消息只会被一个消费者处理**，这就相当于点对点模式的应用。
* 如果**所有的消费者都隶属于不同的消费组**，那么所有的消息都会被广播给所有的消费者，即**每条消息会被所有的消费者处理**，这就相当于发布/订阅模式的应用。

## 2. 客户端开发

在了解了消费者与消费组之间的概念之后，我们就可以着手进行消费者客户端的开发了。

在 Kafka 的历史中，消费者客户端同生产者客户端一样也经历了两个大版本：第一个是于 Kafka 开源之初使用 Scala 语言编写的客户端，我们可以称之为旧消费者客户端（Old Consumer）或 Scala 消费者客户端；第二个是从 Kafka 0.9.x 版本开始推出的使用 Java 编写的客户端，我们可以称之为新消费者客户端（New Consumer）或 Java 消费者客户端 ，它弥补了旧客户端中存在的诸多设计缺陷。

本节主要介绍目前流行的新消费者（Java 语言编写的）客户端 ，而旧消费者客户端己被淘汰，故不再做相应的介绍了。

一个正常的消费逻辑需要具备以下几个步骤：

1. 配置消费者客户端参数及创建相应的消费者实例。
2. 订阅主题。
3. 拉取消息并消费。
4. 提交消费位移。
5. 关闭消费者实例。

我们继续拿第一章的例子来讲解消费者：

```java
import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;
import java.util.concurrent.atomic.AtomicBoolean;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;

public class ConsumerDemo {

    public static final String BROKER_LIST = "106.55.250.68:9092";

    public static final String TOPIC = "test-topic";

    public static final String GROUP_ID = "testGroup";

    public static final AtomicBoolean isRunning = new AtomicBoolean(true);

    public static Properties initConfiguration() {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
        props.put(ConsumerConfig.CLIENT_ID_CONFIG, "consumer.client.id.demo");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        return props;
    }

    public static void main(String[] args) {
        Properties props = initConfiguration();

        try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);) {
            consumer.subscribe(Arrays.asList(TOPIC));

            while (isRunning.get()) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println("topic = " + record.topic() + ", partition = " + record.partition()
                            + ", offset = " + record.offset());
                    System.out.println("key = " + record.key() + ", value = " + record.value());
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

### 2.1 必要的参数配置与构建消费者实例

在创建真正的消费者实例之前需要做相应的参数配置，比如示例代码中的设置消费者所属的消费组的名称、连接地址等。

在 Kafka 消费者客户端 `KafkaConsumer` 中有 4 个参数是必填的：

* `bootstrap.servers`：该参数的释义和生产者客户端 `KafkaProducer` 中的相同，用来指定连接 Kafka 集群所需的 broker 地址清单，具体内容形式为 `hostl:portl,host2:post`，可以设置一个或多个地址，中间用英文逗号隔开。

  注意，这里并非需要设置集群中全部的 broker 地址，消费者会从现有的配置中查找到全部的 Kafka 集群成员。不过**建议至少要设置两个以上的 broker 地址信息**，以保证当其中任意一个宕机时，消费者仍然可以连接到 Kafka 集群上。

* `group.id`：消费者隶属的消费组的名称，默认是空的。如果设置为空，则会报出异常。

  一般而言，这个参数需要设置成具有一定的业务意义的名称。

* `key.deserializer` 和 `value.deserializer`：与生产者客户端 `KafkaProducer` 中的 `key.serializer` 和 `value.serializer` 参数对应。消费者从 broker 端获取的消息格式都是字节数组类型，所以**需要执行相应的反序列化操作才能还原成原有的对象格式**。这两个参数分别用来指定消息中 key 和 value 所需反序列化操作的反序列化器。

  注意这里必须填写反序列化器类的全限定名。

这里还配置了一个 `client.id` 指定 `KafkaConsumer` 对应的客户端 id，可以不设置，Kafka 会自动生成，形式为 "consumer-1"、"consumer-2" 这样的字符串。

因为这些配置太多了，而且容易写错，Kafka 在 `ConsumerConfig` 类里引入了一些常量，这些常量对应属性名称，详情请自行查看源代码。

### 2.2 订阅主题与分区

在创建好消费者之后，我们就需要为该消费者订阅相关的主题了，**一个消费者可以订阅一个或多个主题**。

在示例代码中，我们使用 `KafkaConsumer` 的 `subscribe` 方法订阅了一个主题，**对于这个方法而言，既可以以集合的形式订阅多个主题，也可以以正则表达式的形式订阅特定模式的主题**。它的重载如下：

```java
public void subscribe(Collection<String> topics, ConsumerRebalanceListener listener);
public void subscribe(Collection<String> topics);
public void subscribe(Pattern pattern, ConsumerRebalanceListener listener);
public void subscribe(Pattern pattern);
```

* 对于消费者**使用集合的方式**来订阅主题而言，比较容易理解，订阅了什么主题就消费什么主题中的消息。**如果前后两次订阅了不同的主题，那么消费者以最后一次的为准**。
* 如果消费者采用的是**正则表达式的方式**订阅，在之后的过程中，**如果有人创建了新的主题，并且主题的名字与正则表达式相匹配，那么这个消费者就可以消费到新添加的主题中的消息**。如果应用程序需要消费多个主题，并且可以处理不同的类型，那么这种订阅方式就很有效。

细心的读者可能观察到在 `subscribe` 的重载方法中有一个参数类型是 `ConsumerRebalanceListener`，这个是用来设置相应的再均衡监昕器的，我们很快就会讲到。

除了使用 `subscribe` 订阅主题之外，还可以使用 `assign` 方法订阅特定的分区：

```java
public void assign(Collection<TopicPartition> partitions);
```

`TopicPartition` 用来表示分区，部分源码展示如下：

```java
public final class TopicPartition implements Serializable {
    // ...
  
    private final int partition;
    private final String topic;

    public TopicPartition(String topic, int partition) {
        this.partition = partition;
        this.topic = topic;
    }

    // ...
}
```

`TopicPartition` 类只有 2 个属性：topic 和 partition，分别代表分区所属的主题和自身的分区编号，这个类可以和我们通常所说的主题/分区的概念映射起来。

如果我们事先并不知道主题中有多少个分区怎么办? `KafkaConsumer` 中的 `partitionsFor()` 方法可以用来查询指定主题的元数据信息：

```java
public List<PartitionInfo> partitionsFor(String topic);
```

其中 `PartitionInfo` 类型即为主题的分区元数据信息，此类的主要结构如下：

```java
public class PartitionInfo {
  	private final String topic;
  	private final int partition;
  	private final Node leader;
  	private final Node[] replicas;
  	private final Node[] inSyncReplicas; 
   	private final Node[] offlineReplicas;
  
  	// ...
}
```

`PartitionInfo` 类中的属性 topic 表示主题名称，partition 代表分区编号，leader 代表分区的 leader 副本所在的位置，replicas 代表分区的 AR 集合，inSyncReplicas 代表分区的 ISR 集合，offlineReplicas 代表分区的 OSR 集合 。

通过这个 `partitionsFor` + `assign` 方法，我们可以实现订阅主题（全部分区）的功能，示例：

```java
List<TopicPartition> partitions = new ArrayList<>();
List<PartitionInfo> partitionInfos = new consumer.partitionsFor(topic);
if (partitionInfos != null) {
  	for (PartitionInfo pInfo : partitionInfos) {
      	partitions.add(new TopicPartition(pInfo.topic(), pInfo.partition()));
    }
}
consumer.assign(partitions);
```

集合订阅的三种方式分别代表了三种不同订阅状态：

* AUTO_TOPICS
* AUTO_PATTERN
* USER_ASSIGN

如果没有任何订阅，那么订阅状态为 NONE。同时，这三种状态是互斥的，一个消费者只能使用其中的一种。

> 通过 `subscribe()` 方法订阅主题具有**消费者自动再均衡**的功能，在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组内的消费者增加或减少时，分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。 
>
> 而通过 `assign()` 方法订阅分区时，是不具备消费者自动均衡的功能的，其实这一点从 `assign()` 方法的参数中就可以看出端倪，两种类型的 `subscribe()` 都有 `ConsumerRebalanceListener` 类型参数的方法，而 `assign()` 方法却没有。 

既然有订阅，那么就有**取消订阅**，可以使用 `KafkaConsumer` 中的 `unsubscribe()` 方法来取消主题的订阅。请注意，这个方法既可以取消通过集合方式实现的订阅，也可以取消通过正则表达式方式实现的订阅，还可以取消通过 `assign` 方式实现的订阅。

### 2.3 反序列化

Kafka 所提供的反序列化器有 `ByteBufferDeserializer`、`ByteArrayDeserializer`、`BytesDeserializer`、`DoubleDeserializer`、`FloatDeserializer`、`IntegerDeserializr`、`LongDeserializer`、`ShortDeserializer`、`StringDeserializer`，它们分别用于 `ByteBuffer`、`ByteArray`、`Bytes`、`Double`、`Float`、`Integer`、`Long`、`Short` 及 `String` 类型的反序列化。

这些序列化器也都实现了 `Deserializer` 接口：

```java
public interface Deserializer<T> extends Closeable {

    default void configure(Map<String, ?> configs, boolean isKey) {
        // intentionally left blank
    }

    T deserialize(String topic, byte[] data);
  
  	// ...
}
```

在讲生产者的时候，我们曾经自定义 `Company` 序列化器，接下来我们实现一下它的反序列化器：

```java
import java.nio.ByteBuffer;
import java.nio.charset.StandardCharsets;
import org.apache.kafka.common.errors.SerializationException;
import org.apache.kafka.common.serialization.Deserializer;

public class CompanyDeserializer implements Deserializer<Company> {
    @Override
    public Company deserialize(String topic, byte[] data) {
        if (data == null) {
            return null;
        }
        if (data.length < 0) {
            throw new SerializationException("Size of data received by CompanyDeserializer is shorter than excepted!");
        }

        ByteBuffer buffer = ByteBuffer.wrap(data);
        int nameLen, addressLen;
        String name = null, address = null;

        nameLen = buffer.getInt();
        byte[] nameBytes = new byte[nameLen];
        buffer.get(nameBytes);
        addressLen = buffer.getInt();
        byte[] addressBytes = new byte[addressLen];

        try {
            name = new String(nameBytes, StandardCharsets.UTF_8);
            address = new String(addressBytes, StandardCharsets.UTF_8);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return new Company(name, address);
    }
}
```

如无特殊需要，笔者还是不建议使用自定义的序列化器或反序列化器，因为这样会增加生产者与消费者之间的耦合度，在系统升级换代的时候很容易出错。 

自定义的类型有一个不得不面对的问题就是 `KafkaProducer` 和 `KafkaConsumer` 之间的序列化和反序列化的兼容性。对于 `StringSerializer` 来说，`KafkaConsumer` 可以顺其自然地采用 `StringDeserializer`，不过对于 Company 这种专用类型而言，某个上游应用采用 CompanySerializer 进行序列化之后，下游应用也必须实现对应的 CompanyDeserializer。再者，如果上游的 Company 类型改变，那么下游也需要跟着重新实现一个新的 CompanyDeserializer，后面所面临的难题可想而知。

在实际应用中，在 Kafka 提供的序列化器和反序列化器满足不了应用需求的前提下，推荐使用 Avro、 JSON、 ProtoBuf 等通用的序列化工具来包装。

本节最后我们演示一下使用 Protostuff 的序列化：

```xml
<dependency>
  	<groupId>io.protostuff</groupId>
  	<artifactId>protostuff-core</artifactId>
  	<version>1.8.0</version>
</dependency>
<dependency>
  	<groupId>io.protostuff</groupId>
  	<artifactId>protostuff-runtime</artifactId>
  	<version>1.8.0</version>
</dependency>
```

```java
public class ProtostuffSerializer implements Serializer<Company> {
    @Override
    public byte[] serialize(String topic, Company data) {
        if (data == null) {
            return  null;
        }

        Schema schema = RuntimeSchema.getSchema(data.getClass());
        LinkedBuffer buffer = LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE);
        byte[] protostuff = null;

        try {
            protostuff = ProtostuffIOUtil.toByteArray(data, schema, buffer);
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            buffer.clear();
        }

        return protostuff;
    }
}
```

```java
public class ProtostuffDeserializer implements Deserializer<Company> {
    @Override
    public Company deserialize(String topic, byte[] data) {
        if (data == null) {
            return  null;
        }

        Schema schema = RuntimeSchema.getSchema(Company.class);
        Company company = new Company();
        ProtobufIOUtil.mergeFrom(data, company, schema);

        return company;
    }
}
```

### 2.4 消息消费

**Kafka 中的消费是基于拉模式的**。

消息的消费一般有两种模式：推（push）模式和拉（pull）模式，其中，推模式是服务端主动将消息推送给消费者，而拉模式是消费者主动向服务端发起请求来拉取消息。

从我们的示例代码中可以看出，Kafka 的消息消费是一个不断轮询的过程，**消费者所需要做的就是重复的调用 `poll` 方法，而 `poll` 方法返回的是所订阅的主题（分区）上的一组消息**。

对于 `poll` 方法而言，如果某些分区中没有可供消费的消息，那么此分区对应的消息拉取的结果就为空；如果订阅的所有分区中都没有可供消费的消息，那么方法返回为空的消息集合。

`poll` 的具体定义如下：

```java
public ConsumerRecords<K, V> poll(final Duration timeout)
```

注意到 `poll` 方法里还有一个超时时间参数 timeout，用来控制 `poll` 方法的阻塞时间，**在消费者的缓冲区里没有可用数据时会发生阻塞**。

timeout 的设置取决于应用程序对响应速度的要求，比如需要在多长时间内将控制权移交给执行轮询的应用线程。可以**直接将 timeout 设置为 0，这样 `poll` 方法会立刻返回，而不管是否己经拉取到了消息**。如果应用线程唯一的工作就是从 Kafka 中拉取并消费消息，则可以将这个参数设置一个比较大的时间。

从 `poll` 方法获取到的是消息集合 `ConsumerRecords`，而 `ConsumerRecords` 的每一条消息的类型是 `ConsumerRecord`：

```java
public class ConsumerRecord<K, V> {
		// ...

    private final String topic;
    private final int partition;
    private final long offset;
    private final long timestamp;
    private final TimestampType timestampType;
    private final int serializedKeySize;
    private final int serializedValueSize;
    private final Headers headers;
    private final K key;
    private final V value;
    private final Optional<Integer> leaderEpoch;
  
  	// ...
}
```

其中：

* **topic 代表消息所属的主题**。
* **partition 代表消息所在的主题的分区编号**。
* **offset 代表消息所属分区的偏移量**。
* **timestamp 表示时间戳**。
* **timestampType 表示时间戳的类型**。它有 CreateTime 和 LogAppendTime 两种类型，前者表示消息创建的时间，后者表示消息追加到日志文件的时间，之后我们会详细介绍。
* **headers 字段是消息的头部**。 
* **key 是用来指定消息的键**。
* **value 是指消息的值**。
* **serializedKeySize 是 key 经过序列化后的大小**，如果 key 为空，该值为 -1。
* **serializedValueSize 是 value 经过序列化后的大小**，如果 value 为空，该值为 -1。

我们在消费消息的时候可以直接对 `ConsumerRecord` 中感兴趣的字段进行具体的业务逻辑处理。

我们的示例代码中，使用的是迭代器的方式（for-each 循环）遍历消息，除此之外，我们还可以**按照分区维度**来进行消费，这一点很有用，在手动提交 offset 的时候尤为明显，关于 offset 提交的内容我们很快就会介绍。

`ConsumerRecords` 提供了 `records(TopicPartition)` 的方法用来获取指定分区中的消息：

```java
public List<ConsumerRecord<K, V>> records(TopicPartition partition)
```

使用示例：

```java
ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
for (TopicPartition tp : records.partitions()) {
  	for (ConsumerRecord<String, String> record : records.records(tp)) {
      	System.out.println(record.partition() + ":" + record.value());
    }
}
```

除此之外，还可以**按照主题维度**来进行消费，这个方法是 `records(TopicPartition)` 的重载：

```JAVA
public Iterable<ConsumerRecord<K, V>> records(String topic)
```

但是，`ConsumerRecords` 并未提供类似 `partitions()` 这样的方法，我们只能根据最开始消费者订阅主题时所使用的主题列表来进行消费了：

```java
List<String> topicList = Arrays.asList(topic1, topic2);
try {
  	while (isRunning.get()) {
      	ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
      	for (String topic : topicList) {
          	for (ConsumerRecord<String, String> record : records.records(tp)) {
      					System.out.println(record.topic() + ":" + record.value());
    				}
        }
    }
} finally {
  	consumer.close();
}
```

在 `ConsumerRecords` 类中还提供了几个方法来方便开发人员对消息集进行处理：`count()` 方法用来计算出消息集中的消息个数；`isEmpty()` 方法用来判断消息集是否为空；`empty()` 方法用来获取一个空的消息集。

到目前为止，可以简单地认为 `poll()` 方法只是拉取一下消息而己，但其内部逻辑并不简单，它涉及消费位移、消费者协调器、组协调器、消费者的选举、分区分配的分发、再均衡的逻辑、心跳等内容，在后面的章节中会循序渐进地介绍这些内容。

### 2.5 位移提交

对于 Kafka 中的**分区**而言，它的每条消息都有唯一的 **offset，用来表示消息在分区中对应的位置**。

对于**消费者**而言，它也有一个 offset 的概念，消费者**使用 offset 来表示消费到分区中某个消息所在的位置**。

在每次**调用 `poll()` 方法时**，它返回的是**还没有被消费过的消息集**（当然这个前提是消息己经存储在 Kafka 中了，并且暂不考虑异常情况的发生）。

要做到这一点，就需要**记录上一次消费时的消费位移，并且这个消费位移必须做持久化保存**，而不是单单保存在内存中，否则消费者重启之后就无法知晓之前的消费位移。再考虑一种情况，当有新的消费者加入时，那么必然会有再均衡的动作，对于同一分区而言，它可能在再均衡动作之后分配给新的消费者，如果不持久化保存消费位移，那么这个新的消费者也无法知晓之前的消费位移 。

在旧消费者客户端中，消费位移是存储在 ZooKeeper 中的；而在新消费者客户端中，消费位移存储在 Kafka 内部的主题 `__consumer_offsets` 中。

我们把将**消费位移存储起来（持久化）的动作称为提交，消费者在消费完消息之后需要执行消费位移的提交**。

举个例子：

![image-20220727174430485](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220727174430485.png)

x 表示某一次拉取操作中此分区消息的最大偏移量，假设**当前消费者已经消费了 x 位置的消息，那么我们就可以说消费者的消费位移为 x，图中也用了 `lastConsumedOffset` 这个单词来标识它**。

不过需要注意的是，**当前消费者要提交的位移并不是 x，而是 x + 1，即下一条要拉取的消息的位置，对应于上图中的 `position`**。

在消费者中还有一个 **`committed offset` 的概念，它表示已经提交过的消费位移**。

`KafkaConsumer` 提供了 `position(TopicPartition)` 和 `committed(TopicPartition)` 两个方法来分别获取上面所说的 `position` 和 `committed offset` 的值。

为了论证 `lastConsumedOffset`、`committed offset` 和 `position` 之间的关系，我们使用上面的这两个方法来做相关演示：我们向某个主题中分区编号为 0 的分区发送若干消息，之后再创建一个消费者去消费其中的消息，等待消费完这些消息之后就同步提交消费位移（调用 `commitSync()` 方法，这个方法的细节在下面详细介绍），最后我们观察一下 `lastConsumedOffset`、`committed offset` 和 `position` 的值。代码如下：

```java
TopicPartition tp = new TopicPartition(topic, 0);
consumer.assign(Arrays.asList(tp));
long lastConsumedoffset = -1; // 当前消费到的位移
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(1000);
    if (records.isEmpty()) {
        break;
    }
    List<ConsumerRecord<String,String>> partitionRecords =  records.records(tp);
    lastConsumedOffset = partitionRecords.get(partitionRecords.size() - 1).offset();
    consumer.commitSync(); // 同步提交消费位移
}
System.out.println("comsumed offset is " + lastConsumedOffset);
OffsetAndMetadata offsetAndMetadata = consumer.committed(tp);
System.out.println("commited offset is " + offsetAndMetadata.offset());
long posititon = consumer.position(tp);
System.out.println("the offset of the next record is " + posititon)
```

最终的输出结果如下：

```
comsumed offset is 377 
commited offset is 378 
the offset of the next record is 378
```

可以看出，消费者消费到此分区消息的最大偏移量为377，对应的消费位移 `lastConsumedOffset` 也就是 377。在消费完之后就执行同步提交，最终结果显式所提交的位移 `commited offset` 为 378，并且下一次所要拉取的消息的起始偏移重 `position` 也为 378。在本示例中，`position = committed offset = lastConsumedOffset + 1`，当然 `position` 和 `committed offset` 并不会一直相同，在之后的示例中我们会看到。

#### 2.5.1 自动提交

在 Kafka 中，**默认的消费位移的提交方式是自动提交**，这个由消费者客户端参数 `enable.auto.commit` 配置，默认值为 `true`。它和 MySQL 的自动提交不一样，MySQL 自动提交是每次执行完一句就提交，而 **Kafka 是定期提交**，这个定期的周期时间由客户端参数 `auto.commit.interval.ms` 配置，默认为 5 秒。

在默认的方式下，消费者每隔 5 秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在 `poll()` 方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。

在 Kafka 消费的编程逻辑中位移提交是一大难点，**自动提交消费位移的方式非常简便**，它免去了复杂的位移提交逻辑，让编码更简洁，但随之而来的是**重复消费和消息丢失的问题**。

比如：

![image-20220727220029701](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220727220029701.png)

当前一次 `poll()` 操作所拉取的消息集为 `[x+2, x+7]`，x+2 代表上一次提交的消费位移，说明已经完成了 x+1 之前（包括 x+1 在内）的所有消息的消费，x+5 表示当前正在处理的位置。**如果拉取到消息之后就进行了位移提交，即提交了 x+8，那么当前消费 x+5 的时候遇到了异常，在故障恢复之后，我们重新拉取的消息是从 x+8 开始的**。也就是说，**x+5 至 x+7 之间的消息并未能被消费**，如此便发生了**消息丢失**的现象。

再考虑另外一种情形，**位移提交的动作是在消费完所有拉取到的消息之后才执行的**，那么当消费 x+5 的时候遇到了异常，在故障恢复之后，我们**重新拉取的消息是从 x+2 开始的**。也就是说，**x+2 至 x+4 之间的消息又重新消费了一遍**，故而又发生了**重复消费**的现象。

自动位移提交的方式**在正常情况下不会发生消息丢失或重复消费的现象**，但是在编程的世界里异常无可避免，与此同时，自动位移提交也无法做到精确的位移管理，因此，Kafka 提供了手动提交。

#### 2.5.2 手动提交

在 Kafka 中还提供了**手动位移提交**的方式，这样可以使得开发人员对消费位移的管理控制**更加灵活**。

很多时候并不是说拉取到消息就算消费完成，而是需要将消息写入数据库、写入本地缓存，或者是更加复杂的业务处理。在这些场景下，所有的业务处理完成才能认为消息被成功消费，手动的提交方式可以让开发人员根据程序的逻辑在合适的地方进行位移提交。

开启手动提交功能的前提是消费者客户端参数 `enable.auto.commit`配置为 `false`。

手动提交可以分为异步提交和同步提交：

* `commitSync()`：同步提交，它会根据 `poll()` 方法拉取的最新位移 position 来进行提交，只要没有发生不可恢复的错误，它就会阻塞消费者直至位移提交完成。

  对于不可恢复的错误，比如 `CommitFailedException`、`WakeupException`、`InterruptException`、`AuthenticationException`、`AuthorizationException` 等，我们可以将其捕获并做针对性的处理。

  对于采用 `commitSync()` 的无参方法而言，它提交消费位移的频率和拉取批次消息、处理批次消息的频率是一样的，如果**想寻求更细粒度的、更精准的提交，那么就需要使用 `commitSync()` 的另一个含参方法**，具体定义如下：

  ```java
  public void commitSync(final Map<TopicPartition OffsetAndMetadata> offsets)
  ```

  该方法提供了一个 offsets 参数，用来提交指定分区的位移。无参的 `commitSync()` 方法只能提交当前批次对应的 position 值，如果需要提交一个中间值，比如业务每消费一条消息就提交一次位移，那么就可以使用这种方式。

  我们来看一下示例：

  ```java
  while (isRunning.get()) {
      ConsumerRecords<String,String> records = consumer.poll(1000);
      for (ConsumerRecord<String, String> record : records) {
          // do some logical processing.
          long offset = record.offset();
          TopicPartition partition = new TopicPartition(record.topic(), record.partition());
          consumer.commitsync(Collections.singletonMap(partition, new offsetAndMetadata(offset + 1)));
      }
  }
  ```

  很多时候我们都不需要消费一次就提交一次的场景，更多时候我们会按照分区的粒度划分提交的界限，也就是每消费完一个分区，就把这个分区的 offset 提交掉。代码实现：

  ```java
  try {
      while (isRunning.get()) {
          ConsumerRecords<String, String> records = consumer.poll(1000);
          for (TopicPartition partition : records.partitions()) {
              List<ConsumerRecord<String, String>> partitionRecords = records.records(partition);
              for (ConsumerRecord<String, String> record : partitionRecords) {
                  // do some logical processing.
                  long lastConsumedoffset = partitionRecords.get(partitionRecords.size() - 1).offset();
                  consumer.commitSync(Collections.singletonMap(partition, new offsetAndMetadata (lastConsumedoffset + 1))) ;
              }
          }
      }
  } finally {
      consumer.close();
  }
  ```

* `commitAsync()`：与 `commitSync()` 方法相反，异步提交的方式在执行的时候**消费者线程不会被阻塞，可能在提交消费位移的结果还未返回之前就开始了新一次的拉取操作**。异步提交可以使消费者的性能得到一定的增强。

  `commitAsync` 方法有三个不同的重载方法，具体定义如下：

  ```java
  public void commitAsync();
  public void commitAsync(OffsetCommitCallback callback);
  public void commitAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, OffsetCommitCallback callback);
  ```

  我们看到，异步的方法都提供了 callback 回调，当位移提交完成后会回调 `OffsetCommitCallback` 中的 `onComplete()` 方法。

  我们演示一下：

  ```java
  while (isRunning.get()) {
      ConsumerRecords<String, String> records = consumer.poll(1000);
      for (ConsumerRecord<String,String> record : records) {
          // do some logical processing.
          consumer.commitAsync(new offsetCommitCallback() {
              @Override
              public void onComplete(Map<TopicPartition，offsetAndMetadata> offsets, 
                                     Exception exception) {
                  if (exception == null) {
                  	System.out.println(offsets);
                  } else {
                      log.error("fail to commit offsets { } ", offsets, exception);
                  }              
              }
          });
      }
  }
  ```

  `commitAsync()` 提交的时候同样会有失败的情况发生，那么我们应该怎么处理呢？

  读者有可能想到的是重试，问题的关键也就在这里了：如果某一次异步提交的消费位移为 x，但是提交失败了，然后下一次又异步提交了消费位移为 x+y，这次成功了。如果这里引入了重试机制，前一次的异步提交的消费位移在重试的时候提交成功了，那么此时的消费位移又变为了 x。如果此时发生异常（或者再均衡），那么恢复之后的消费者(或者新的消费者）就会从 x 处开始消费消息，这样就发生了**重复消费**的问题。

  为此，我们**可以设置一个递增的序号来维护异步提交的顺序**，每次位移提交之后就增加序号相对应的值。在遇到位移提交失败需要重试的时候，可以检查所提交的位移和序号的值的大小：

  * 如果前者小于后者，则说明有更大的位移已经提交了，不需要再进行本次重试；
  * 如果两者相同，则说明可以进行重试提交。除非程序编码错误，否则不会出现前者大于后者的情况。

  > 如果位移提交失败的情况经常发生，那么说明系统肯定出现了故障，在一般情况下，位移提交失败的情况很少发生，不重试也没有关系，后面的提交也会有成功的。

  重试会增加代码逻辑的复杂度，但是不重试会增加重复消费的概率。如果消费者异常退出，那么这个重复消费的问题就很难避免，因为这种情况下无法及时提交消费位移；如果消费者正常退出或发生再均衡的情况，那么**可以在退出或再均衡执行之前使用同步提交的方式做最后的把关**。

### 2.6 控制消费

`KafkaConsumer` 提供了对消费速度进行控制的方法，在有些应用场景下我们可能需要暂停某些分区的消费而先消费其他分区，当达到一定条件时再恢复这些分区的消费。

在 `KafkaConsumer` 中，使用 `pause()` 和 `resume()` 方法来分别实现**暂停某些分区在拉取操作时返回数据给客户端**和**恢复某些分区向客户端返回数据**的操作。这两个方法的具体定义如下：

```JAVA
public void pause(Collection<TopicPartition> partitions);
public void resume(Collection<TopicPartition> partitions);
```

`KafkaConsumer` 还提供了一个无参的 `paused()` 方法来返回被暂停的分区集合，此方法的具体定义如下：

```java
public Set<TopicPartition> paused();
```

### 2.7 关闭消费

在之前的示例中，我们展示的都是使用一个 `while` 循环来包裹住 `poll()` 方法及相应的消费逻辑，如何优雅地退出这个循环也很有考究。

细心的读者可能注意到有些示例代码并不是以 `while(true)` 的形式做简单的包裹，而是使用 `while(isRunning.get())` 的方式，这样可以通过在其他地方设定 `isRunning.set(false)` 来退出循环。

还有一种方式是**调用 `KafkaConsumer` 的 `wakeup()` 方法**，该方法是 `KafkaConsumer` 中唯一可以从其他线程里安全调用的方法（`KafkaConsumer` 是非线程安全的，请和 `KafkaProducer` 区别开)，调用 **`wakeup()` 方法后可以退出 `poll()` 的逻辑，并抛出 `WakeupException` 的异常**，我们也不需要处理异常，它只是一种跳出循环的方式，就和线程的 `interrupt` 类似。

跳出循环后一定要记得使用 `close` 关闭资源，为此我们最好使用 try-with-resources 语句。

### 2.8 指定位移消费



### 2.9 再均衡

**再均衡是指分区的所属权从一个消费者转移到另一消费者的行为**，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。

不过，**在再均衡发生期间，消费组内的消费者是无法读取消息的**。也就是说，在再均衡发生期间的这一小段时间内，消费组会变得不可用。

另外，**当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失**。比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作，之后这个分区又被分配给了消费组内的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。

**一般情况下，应尽量避免不必要的再均衡的发生**。

还记得 `subscribe` 方法中的 `ConsumerRebalanceListener` 吗，它就是再均衡监听器，该接口定义如下：

```java
public interface ConsumerRebalanceListener {
    
    void onPartitionsRevoked(Collection<TopicPartition> partitions);
    
    void onPartitionsAssigned(Collection<TopicPartition> partitions);
    
    // ...
}
```

* `void onPartitionsRevoked(Collection<TopicPartition> partitions)`：这个方法会在**再均衡开始之前**和**消费者停止读取消息之后**被调用。可以通过这个回调方法来**处理消费位移的提交**，以此来避免一些不必要的重复消费现象的发生。

  参数 partitions 表示再均衡前所分配到的分区。

* `void onPartitionsAssigned(Collection<TopicPartition> partitions)`：这个方法会在**重新分配分区之后**和**消费者开始读取消费之前**被调用。

  参数 partitions 表示再均衡后所分配到的分区。

来看一个示例：

```java
Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>();
consumer.subscribe(Arrays.asList(topic), new ConsumerRebalanceListener() {
    @Override
    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
        consumer.commitSync(currentOffsets);
        currentOffsets.clear();
    }

    @Override
    public void onPartitionsAssigned(Collection<TopicPartition> partitions) {

    }
});

try {
    while (isRunning.get()) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
        for (ConsumerRecord<String, String> record : records) {
            currentOffsets.put(new TopicPartition(record.topic(), record.partition()), 
                               new OffsetAndMetadata(record.offset() + 1));
        }
        consumer.commitAsync(currentOffsets, null);
    }
} finally {
    consumer.close();
}
```

这段代码中，将消费位移暂存到一个局部变量 currentOffsets 中，这样在正常消费的时候可以通过 `commitAsync()` 方法来异步提交消费位移，在发生再均衡动作之前可以通过再均衡监听器的 `onPartitionsRevoked()` 回调执行 `commitSync()` 方法同步提交消费位移，以尽量避免一些不必要的重复消费。

再均衡监昕器还可以配合外部存储使用，比如存到数据库里，然后通过监听器再从数据库中查找分配到的分区的消费位移。`KakfaConsumer` 提供了 `seek()` 方法用来跳转特定的偏移量：

```java
void seek(TopicPartition partition, long offset);
void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata);
```

### 2.10 消费者拦截器

### 2.11 多线程实现

## 3. 重要的消费者参数