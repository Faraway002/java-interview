[TOC]

# Kafka 简介

## 1. 概述

Kafka 是一个分布式的基于发布\订阅的消息系统，有着强大的消息处理能力，相比与其他消息系统，具有以下**优点**：

- **高性能**：单机每秒处理几十上百万的消息量。即使存储了 TB 级别的消息，也保持稳定的性能。

  Kafka 的高性能主要依靠以下几点保证：

  - **零拷贝**：减少内核态到用户态的拷贝，磁盘通过 `sendfile` 实现 DMA 拷贝 Socket Buffer。
  - **顺序读写**：充分利用**磁盘顺序读写**的超高性能。
  - **页缓存 `mmap` **：将**磁盘文件映射到内存**, 用户通过修改内存就能修改磁盘文件。

- **高可用**：单节点支持上千个客户端，并保证零停机和零数据丢失。

  Kafka 是分布式，分区，复制和容错的。

- **持久化**：将消息持久化到磁盘。通过将数据持久化到硬盘以及 replication 防止数据丢失。

- **分布式**：所有的组件均为分布式的，无需停机即可扩展机器。

正是因其具有这些的优秀特性而广泛用于应用解耦、流量削峰、异步消息等场景，比如消息中间件、日志聚合、流处理等等。

## 2. Kafka 内的重要概念介绍

![image-20220726074947390](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726074947390.png)

* **消息（Message）**：Kafka 的数据单元称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”。

* **批次**：为了提高效率，消息被分批写入Kafka。提高吞吐量却加大了响应时间。

* **主题（Topic）**： 通过主题将消息进行分类，类似数据库中的表。

* **分区（Partition）**：Topic 可以被分成若干分区分布于 Kafka 集群中，方便扩容。

  单个分区内的消息是有序的，Partition 设置为 1 才能保证全局有序。

* **副本（Replicas）**：每个主题被分为若干个分区，每个分区有多个副本。

* **生产者（Producer）**：生产者在默认情况下**把消息均衡地分布到主题的所有分区上**。消费者可以：

  - 直接指定消息的分区
  - 根据消息的 key 散列取模得出分区
  - 轮询指定分区

* **消费者（Consumer）**： 消费者通过**偏移量**来区分已经读过的消息，从而消费消息。

  把每个分区最后读取的消息偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或重启，它的**读取状态不会丢失**。

* **消费者组（Consumer Group）**：消费者组保证**每个分区只能被一个消费者使用**，避免重复消费。

  如果群组内**一个消费者失效**，消费组里的**其他消费者可以接管失效消费者的工作再平衡**，重新分区。

* **节点（Broker）**：连接生产者和消费者，**单个 Broker 可以轻松处理数千个分区**以及**每秒百万级的消息量**。

  - Broker 接收来自生产者的消息，为消息设置偏移量，并提交**消息到磁盘保存**。
  - Broker 为消费者提供服务，响应读取分区的请求，**返回已经提交到磁盘上的消息**。

* **集群**：每个分区都有一个**首领**，当分区被分配给多个 Broker 时，会通过首领进行**分区复制**。

* **生产者 Offset**：消息写入的时候，每一个分区都有一个 Offset，即每个分区的最新最大的 Offset。

* **消费者 Offset**：不同消费组中的消费者可以针对一个分区存储不同的 Offset，互不影响

* **LogSegment**：一个分区由多个 LogSegment 组成，而一个 LogSegment 由 `.log .index .timeindex` 组成。

  - `.log` 追加是顺序写入的，文件名是以文件中第一条消息的 Offset 来命名的。
  - `.Index` 进行日志删除的时候和数据查找的时候可以快速定位。
  - `.timeStamp` 则根据**时间戳查找对应的偏移量**。

## 3. Kafka 安装与启动

在 Linux 系统下，只需要下载官网的压缩包，`tar -zxvf`，然后配置一下环境变量即可。

Kafka 依赖 Zookeeper，但是不必担心，Kafka 的压缩包内置了 Zookeeper。

首先，启动 Kafka 之前，要先启动 zookeeper，使用后台进程启动即可，启动脚本位于 bin 下的 `zookeeper-server-start.sh`，相关配置文件位于 config 下的 `zookeeper.properties`，因此启动命令为：

```bash
$> ./bin/zookeeper-server-start.sh config/zookeeper.properties &
```

然后启动 Kafka 服务，脚本在 bin 下的 `kafka-server-start.sh`，配置文件在 config 下的 `server.properties` 中，因此启动命令为:

```bash
$> ./bin/kafka-server-start.sh config/server.properties &
```

### 3.1 Kafka 命令行简要使用

#### 3.1.1 创建 topic

这里创建一个 topic，名字叫 test-topic，下面的例子都用这个 topic：

```bash
$> ./bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092
```

#### 3.1.2 查看 topic

我们可以查看 topic：

```bash
$> ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092
```

也可以查看具体的某一个 topic：

```bash
$> ./bin/kafka-topics.sh --describe --topic test-topic --bootstrap-server localhost:9092
```

#### 3.1.3 发送消息

```bash
$> ./bin/kafka-console-producer.sh --topic test-topic --bootstrap-server localhost:9092
```

#### 3.1.4 消费消息

```bash
$> ./bin/kafka-console-consumer.sh --topic test-topic --from-beginning --bootstrap-server localhost:9092
```

#### 3.1.5 删除 topic

```bash
$> ./bin/kafka-topics.sh --delete --topic test-topic --bootstrap-server localhost:9092
```

果 kafka 启动时加载的配置文件中 server.properties 没有配置delete.topic.enable=true，那么此时的删除并不是真正的删除，而是把 topic 标记为 `marked for deletion`，即逻辑删除。

要想彻底删除，则可以登录 zookeeper 客户端

```bash
$> ./zkCli.sh
```

找到 topic 所在的目录：

```bash
$> ls /brokers/topics
```

找到要删除的 topic，执行：

```bash
$> rmr /brokers/topics/test-topic
```

## 4. Java 访问 Kafka

首先引入 maven 依赖：

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>${kafka.version}</version>
</dependency>
```

下面是一个生产者 Demo:

```java
import java.util.HashMap;
import java.util.Map;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;

public class ProducerDemo {

    public static void main(String[] args) {
        Map<String, Object> props = new HashMap<>();
        props.put("bootstrap.servers", "106.55.250.68:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        String topic = "test-topic";
        Producer<String, String> producer = new KafkaProducer<>(props);
        producer.send(new ProducerRecord<>(topic, "idea-key2", "java-message 1"));
        producer.send(new ProducerRecord<>(topic, "idea-key2", "java-message 2"));
        producer.send(new ProducerRecord<>(topic, "idea-key2", "java-message 3"));

        producer.close();

    }

}
```

下面是一个消费者 Demo：

```java
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import java.time.Duration;
import java.util.List;
import java.util.Properties;

public class ConsumerDemo {

    public static void main(String[] args) {
        String topic = "test-topic";

        Properties props = new Properties();
        props.put("bootstrap.servers", "106.55.250.68:9092");
        props.put("group.id", "testGroup1");
        props.put("enable.auto.commit", "true");
        props.put("auto.commit.interval.ms", "1000");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        try (Consumer<String, String> consumer = new KafkaConsumer<>(props)) {
            consumer.subscribe(List.of(topic));
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("partition = %d, offset = %d, key = %s, value = %s%n", record.partition(),
                            record.offset(), record.key(), record.value());
                }
            }
        }

    }
}
```

## 5. SpringBoot 整合 Kafka

在 SpringBoot 项目中，引入该依赖：

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

然后，在 application.yml 中可以添加以 `spring.kafka` 开头的配置项，全部配置项参见 `KafkaProperties` 类，下面是一个简单的示例：

```yaml
spring:
    kafka:
        bootstrap-servers: 106.55.250.68:9092
        consumer:
            group-id: consumer-group-test
            enable-auto-commit: true
            auto-commit-interval: 3000
```

接下来，如果要发送消息，则可以使用 `KafkaTemplate`，调用 `send(String topic，V data)` 即可发送一条消息到某个 topic 下，当然，也可以使用 `send(String topic, Integer partition, K key, V data)` 指定 partition。

如果要消费，就更简单了，只需要使用一个注解 `@KafkaListener`，作用于方法上，注解内写上你关注的 topic，它就会在接收到消息时自动调用该方法，把消息绑定在参数 `ConsumerRecord<String, Object> message` 上，比如：

```java
@KafkaListener(topics = {"test"})
public void handleMessage(ConsumerRecord<String, Object> record) {
    // ...
}
```

更多用法参见 Spring 官方文档。
