[TOC]

# Kafka 生产消费基本原理

## 1. 主题与日志

### 1.1 主题

主题是存储消息的一个逻辑概念，可以简单理解为**一类消息的集合**，由使用方去创建。

Kafka 中的主题一般会有多个消费者去消费对应主题的消息，也可以存在多个生产者往主题中写入消息。

![image-20220726084417617](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726084417617.png)

**每个主题又可以划分成多个分区，每个分区存储不同的消息**。当**消息添加至分区时，会为其分配一个位移 offset**（从0开始递增），并保证分区上唯一。

**消息在分区上的顺序由 offset 保证**，即同一个分区内的消息是有序的，如下图所示：

![image-20220726091744895](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726091744895.png)

**同一个主题的不同分区会分配在不同的 Broker 上**，分区时保证 Kafka 集群具有水平扩展的基础。

举个实际的例子：

![image-20220726084608005](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726084608005.png)

以主题 `nginx_access_log` 为例，分区数为 3。

分区在**逻辑上对应一个日志**（Log），**物理上对应的是一个文件夹**。比如：

```bash
drwxr-xr-x  2 root root 4096 10月 11 20:07 nginx_access_log-0/
drwxr-xr-x  2 root root 4096 10月 11 20:07 nginx_access_log-1/
drwxr-xr-x  2 root root 4096 10月 11 20:07 nginx_access_log-2/
```

消息写入分区时，实际上是将消息写入分区所在的文件夹中。

**日志又分成多个分片（Segment），每个分片由日志文件与索引文件组成**，每个分片大小是有限的（在 Kafka 集群的配置文件 `log.segment.bytes` 配置，默认为 1073741824 字节，即 1GB），当分片大小超过限制则会重新创建一个新的分片，**外界消息的写入只会写入最新的一个分片，因此保证了顺序 I/O**。

比如：

```bash
-rw-r--r--  1 root root    1835920 10月 11 19:18 00000000000000000000.index
-rw-r--r--  1 root root 1073741684 10月 11 19:18 00000000000000000000.log
-rw-r--r--  1 root root    2737884 10月 11 19:18 00000000000000000000.timeindex
-rw-r--r--  1 root root    1828296 10月 11 19:30 00000000000003257573.index
-rw-r--r--  1 root root 1073741513 10月 11 19:30 00000000000003257573.log
-rw-r--r--  1 root root    2725512 10月 11 19:30 00000000000003257573.timeindex
-rw-r--r--  1 root root    1834744 10月 11 19:42 00000000000006506251.index
-rw-r--r--  1 root root 1073741771 10月 11 19:42 00000000000006506251.log
-rw-r--r--  1 root root    2736072 10月 11 19:42 00000000000006506251.timeindex
-rw-r--r--  1 root root    1832152 10月 11 19:54 00000000000009751854.index
-rw-r--r--  1 root root 1073740984 10月 11 19:54 00000000000009751854.log
-rw-r--r--  1 root root    2731572 10月 11 19:54 00000000000009751854.timeindex
-rw-r--r--  1 root root    1808792 10月 11 20:06 00000000000012999310.index
-rw-r--r--  1 root root 1073741584 10月 11 20:06 00000000000012999310.log
-rw-r--r--  1 root root         10 10月 11 19:54 00000000000012999310.snapshot
-rw-r--r--  1 root root    2694564 10月 11 20:06 00000000000012999310.timeindex
-rw-r--r--  1 root root   10485760 10月 11 20:09 00000000000016260431.index
-rw-r--r--  1 root root  278255892 10月 11 20:09 00000000000016260431.log
-rw-r--r--  1 root root         10 10月 11 20:06 00000000000016260431.snapshot
-rw-r--r--  1 root root   10485756 10月 11 20:09 00000000000016260431.timeindex
-rw-r--r--  1 root root          8 10月 11 19:03 leader-epoch-checkpoint
```

**一个分片包含多个不同后缀的日志文件**，分片中的第一个消息的 Offset 将作为该分片的基准偏移量，偏移量固定长度为 20，不够前面补齐 0，然后将其作为索引文件以及日志文件的文件名，如 `00000000000003257573.index`、`00000000000003257573.log`、`00000000000003257573.timeindex`，**相同文件名的文件组成一个分片**。

Kafka 的日志文件后缀对应含义如下：

| 文件类型                 | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| .index                   | 偏移量索引文件，记录 `<相对位移，起始地址>` 映射关系，其中相对位移表示该分片的第一个消息，从 1 开始计算，起始地址表示对应相对位移消息在分 片.log 文件的起始地址 |
| .timeindex               | 时间戳索引文件，记录 `<时间戳，相对位移>` 映射关系           |
| .log                     | 日志文件，存储消息的详细信息                                 |
| .snaphot                 | 快照文件                                                     |
| .deleted                 | 分片文件删除时会先将该分片的所有文件加上 .delete 后缀，然后由 `delete-file` 任务延迟删除这些文件 |
| .cleaned                 | 日志清理时临时文件                                           |
| .swap                    | Log Compaction 之后的临时文件                                |
| .leader-epoch-checkpoint |                                                              |

### 1.2 日志索引

日志索引主要是 `.index` 文件和 `.timeindex` 文件。

这里以文件`00000000000003257573.index` 和 `00000000000003257573.timeindex` 为例：

![image-20220726085611625](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726085611625.png)

* `.index` 文件：

  首先我们可以通过以下命令查看该索引文件的内容：

  ```bash
  $> ./bin/kafka-dump-log.sh --files /tmp/kafka-logs/nginx_access_log-1/00000000000003257573.index |head -n 10 
  Dumping /tmp/kafka-logs/nginx_access_log-1/00000000000003257573.index
  offset: 3257687 position: 17413
  offset: 3257743 position: 33770
  offset: 3257799 position: 50127
  offset: 3257818 position: 66484
  offset: 3257819 position: 72074
  offset: 3257871 position: 87281
  offset: 3257884 position: 91444
  offset: 3257896 position: 95884
  offset: 3257917 position: 100845
  ```

  我们可以看到输出结构为 `<offset,position>`，实际上**索引文件中保存的并不是实际位移而是相对位移**。这里格式化输出时加上了基准偏移量。

  比如，`<114,17413>` 是输出的第一条数据，在上面那个图中也可以找到，表示该分片相对位移为 114 的消息，其位移为 3257573 + 114，即 3257687，所以在命令中看到的输出就是上面这样的。

  position 表示对应 `offset` 在 `.log` 文件的物理地址，因此**通过 `.index` 索引文件则可以获取对应 offset 所在的物理地址**。

  索引采用**稀疏索引**的方式构建，**并不保证分片中的每个消息都在索引文件有映射关系**（`.timeindex` 索引也是类似），主要是为了**节省磁盘空间、内存空间**，因为**索引文件最终会映射到内存中**。

* `timeindex` 文件：首先我们可以通过 `kafka-dump-log.sh` 脚本查看时间索引文件的内容：

  ```bash
  $> ./bin/kafka-dump-log.sh --files /tmp/kafka-logs/nginx_access_log-1/00000000000003257573.timeindex |head -n 10
  Dumping /tmp/kafka-logs/nginx_access_log-1/00000000000003257573.timeindex
  timestamp: 1570792689308 offset: 3257685
  timestamp: 1570792689324 offset: 3257742
  timestamp: 1570792689345 offset: 3257795
  timestamp: 1570792689348 offset: 3257813
  timestamp: 1570792689357 offset: 3257867
  timestamp: 1570792689361 offset: 3257881
  timestamp: 1570792689364 offset: 3257896
  timestamp: 1570792689368 offset: 3257915
  timestamp: 1570792689369 offset: 3257927
  ```

  这里也是保存的一个相对位移，但是是基于时间戳大小排序的，通过这个相对位移，再结合 `.index` 文件就可以快速定位了。

想要通过索引文件快速定位消息很简单，因为两个索引文件一定程度上都是有序的，因此可以使用二分查找。

比如我想查看时间戳 `1570793423501` 开始的消息，步骤如下：

1. 首先定位分片，将 `1570793423501` 与每个分片的最大时间戳进行对比（**最大时间戳取时间索引文件的最后一条记录时间**），直到找到大于或等于`1570793423501`的日志分段，比如这里会定位到时间索引文件`00000000000003257573.timeindex`，其最大时间戳为`1570793423505`；
1. 通过**二分法**找到大于或等于`1570793423501`的最大索引项。假设这里找到了 `<timestamp: 1570793423503 offset: 6506240>`（相对位移为 3247667）；
1. 根据相对位移 3247667 去 `.index` 索引文件中找到不大于该相对位移的最大索引值 `<3248656,1073734174>`；
1. 从日志文件 `00000000000003257573.log` 的 1073734174 位置处开始扫描，查找不小于 `1570793423501` 的数据。

### 1.3 日志删除

与其他消息中间件不同的是，**Kafka 集群中的消息不会因为消费与否而删除，而是提供对应的策略周期性执行删除或者压缩操作**。

> **提示**
>
> broker 配置文件`log.cleanup.policy`参数如果为 delete 则执行删除操作，如果为 compact 则执行压缩操作，默认为 delete。

#### 1.3.1 基于时间的日志删除

首先看一下配置时间阈值的选项：

| 参数                    | 默认值      | 作用                                 |
| ----------------------- | ----------- | ------------------------------------ |
| `log.retention.hours`   | 168（七天） | 日志保留时间（小时）                 |
| `log.retention.minutes` | 无          | 日志保留时间（分钟），优先级大于小时 |
| `log.retention.ms`      | 无          | 日志保留时间（毫秒），优先级大于分钟 |

当消息在集群保留时间**超过设定阈值，则需要进行删除**。

这里会**根据分片日志的最大时间戳来判断**该分片的时间是否满足删除条件，最大时间戳首先会选取时间戳索引文件中的最后一条索引记录，如果对应的时间戳值大于 0 则取该值，否则为最近一次修改时间。

![image-20220726092043568](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726092043568.png)

如果恰好该分区下的所有日志分片均已过期，那么会先生成一个新的日志分片作为新消息的写入文件，然后再执行删除。

#### 1.3.2 基于空间的日志删除

首先看一下配置空间阈值的选项：

| 参数                  | 默认值                                   | 作用                                   |
| --------------------- | ---------------------------------------- | -------------------------------------- |
| `log.retention.bytes` | 1073741824（即1G），默认未开启，即无穷大 | 日志文件总大小，并不是指单个分片的大小 |
| `log.segment.bytes`   | 1073741824（即1G）                       | 单个日志分片大小                       |

首先会计算待删除的日志大小，然后从最旧的一个分片开始查看可以执行删除操作的文件集合，最后执行删除操作。

![image-20220726092341887](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726092341887.png)

#### 1.3.3 基于日志起始偏移量的日志删除

一般情况下，日志文件的**起始偏移量**（logStartOffset）会等于第一个日志分片的 baseOffset，但是其值**会因为删除消息请求而增长，logStartOffset 的值实际上是日志集合中的最小消息，而小于这个值的消息都会被清理掉**。

![image-20220726123529604](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726123529604.png)

如上图所示，我们假设 logStartOffset = 7421048，日志删除流程如下：

- 从最旧的日志分片开始遍历，判断其下一个分片的 baseOffset 是否小于或等于 logStartOffset 值，如果满足，则需要删除，因此第一个分片会被删除。
- 分片二的下一个分片 baseOffset = 6506251 < 7421048，所以分片二也需要删除。
- 分片三的下一个分片 baseOffset = 9751854 > 7421048，所以分片三不会被删除。

### 1.4 日志压缩

前面提到当 broker 配置文件 `log.cleanup.policy` 参数值设置为 compact 时，则会执行压缩操作。

这里的压缩跟普通意义的压缩不一样，这里的压缩是指**将相同 key 的消息只保留最后一个版本的 value 值**，如下图所示，压缩之前 offset 是连续递增，压缩之后offset 递增可能不连续，只保留 5 条消息记录：

![image-20220726144400226](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726144400226.png)



## 2. 副本

## 3. 生产者

## 4. 消费者