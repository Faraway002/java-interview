[TOC]

# 生产者

## 1. 概述

从编程的角度而言，生产者就是负责向 Kafka 发送消息的应用程序。

在 Kafka 的历史变迁中， 一共有两个大版本的生产者客户端：

* 第一个是于 Kafka 开源之初使用 Scala 语言编写的客户端，我们可以称之为旧生产者客户端（Old Producer）或 Scala 版生产者客户端 ；
* 第二个是从 Kafka 0.9.x 版本开始推出的使用 Java 语言编写的客户端，我们可以称之为新生产者客户端（New Producer）或 Java 版生产者客户端，它弥补了旧版客户端中存在的诸多设计缺陷。

虽然 Kafka 是用 Java/Scala 语言编写的，但这并不妨碍它对于多语言的支持。

本章主要针对现下流行的新生产者（Java 语言编写的）客户端做详细介绍，而旧生产者客户端己被湖汰，故不再做相应的介绍了。

## 2. 客户端开发

一个正常的生产逻辑需要具备以下几个步骤：

1. 配置生产者客户端参数及创建相应的生产者实例。
2. 构建待发送的消息。
3. 发送消息。
4. 关闭生产者实例。

我们继续拿第一章的例子来讲解生产者：

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class ProducerDemo {

    public static final String BROKER_LIST = "106.55.250.68:9092";

    public static final String TOPIC = "test-topic";

    public static Properties initConfiguration() {
        Properties props = new Properties();
        props.put("bootstrap.servers", BROKER_LIST);
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        return props;
    }

    public static void main(String[] args) {
        Properties props = initConfiguration();

        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        ProducerRecord<String, String> record = new ProducerRecord<> (TOPIC,"hello, Kafka!") ;

        try {
            producer.send(record);
        } catch (Exception e) {
            e.printStackTrace();
        }

        producer.close();
    }

}
```

这里有必要单独说明的是构建的消息对象 `ProducerRecord`，它并不是单纯意义上的消息，它包含了多个属性，原本需要发送的与业务相关的消息体只是其中的一个 value 属性。

`ProducerRecord` 的定义如下（省略其他方法）：

```java
public class ProducerRecord<K, V> {

    private final String topic;
    private final Integer partition;
    private final Headers headers;
    private final K key;
    private final V value;
    private final Long timestamp;
    
    //...
    
}
```

其中：

* **topic 代表消息要发往的主题**。

* **partition 代表消息要发往的主题的分区**。

* **headers 字段是消息的头部**， Kafka 0.11.x 版本才引入这个属性，它大多用来设定一些与应用相关的信息，如无需要也可以不用设置。 

* **key 是用来指定消息的键**，它不仅是消息的附加信息，**还可以用来计算分区号进而可以让消息发往特定的分区**。

  前面提及消息以主题为单位进行归类，而这个 **key 可以让消息再进行二次归类**，**同一个 key 的消息会被划分到同一个分区中**，之后我们会详细介绍。

  key 的消息还可以支持**日志压缩**的功能，之后我们会详细介绍。

* **value 是指消息体**， 一般不为空，如果为空则表示特定的消息一一墓碑消息。

* **timestamp 是指消息的时间戳**，它有 CreateTime 和 LogAppendTime 两种类型，前者表示消息创建的时间，后者表示消息追加到日志文件的时间，之后我们会详细介绍。

### 2.1 必要的参数配置与构建生产者实例

在创建真正的生产者实例前需要配置相应的参数。其中有三个是必须要填写的：

* `bootstrap.servers`：该参数用来指定生产者客户端连接 Kafka 集群所需的 broker 地址清单，具体的内容格式为 `host1:port1,host2:port2,...,hostn:portn`，也就是可以设置多个地址，中间以英文逗号隔开。

  注意，这里并非需要所有的 broker 地址，因为生产者会从给定的 broker 里查找到其他 broker 的信息。不过**建议至少要设置两个以上的 broker 地址信息**，以保证当其中任意一个宕机时，生产者仍然可以连接到 Kafka 集群上。

* `key.serializer` 以及 `value.serializer`：broker 端接受的消息必须以字节数组的形式存在。`KafkaProducer` 使用的泛型就是规定 key 和 value 的类型的，而 `key.serializer` 以及 `value.serializer` 就是可以把 key 和 value 序列化成字节数组的序列化器。

  这里必须填写序列化器的全限定名，以便使用反射加载。

因为这些配置太多了，而且容易写错，Kafka 在 `ProducerConfig` 类里引入了一些常量，这些常量对应属性名称，详情请自行查看源代码。

配置完成之后，就可以创建一个生产者实例了：`KafkaProducer<String, String> producer = new KafkaProducer<>(props);`

**`KafkaProducer` 是线程安全的**，可以在多个线程中共享单个 `KafkaProducer` 实例，也可以将 `KafkaProducer` 实例进行池化来供其他线程调用。

### 2.2 消息的发送

在创建完生产者实例之后，接下来的工作就是构建消息，即创建 `ProducerRecord` 对象。

之前我们已经了解过该类的字段，我们可以通过各种构造方法构建这个对象，这里就不一一列举了。

注意，**针对不同的消息需要构建不同的 `ProducerRecord` 对象**，在实际应用中 `ProducerRecord` 对象是一个非常频繁的操作。

创建生产者实例和构建消息之后，就可以开始发送消息了。

发送消息主要有 3 种模式：

* **发后即忘（fire-and-forg）**：我们的示例代码中就是这种方式，这种方式下，**生产者只管往 Kafka 发送消息而不关心是否送达**。

  这种发送方式的性能最高，当然可靠性是最差的。

* **同步（sync）**：`send` 方法其实是异步的，它有两个重载方法，返回值都是 `Future`，因此我们可以获取这个返回值，然后调用 `get` 方法阻塞，这就是同步的方式。

  比如：

  ```java
  try {
      Future<RecordMetaData> future = producer.send(record);
      RecordMetaData metadata = future.get();
  } catch (ExecutionException | InterruptedException e) {
      e.printStackTrace();
  }
  ```

  这样可以获取一个 `RecordMetadata` 对象，在 `RecordMetadata` 对象里包含了**消息的一些元数据信息**，比如当前消息的主题、分区号、分区中的偏移量、时间戳等。

* **异步（async）**：`send` 的另一个重载方法额外要求一个 `Callback` 参数，表示回调，使用这个方法就可以实现异步发送。

  比如：

  ```java
  producer.send(record, (metadata, exception) -> {
      if (exception != null) {
          exception.printStackTrace();
      } else {
          System.out.println(metadata.topic() + "-" + metadata.partition() + ":" + metadata.offset());
      }
  });
  ```

  示例代码中,遇到异常时只是做了 简单的打印操作，在实际应用中应该使用更加稳妥的方式来处理，比如可以将异常记录以便日后分析，也可以做一定的处理来进行消息重发。 

  `onCompletion()` 的方法的两个参数是互斥的，消息发送成功时，metadata 不为 null 而 exception 为 null；消息发送异常时，metadata 为 null 而 exception 不为 null。

`KafkaProducer` 一般会发生两种类型的异常：

* 可重试的异常：这类异常通常包括：`NetworkException`、`LeaderNotAvailableException`、`UnknownTopicOrPartitionException`、`NotEnoughReplicasException`、`NotCoordinatorException` 等。

  通常导致这些异常的原因是网络故障、Leader 宕机正在选举等，我们可以过一段时间重新发送。

* 不可重试的异常：这类异常比如 `RecordTooLargeException`，表示消息太大，发送不了。

对于可重试的异常来说，如果在初始配置时设置了 `retries` 参数，则 Kafka 会在规定的次数内重试发送，直到超过次数或发送成功。默认值为 0，表示不重试。

### 2.3 序列化

**生产者需要序列化器（Serializer）把对象转换成字节数组才能通过网络发送给 Kafka；而在对侧，消费者需要用反序列器（Deserializer）把从 Kafka 中收到的字节数组转换成相应对象**。

在我们的示例代码中，为了方便，key 和 value 都设定为字符串，序列化器也是用的是 Kafka 自带的 `org.apache.kafka.common.serialization.StringSerializer`。除了用于 `String` 类型的序列化器，还有 ByteArray、ByteBuffer、Bytes、Double、Integer、Long 这几种类型，它们都实现了 `org.apache.kafka.common.serialization.Serializer` 接口：

```java
public interface Serializer<T> extends Closeable {
    // 用于配置当前类
    default void configure(Map<String, ?> configs, boolean isKey) {
        // intentionally left blank
    }

   	// 执行实际的序列化操作
    byte[] serialize(String topic, T data);
	
    // ...
}
```

 生产者使用的序列化器和消费者使用的反序列化器是需要一一对应的，如果生产者使用字符串的序列化器，而消费者使用 Integer 的序列化器，那么就无法解析出消息了。

如果自带的序列化器无法满足业务需求，则可以借助第三方序列化工具，比如 JSON、ProtoBuf 等。

下面来看一个自定义序列化工具示例，假设我们要发送和接收的消息都是 Company 对象，定义如下（使用了 Lombok）：

```java
@Data 
@NoArgsConstructor 
@AllArgsConstructor 
@Builder 
public class Company { 
	private String name ; 
	private String address; 
}
```

它的序列化器我们定义如下：

```java
import org.apache.kafka.common.serialization.Serializer;

import java.nio.ByteBuffer;
import java.nio.charset.StandardCharsets;

public class CompanySerializer implements Serializer<Company> {
    @Override
    public byte[] serialize(String topic, Company data) {
        if (data == null) {
            return null;
        }
        byte[] name, address;
        try {
            if (data.getName() != null) {
                name = data.getName().getBytes(StandardCharsets.UTF_8);
            } else {
                name = new byte[0];
            }

            if (data.getAddress() != null) {
                address = data.getAddress().getBytes(StandardCharsets.UTF_8);
            } else {
                address = new byte[0];
            }

            ByteBuffer buffer = ByteBuffer.allocate(4 + 4 + name.length + address.length);
            buffer.putInt(name.length);
            buffer.put(name);
            buffer.putInt(address.length);
            buffer.put(address);

            return buffer.array();
        } catch (Exception e) {
            e.printStackTrace();
        }
        
        return new byte[0];
    }
}
```

要使用这个自定义的序列化器也非常简单，在我们之前讲解的配置中配置该类的全限定名即可。

### 2.4 分区器

消息在通过 `send()` 方法发往 broker 的过程中，有可能需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的一系列作用之后才能被真正地发往 broker。

拦截器（下一章会详细介绍）一般不是必需的，而序列化器是必需的。

消息经过序列化之后就需要确定它发往的分区，如果消息 `ProducerRecord` 中指定了 partition 字段，那么就不需要分区器的作用，因为 partition 代表的就是所要发往的分区号。

**如果消息 `ProducerRecord` 中没有指定 partition 字段，那么就需要依赖分区器，根据 key 这个字段来计算 partition 的值**。分区器的作用就是为消息分配分区。

Kafka 中提供的默认分区器是 `org.apache.kafka.clients.producer.internals.DefaultPartitioner`，它实现了`org.apache.kafka.clients.producer.Partitioner` 接口，具体如下所示：

```java
public interface Partitioner extends Configurable, Closeable {

    int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);
    
    // ...

}
```

`partition()` 方法用来计算分区号，返回值为 int 类型，参数分别表示主题、键、序列化后的键、值、序列化后的值，以及集群的元数据信息，通过这些信息可以实现功能丰富的分区器。

在默认分区器 `DefaultPartitioner` 的实现中，在 `partition()` 方法中定义了主要的分区分配逻辑：

* **如果 key 不为 null，那么默认的分区器会对 key 进行哈希**（采用 MurmurHash2 算法，具备高运算性能及低碰撞率)，最终根据得到的哈希值来计算分区号，拥有相同 key 的消息会被写入同一个分区。
* **如果 key 为null，那么消息将会以轮询的方式发往主题内的各个可用分区**。

除了使用 Kafka 提供的默认分区器进行分区分配，还可以使用自定义的分区器，只需同 `DefaultPartitioner` 一样实现 `Partitioner` 接口即可。

默认的分区器在 key 为 null 时不会选择非可用的分区，我们可以通过自定义的分区器来打破这一限制，具体的实现可以参考下面的示例代码：

```java
import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.utils.Utils;

import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;

public class DemoPartitioner implements Partitioner {
    private final AtomicInteger counter = new AtomicInteger(0);

    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        if (null == keyBytes) {
            return counter.getAndIncrement() % numPartitions;
        } else {
            return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
        }
    }

    @Override
    public void close() {
        
    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

要使用自定义的分区器，需要配置 `partitioner.class` 配置，值为类全限定名。

### 2.5 生产者拦截器

拦截器（Interceptor）是早在 Kafka 0.10.0.0 中就已经引入的一个功能，Kafka 一共有两种拦截器：生产者拦截器和消费者拦截器。本节主要讲述生产者拦截器的相关内容。

生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。

使用起来也很方便，主要是实现 `org.apache.kafka.clients.producer.ProducerInterceptor`：

```java
public interface ProducerInterceptor<K, V> extends Configurable {
    ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);
    
    void onAcknowledgement(RecordMetadata metadata, Exception exception);
    
    void close();
}
```

其中，除了 close，其他两个方法都非常重要：

* `KafkaProducer` 在将消息序列化和计算分区之前会调用生产者拦截器的 `onSend()`方法来对消息进行相应的定制化操作。一般来说最好不要修改消息 `ProducerRecord` 的 topic、key 和 partition 等信息，如果要修改，则需确保对其有准确的判断，否则会与预想的效果出现偏差。

* `KafkaProducer` 会在消息被应答（Acknowledgement）之前或消息发送失败时调用生产者拦截器的 `onAcknowledgement()` 方法，优先于用户在 `send` 设定的 `Callback` 之前执行。

  **这个方法运行在Producer 的 I/O 线程中，所以这个方法中实现的代码逻辑越简单越好，否则会影响消息的发送速度**。

下面是一个示例，这个示例中，我们为每条消息添加一个前缀 `"prefix-"`，并通过 `onAcknowledgement` 计算消息发送的成功率。实现如下：

```java
import org.apache.kafka.clients.producer.ProducerInterceptor;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

import java.util.Map;

public class ProducerInterceptorPrefix implements ProducerInterceptor<String, String> {
    private volatile long sendSuccess = 0;

    private volatile long sendFailure = 0;

    @Override
    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {
        String modifiedValue = "prefix-" + record.value();
        return new ProducerRecord<>(record.topic(), record.partition(), record.timestamp(), 
                record.key(), modifiedValue, record.headers());
    }

    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        if (exception == null) {
            sendSuccess++;
        } else {
            sendFailure++;
        }
    }

    @Override
    public void close() {
        double successRatio = (double) sendSuccess / (sendFailure + sendFailure);
        System.out.println("[INFO] 发送成功率=" + String.format("%f", successRatio * 100) + "%");
    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

实现自定义的 `ProducerInterceptor` 之后，需要配置参数 `interceptor.classes` 中指定这个拦截器。

该属性不仅可以指定一个拦截器，而且可以指定多个拦截器，形成拦截器链。拦截器链会按照指定的顺序一一执行。

如果拦截链中的某个拦截器的执行需要依赖于前一个拦截器的输出，那么就有可能产生“副作用”。设想一下，如果前一个拦截器由于异常而执行失败，那么这个拦截器也就跟着无法继续执行。在拦截链中，如果某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。

## 3. 原理分析

### 3.1 整体架构

我们来看一下生产者客户端的整体架构：

![image-20220726223037027](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726223037027.png)

#### 3.1.1 主线程与 Sender 线程

整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和 Sender 线程（发送线程)。

* 在主线程中由 `KafkaProducer` 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后**缓存到消息累加器**（`RecordAccumulator`，也称为消息收集器）中。
* **Sender 线程负责从 `RecordAccumulator` 中获取消息并将其发送到 Kafka 中**。

#### 3.1.2 `RecordAccumulator`

`RecordAccumulator` 主要用来缓存消息，以便 **Sender 线程可以批量发送**，进而减少网络传输的资源消耗以提升性能。

`RecordAccumulator` 缓存的大小可以通过生产者客户端参数 `buffer.memory` 配置，默认值为 33554432B，即 32MB。

如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这个时候 `KafkaProducer` 的 `send()` 方法调用要么被阻塞，要么抛出异常，这个取决于参数 `max.block.ms` 的配置，此参数的默认值为 60000，即 60 秒。

主线程中发送过来的消息都会被追加到 `RecordAccumulator` 的某个双端队列中，在 `RecordAccumulator` 的内部为每个分区都维护了一个双端队列，**队列中的内容就是 `ProducerBatch`，消息写入缓存时，追加到双端队列的尾部；Sender 读取消息时，从双端队列的头部读取**。

如果生产者客户端需要向很多分区发送消息，则可以将 `buffer.memory` 参数适当调大以增加整体的吞吐量。

#### 3.1.3 `ProducerBatch`

`ProducerBatch` 代表一个**消息批次**，可以包含一至多个 `ProducerRecord`。**多个`ProducerRecord` 会被包含在 `ProducerBatch` 中，这样可以使字节的使用更加紧凑**；与此同时，**将较小的 `ProducerRecord` 拼凑成一个较大的 `ProducerBatch`，也可以减少网络请求的次数以提升整体的吞吐量**。

> `ProducerBatch` 和消息的具体格式有关，更多的详细内容我们在之后的章节再说。

#### 3.1.4 `RecordAccumulator` 中的 BufferPool

消息在网络上都是以字节的形式传输的，在发送之前需要**创建一块内存区域来保存对应的消息**。

在 Kafka 生产者客户端中，这是通过 JAVA NIO 包中的  `java.io.ByteBuffer` 实现消息内存的创建和释放。不过，频繁的创建和释放是比较耗费资源的，**因此在 `RecordAccumulator` 的内部还有一个 BufferPool，它主要用来实现 `ByteBuffer` 的复用，以实现缓存的高效利用**。

不过，**BufferPool 只针对特定大小的 `ByteBuffer` 进行管理**，而其他大小的 `ByteBuffer` 不会缓存进 BufferPool 中，这个特定的大小由 `batch.size` 参数来指定，默认值为 16384B，即 16KB。

我们可以适当地调大 `batch.size` 参数以便多缓存一些消息，这个参数的大小也会影响 `ProducerBatch` 的大小。

当一条消息流入`RecordAccumulator` 时，会先寻找与消息分区所对应的双端队列，再从这个双端队列的尾部获取一个 `ProducerBatch`，查看 `ProducerBatch` 中是否还可以写入这个 `ProducerRecord`，如果可以则写入，如果不可以则需要创建一个新的 `ProducerBatch`。**在新建 `ProducerBatch` 时需要评估这条消息的大小是否超过 `batch.size` 参数的大小，如果不超过，那么就以 `batch.size` 参数的大小来创建 `ProducerBatch`，这样在使用完这段内存区域之后，可以通过 BufferPool 的管理来进行复用**；如果超过，那么就以评估的大小来创建 `ProducerBatch`，这段内存区域不会被复用。

#### 3.1.5 请求与缓存请求

Sender 从 `RecordAccumulator` 中获取缓存的消息之后，会进一步将原本 `<分区，Deque<ProducerBatch>>` 的保存形式转变成 `<Node, List<ProducerBatch>` 的形式，其中 Node 表示 Kafka 集群的 broker 节点。也就是说，Sender 根据分区从配置的 broker list 中定位到了 broker，准备进行发送了。

对于网络连接来说，生产者客户端是与具体的 broker 节点建立的连接，也就是向具体的 broker 节点发送消息，而并不关心消息属于哪一个分区；而对于 `KafkaProducer` 的应用逻辑而言，我们只关注向哪个分区中发送哪些消息，所以在这里需要做一个应用逻辑层面到网络 I/O 层面的转换。

在转换成 `<Node, List<ProducerBatch>>` 的形式之后，Sender 还会进一步封装成 `<Node, Request>` 的形式，这样就可以将 Request 请求发往各个 Node 了，这里的 Request 是指 Kafka 的各种协议请求，对于消息发送而言就是指具体的 `ProduceRequest`，更多与Kafka协议有关的内容我们之后再讲。

请求在从 Sender 线程发往 Kafka 之前还会保存到 `InFlightRequests` 中， `InFlightRequests` 保存对象的具体形式为 `Map<NodeId, Deque<Request>>`，它的主要作用是**缓存了已经发出去但还没有收到响应的请求**（NodeId 是一个 String 类型，表示节点的 id 编号）。

与此同时，`InFlightRequests` 还提供了许多管理类的方法，并且通过配置参数还可以限制每个连接（也就是客户端与 Node 之间的连接）最多缓存的请求数。这个配置参数为 `max.in.flight.requests.per.connection`，默认值为 5，即每个连接最多只能缓存 5 个未响应的请求，超过该数值之后就不能再向这个连接发送更多的请求了，除非有缓存的请求收到了响应（Response）。

通过比较 `Deque<Request>` 的 size 与这个参数的大小来判断对应的 Node 中是否已经堆积了很多未响应的消息，如果真是如此，那么说明这个 Node 节点负载较大或网络连接有问题，再继续向其发送请求会增大请求超时的可能。

##### 3.1.5.1 `leastLoadedNode`

 `InFlightRequests` 还可以获得 `leastLoadedNode`，即**所有 Node 中负载最小的那一个**。

这里的负载最小是通过每个 Node 在 InFlightRequests 中还未确认的请求决定的，**未确认的请求越多则认为负载越大**。

对于下图中的 `InFlightRequests` 来说，图中展示了三个节点：Node0、Node1 和 Node2。很明显 Node1 的负载最小。也就是说，Node1 为当前的 leastLoadedNode。选择 leastLoadedNode 发送请求可以使它能够尽快发出，避免因网络拥塞等异常而影响整体的进度。

![image-20220726231525482](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220726231525482.png)

leastLoadedNode 的概念可以用于多个应用场合，比如元数据请求、消费者组播协议的交互。

### 3.2 元数据的更新

我们通常使用下面的代码创建一条消息：

```java
ProducerRecord<String, String> record = new ProcuderRecord<>(topic, "Hello, Kafka!")；
```

我们只知道主题的名称，对于其他一些必要的信息却一无所知。KafkaProducer 要将此消息追加到指定主题的某个分区所对应的 leader 副本之前，首先需要知道主题的分区数量，然后经过计算得出（或者直接指定）目标分区，之后 KafkaProducer 需要知道目标分区的 leader 副本所在的 broker 节点的地址、端口等信息才能建立连接，最终才能将消息发送到 Kafka，在这一过程中所需要的信息都属于**元数据信息**。

在 2.1 节中我们了解了 `bootstrap.servers` 参数只需要配置部分 broker 节点的地址即可，不需要配置所有 broker 节点的地址，因为客户端可以自己发现其他 broker 节点的地址，这一过程也属于元数据相关的更新操作。

与此同时，分区数量及 leader 副本的分布都会动态地变化，客户端也需要动态地捕捉这些变化。

**元数据是指 Kafka 集群的元数据**，这些元数据具体记录了集群中有哪些主题、这些主题有哪些分区，每个分区的 leader 副本分配在哪个 broker 上、follower 副本分配在哪些节点上、哪些副本在 AR、ISR 等集合中、集群中有哪些节点、控制器节点又是哪一个等信息。

当客户端中没有需要使用的元数据信息时，比如没有指定的主题信息，或者超过 `metadata.max.age.ms` 时间没有更新元数据都会引起元数据的更新操作。
 `metadata.max.age.ms` 的默认值为 300000，即 5 分钟。元数据的更新操作是在客户端内部进行的，对客户端的外部使用者不可见。

当需要更新元数据时，首先会先挑选出 leastLoadedNode，然后向这个 Node 发送 MetadataRequest 请求来获取具体的元数据信息。这个更新操作是由 Sender 线程发起的，在创建完 MetadataRequest 之后同样会存入 `InFlightRequests`，之后的步骤就和发送消息时的类似。

元数据虽然由 Sender 线程负责更新，但是主线程也需要读取这些信息，这里的数据同步通过 `synchronized` 和 `final` 关键字来保障。

## 4. 重要的生产者参数

在 `KafkaProducer` 中，大部分参数都有合理的默认值，一般不需要修改它们。

不过了解这些参数可以让我们更合理的使用客户端，其中还有一些重要参数涉及程序的可用性以及性能，下面讲解这些重要参数。

1. **`acks`**：这个参数用来**指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的**。

   `acks` 是生产者客户端中一个非常重要的参数，它**涉及消息的可靠性和吞吐量之间的权衡**。

   `acks`参数有 3 个值可选：

   * `acks = 0`：**生产者发送消息后不需要等待任何服务端的响应**。

     如果从发送到写入 Kafka 的过程中出现某些异常，导致 Kafka 并没有收到这条消息，那么生产者也无从得知，**消息也就丢失了**。

     但是在其他配置环境相同的情况下，**acks 设置为 0 可以达到最大的吞吐量**。

   * `acks = -1` 或者 `acks = all`：**生产者在消息发送之后，需要等待 ISR 中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应**。

     在其他配置环境相同的情况下，acks 设置为 -1 可以达到最强的可靠性。但这并不意味着消息就一定可靠，因为 ISR 中可能只有 leader 副本，这样就退化成了 acks = 1 的情况。要获得更高的消息可靠性需要配合 `min.insync.replicas` 等参数的联动，消息可靠性分析的具体内容我们之后会详细介绍。

   * `acks = 1`：这也是默认值。生产者发送消息之后，只要分区的 leader 副本成功写入消息，那么它就会收到来自服务端的成功响应；如果无法写入 leader 副本，那么就会收到一个错误响应，为了避免消息丢失，生产者应该选择重发消息。

     >如果消息写入 leader 副本并返回成功响应给生产者，但是在被其他 follower 副本拉取之前 leader 崩溃，那么此时消息还是会丢失，因为新选举的 leader 副本中并没有这条对应的消息。

     `acks = 1` 是 0 和 -1 之间的一个折中方案（消息可靠性和吞吐量的折中）。

2. **`max.request.size`**：这个参数**用来限制生产者客户端能发送的消息的最大值**，默认值为 1048576B，即 1MB。

   一般情况下，这个默认值就可以满足大多数的应用场景了。笔者并不建议读者盲目地增大这个参数的配置值，尤其是在对 Kafka 整体脉络没有足够把控的时候。因为**这个参数还涉及一些其他参数的联动**，比如 broker 端的 `message.max.bytes` 参数，**如果配置错误可能会引起一些不必要的异常**。

   比如将 broker 端的 `message.max.bytes`参数配置为 10，而 `max.request.size` 参数配置为 20,那么当我们发送一条大小为 15 的消息时，生产者客户端就会报出如下的异常：

   ```java
   org.apache. kafka.common.errors.RecordTooLargeException: The request included amessage larger than the max message size the server will accept.
   ```

3. **`retries` 和 `retry.backoff.ms`**：`retries` 参数用来配置**生产者重试的次数**，默认值为 0，即在发生异常的时候不进行任何重试动作。

   消息在从生产者发出到成功写入服务器之前可能发生一些临时性的异常，比如网络抖动、leader 副本的选举等，这种异常往往是可以自行恢复的，生产者可以通过配置 retries 大于 0 的值，以此通过内部重试来恢复而不是一味地将异常抛给生产者的应用程序。如果重试达到设定的次数，那么生产者就会放弃重试并返回异常。不过并不是所有的异常都是可以通过重试来解决的，比如消息太大。

   重试还和另一个参数 `retry.backoff.ms` 有关，这个参数的默认值为 100，它用来设定**两次重试之间的时间间隔**，避免无效的频繁重试。在配置 `retries` 和 `retry.backoff.ms` 之前，最好先估算一下可能的异常恢复时间，这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试。

   Kafka 可以保证同一个分区中的消息是有序的。如果生产者按照一定的顺序发送消息，那么这些消息也会顺序地写入分区，进而消费者也可以按照同样的顺序消费它们。对于某些应用来说，顺序性非常重要，比如 MySQL 的 binlog 传输，如果出现错误就会造成非常严重的后果。

   如果将 `acks` 参数配置为非零值，并且 `max.in.flight.requests.per.connection`（inFlightRequest 缓存的请求个数）参数配置为大于 1 的值，那么就会出现错序的现象，原因是：如果第一批次消息写入失败，而第二批次消息写入成功，那么生产者会重试发送第一批次的消息，此时如果第一批次的消息写入成功，那么这两个批次的消息就出现了错序。

   一般而言，在需要保证消息顺序的场合建议把参数 `max.in.flight.requests.per.connection` 配置为1，而不是把 `acks` 配置为 0，不过这样也会影响整体的吞吐。

4. **`compression.type`**：这个参数用来指定**消息的压缩方式**，默认值为 none，即默认情况下，消息不会被压缩。

   该参数还可以配置为 gzip、snappy 和 Iz4。

   对消息进行压缩可以极大地减少网络传输量、降低网络 I/O，从而提高整体的性能。消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩。

5. **`connections.max.idle.ns`**：这个参数用来指定在多久之后关闭限制的连接，默认值是 540000 ms，即 9 分钟。

6. **`linger.ms`**：这个参数用来指定生产者发送 `ProducerBatch` 之前等待更多消息 (`ProducerRecord`）加入`ProducerBatch` 的时间，默认值为 0。

   生产者客户端会在 `ProducerBatch` 被填满或等待时间超过 `linger.ms` 值时发送出去。

   增大这个参数的值会增加消息的延迟，但是同时能提升一定的吞吐量。

   > 这个 `linger.ms` 参数与 TCP 协议中的 Nagle 算法有异曲同工之妙。

7. **`receive.buffer.bytes`**：这个参数用来设置 Socket 接收消息缓冲区（SO_RECBUF）的大小，默认值为 32768B，即 32KB。如果设置为 -1，则使用操作系统的默认值。

8. **`send.buffer.bytes`**：这个参数用来设置 Socket 发送消息缓冲区（SO_SNDBUF）的大小，默认值为131072B，即128KB。

   与 `receive.buffer.bytes` 参数一样，如果设置为 -1，则使用操作系统的默认值。

9. **`request.timeout.ms`**：这个参数用来配置 `Producer` 等待请求响应的最长时间，默认值为 30000 ms。

   请求超时之后可以选择进行重试。

   注意这个参数需要比 broker 端参数 `replica.lag.time.max.ms` 的值要大，这样可以减少因客户端重试而引起的消息重复的概率。