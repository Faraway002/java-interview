[TOC]

# 传输层

运输层位于应用层和网络层之间，是 OSI 分层体系中的第四层，同时也是网络体系结构的重要部分。运输层主要负责网络上的端到端通信。

运输层为运行在不同主机上的应用程序之间的通信起着至关重要的作用。

## 1. 概述

计算机网络的运输层非常类似于高速公路，高速公路负责把人或者物品从一端运送到另一端，而计算机网络的运输层则负责把报文从一端运输到另一端，这个端指的就是端系统。

在运输层运输报文的过程中，会遵守一定的协议规范，比如一次传输的数据限制、选择什么样的运输协议等。**运输层实现了让两个互不相关的主机进行逻辑通信的功能，看起来像是让两个主机相连一样，实际上主机可能相距十万八千里**。

在数据传输到运输层后，运输层协议会为其附上首部。这个时候的分组在运输层中也称为**报文段（segment）**。运输层一般会将报文段进行分割，分割成为较小的块，为每一块加上运输层首部并将其向目的地发送。

可选的运输层协议主要有 TCP 和 UDP，关于这两种运输协议的选择及其特性也是我们着重探讨的重点。

* TCP 叫做传输控制协议（Transmission Control Protocol），通过名称可以大致知道 TCP 协议有控制传输的功能，主要体现在其可控，可控就表示着可靠，确实是这样的，TCP 为应用层提供了一种**可靠的、面向连接**的服务，它能够将分组可靠的传输到服务端。

* UDP 叫做用户数据报协议（User Datagram Protocol），通过名称可以知道 UDP 把重点放在了数据报上，它为应用层提供了一种**无需建立连接**就可以直接发送数据报的方法。

所以，准确来说，**TCP 的分组称作报文段，UDP 的分组称作数据报**。

### 1.1 套接字编程

在 TCP 或者 UDP 发送具体的报文信息前，需要先经过一扇“门”，这个门就是套接字（socket），**套接字向上连接着应用层，向下连接着网络层**。

使用 TCP 或 UDP 通信时，会广泛用到套接字的 API，使用这套 API 设置 IP 地址、端口号，实现数据的发送和接收。

![image-20220329151048469](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329151048469.png)

#### 1.1.1 套接字类型

套接字的主要类型有三种，下面我们分别介绍一下

- 数据报套接字：数据报套接字提供一种无连接的服务，而且并不能保证数据传输的可靠性。数据有可能在传输过程中丢失或出现数据重复，且无法保证顺序地接收到数据。

  数据报套接字使用 UDP 进行数据的传输。由于数据报套接字不能保证数据传输的可靠性，对于有可能出现的数据丢失情况，需要在程序中做相应的处理。

- 流套接字：流套接字用于提供面向连接、可靠的数据传输服务。能够保证数据的可靠性、顺序性。流套接字之所以能够实现可靠的数据服务，原因在于其使用了 TCP。

- 原始套接字: 原始套接字允许直接发送和接收 IP 数据包，而无需任何特定于协议的传输层格式，原始套接字可以读写内核没有处理过的 IP 数据包。

#### 1.1.2 套接字通信流程

在计算机网络中，要想实现通信，必须至少需要两个端系统，至少需要一对两个套接字才行。

下面是 TCP 套接字的通信过程（UDP 比较简单，这里不做举例）：

![image-20220424174626103](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220424174626103.png)

1. 服务端和客户端初始化 `socket`，得到文件描述符；

2. 服务端调用 `bind`，将绑定在 IP 地址和端口;
3. 服务端调用 `listen`，进行监听；
4. 服务端调用 `accept`，等待客户端连接；
5. 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
6. 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
7. 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
8. 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。所以，监听的 socket 和真正用来传送数据的 socket，是两个socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

### 1.2 IP 简述

在仔细探究运输层协议之前，我们先简要了解一下 IP 协议。

IP 是 Internet Protocol（网际互连协议）的缩写，是 TCP/IP 体系中的网络层协议。设计 IP 的初衷主要想解决两类问题：

- 提高网络扩展性：实现大规模网络互联。
- 对应用层和链路层进行解藕，让二者独立发展。

IP 是整个 TCP/IP 协议族的核心，也是构成互联网的基础。为了实现大规模网络的互通互联，IP 更加注重适应性、简洁性和可操作性，并在可靠性做了一定的牺牲。IP **不保证**分组的**交付时限和可靠性**，所传送分组有可能出现**丢失、重复、延迟或乱序**等问题。

IP 会使用 IP 地址来标识主机，**每台主机都会被分配一个唯一的 IP 地址**。

### 1.3 端口号

如果说 IP 表示一台主机，则**端口号是表示一台主机中的特定的进程**。

端口号是 16 位的非负整数，它的范围是 0 - 65535 之间，这个范围会分为三种不同的端口号段，由 Internet 号码分配机构 IANA 进行分配：

- 周知/标准端口号，它的范围是 0 - 1023
- 注册端口号，范围是 1024 - 49151
- 私有端口号，范围是 49152 - 65535

仅凭一方的 IP 地址 + 端口号来识别一个报文段是不够的，因此通常会使用 `(源 IP 地址, 源端口号, 目的 IP 地址, 目的端口号)` 的一个四元组来标识，这些也是**多路分解和多路复用**的基础。

### 1.4 多路复用与多路分解

* 将运输层报文段中的数据交付到正确的套接字的工作称为**多路分解**。
* 在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息从而生成报文段，然后将报文段传递到网络层，所有这些工作被称为**多路复用**。

多路复用和多路分解又分为无连接的多路复用/多路分解和面向连接的多路复用/多路分解。

#### 1.4.1 无连接的多路复用和多路分解

无连接套接字的标识是一个**二元组**，仅包含**目的 IP 地址和目的端口号**。所以，如果两个 UDP 报文段有不同的源 IP 地址，但是具有相同的源端口号，并且具有相同的目的 IP 地址和目的端口号，那么这两个报文会通过套接字定位到相同的目的进程。

源端口号也是很重要的，这是因为**源端口号会作为返回地址的一部分**，即当 B 需要回发一个报文段给 A 时，B 需要从 A 到 B 中的源端口号取值，如下图所示：

![image-20220329154530544](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329154530544.png)

#### 1.4.2 面向连接的多路复用与多路分解

如果说无连接的多路复用和多路分解指的是 UDP 的话，那么面向连接的多路复用与多路分解指的是 TCP 了，TCP 和 UDP 在报文结构上的差别是，UDP 是一个二元组而 TCP 是一个**四元组**，即**源 IP 地址、目标 IP 地址、源端口号、目标端口号** ，这个我们上面也提到了。当一个 TCP 报文段从网络到达一台主机时，这个主机会根据这四个值拆解到对应的套接字上。

![image-20220329154823948](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329154823948.png)

上图显示了面向连接的多路复用和多路分解的过程，图中主机 C 向主机 B 发起了两个 HTTP 请求，主机 A 向主机 C 发起了一个 HTTP 请求，主机 A、B、C 都有自己唯一的 IP 地址，当主机 C 发出 HTTP 请求后，主机 B 能够分解这两个 HTTP 连接，因为主机 C 发出请求的两个源端口号不同，所以对于主机 B 来说，这是两条请求，主机 B 能够进行分解。对于主机 A 和主机 C 来说，这两个主机有不同的 IP 地址，所以对于主机 B 来说，也能够进行分解。

## 2. UDP

UDP 的全称是用户数据报协议（User Datagram Protocol），UDP 为应用程序提供了一种**无需建立连接**就可以发送封装的 IP 数据包的方法。如果应用程序开发人员选择的是 UDP 而不是 TCP 的话，那么该应用程序相当于就是和 IP 直接打交道的。

从应用程序传递过来的数据，会附加上多路复用/多路分解的源和目的端口号字段，以及其他字段，然后将形成的报文传递给网络层，网络层将运输层报文段封装到 IP 数据报中，然后尽力而为的交付给目标主机。最关键的一点就是，使用 UDP 协议在将数据报传递给目标主机时，**发送方和接收方的运输层实体间是没有握手的**，正因为如此，UDP 被称为是无连接的协议。

### 2.1 UDP 的特点

UDP 协议一般作为流媒体应用、语音交流、视频会议所使用的传输层协议，DNS 协议底层也使用了 UDP 协议，这些应用或协议之所以选择 UDP 主要是因为以下这几点：

- **速度快**：采用 UDP 协议时，只要应用进程将数据传给 UDP，UDP 就会将此数据打包进 UDP 报文段并立刻传递给网络层。而 TCP 有拥塞控制的功能，它会在发送前判断互联网的拥堵情况，如果互联网极度阻塞，那么就会抑制 TCP 的发送方。使用 UDP 的目的就是希望实时性。
- **无须建立连接**：TCP 在数据传输之前需要经过三次握手的操作，而 UDP 则无须任何准备即可进行数据传输。因此 UDP 没有建立连接的时延。
- **无连接状态**：TCP 需要在端系统中维护连接状态，连接状态包括接收和发送缓存、拥塞控制参数以及序号和确认号的参数，在 UDP 中没有这些参数，也没有发送缓存和接受缓存。因此，某些专门用于某种特定应用的服务器当应用程序运行在 UDP 上，一般能支持更多的活跃用户
- **分组首部开销小**：每个 TCP 报文段都有 20 字节的首部开销，而 UDP 仅仅只有 8 字节的首部开销。

> 请注意，并不是所有使用 UDP 的应用都是不可靠的，应用程序完全可以基于 UDP 自己实现可靠的数据传输，比如 HTTP/3 使用的 QUIC 协议。

### 2.2 UDP 的报文结构

每个 UDP 报文分为 UDP 报文头和 UDP 数据区两部分。报文头由 4 个 16 位长（2 字节）字段组成，分别说明该报文的源端口、目的端口、报文长度和校验和：

![image-20220329155637134](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329155637134.png)

- **源端口号**：这个字段占据 UDP 报文头的前 16 位，通常包含发送数据报的应用程序所使用的 UDP 端口。接收端的应用程序利用这个字段的值作为发送响应的目的地址。

  这个字段是可选项，有时不会设置源端口号，没有源端口号就默认为 0 ，通常用于不需要返回消息的通信中。

- **目标端口号**：表示接收端端口，字段长为 16 位

- **长度**：该字段占据 16 位，表示 UDP 数据报长度，包含 UDP 报文头和 UDP 数据长度。因为 UDP 报文头长度是 8 个字节，所以这个值最小为 8，最大长度为 65535 字节。

- **校验和**：UDP 使用校验和来保证数据安全性，UDP 的校验和也提供了差错检测功能，差错检测用于校验报文段从源到目标主机的过程中，数据的完整性是否发生了改变。

> **UDP 报文里为什么没有 IP 地址？**
>
> 我们在讲解多路复用与多路分解时，提到一个无连接套接字用一个目的 IP 地址和目的端口号标识，但是在 UDP 报文中，并没有看见目的 IP 地址。
>
> 事实上，TCP 报文中也没有目的 IP 地址和源 IP 地址，这是因为底层的 IP 数据报包含了源 IP 地址和目的 IP 地址，所以实际上无论是 TCP 还是 UDP 都使用四元组标识，但是 UDP 实际上在多路复用和多路分解使用的并不是完整的四元组。

### 2.3 UDP 校验和

UDP 校验和提供了差错检测的功能，这就是说，校验和用于确定当 UDP 报文段从源到达目的地移动时，其中的比特是否发生了改变。

原理是：发送方对 UDP 报文段中的所有 16 比特字进行**求和**，然后进行**反码**运算，求和时遇到的任何溢出都将被**回卷**。把求出的结果放在校验和中，这样一来，接收方就多了一个 16 比特字，相加取反以后，得到的结果应该是全 1。如果不是全 1，则说明出现了差错。

UDP 为什么提供差错检测？这其实是一种端到端的设计原则，这个原则说的是**要让传输中各种错误发生的概率降低到一个可以接受的水平**。

那 UDP 提供了差错检测为什么还是不可靠？事实上，UDP 不可靠的原因是它虽然提供差错检测的功能，但是**对于差错没有恢复能力，更不会有重传机制**。

## 3. TCP

UDP 是一种没有复杂的控制，提供无连接通信服务的一种协议，换句话说，它将部分控制部分交给应用程序去处理，自己只提供作为传输层协议最基本的功能。与 UDP 不同的是，同样作为传输层协议，TCP 协议要比 UDP 的功能多很多。

TCP 的全称是 Transmission Control Protocol，它被称为是一种**面向连接的协议**，这是因为一个应用程序开始向另一个应用程序发送数据之前，这两个进程必须先进行**握手**，握手是一个**逻辑连接**，并不是两个主机之间进行真实的握手。 这个**连接是指各种设备、线路或者网络中进行通信的两个应用程序为了相互传递消息而专有的、虚拟的通信链路**。

如下图所示：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329200730415.png" alt="image-20220329200730415" style="zoom:67%;" />

一旦主机 A 和主机 B 建立了连接，那么进行通信的应用程序只使用这个虚拟的通信线路发送和接收数据就可以保证数据的传输，TCP 协议负责控制连接的建立、断开、保持等工作。

TCP 连接是**全双工**的，所谓全双工，指的是**主机 A 与另外一个主机 B 存在一条 TCP 连接，那么应用程数据就可以从主机 B 流向主机 A 的同时，也从主机 A 流向主机 B**。

TCP **只能进行点对点连接**，那么所谓的多播，即一个主机对多个接收方发送消息的情况，是不存在的，TCP 连接只能连接两个（一对）主机。

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329200817871.png" alt="image-20220329200817871" style="zoom:67%;" />

TCP 会将数据临时存储到连接的**发送缓存（send buffer）**中，这个 send buffer 是握手期间设置的缓存之一，然后 TCP 在合适的时间将发送缓存中的数据发送到目标主机的**接收缓存（receive buffer）**中，实际上，每一端都会有发送缓存和接收缓存，如下图所示：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329200914162.png" alt="image-20220329200914162" style="zoom:67%;" />

**TCP 会将要传输的数据流分为多个块**（chunk），然后**向每个 chunk 中添加 TCP 标头**，这样就形成了一个 TCP 段也就是报文段。每一个报文段可以传输的长度是有限的，不能超过**最大分节长度（Maximum Segment Size，MSS）**。

在报文段向下传输的过程中，会经过链路层，链路层有一个**最大传输单元（Maximum Transmission Unit，MTU），即数据链路层上所能通过最大数据包的大小**，最大传输单元通常与通信接口有关。

**MSS 和 MTU 的关系一般是 MSS = MTU - TCP 报文段的头长度 - IP 数据报的头长度**。如果 MTU 是 1500，则 MSS = 1500 - 20 - 20 = 1460。

### 3.1 TCP 和 UDP 的对比

1. **连接**。TCP 是面向连接的传输层协议，传输数据前先要建立连接；UDP 是不需要连接的，即刻传输数据。
2. **服务对象**。TCP 是一对一的两点服务，即一条连接只有两个端点；UDP 支持一对一、一对多、多对多的交互通信。
3. **可靠性**。TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达；UDP 是尽最大努力交付，不保证可靠交付数据。
4. **拥塞控制与流量控制**。TCP 有拥塞控制和流量控制机制，保证数据传输的安全性和整个网络的尽可能畅通；UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
5. **首部开销**。TCP 首部长度较长，会有一定的开销，首部在没有使用选项字段时是 `20` 个字节，如果使用了选项字段则会变长；UDP 首部只有 8 个字节，并且是固定不变的，开销较小。
6. **分片**。TCP 的数据大小如果**大于 MSS** 大小，则会**在传输层进行分片**，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片；UDP 的数据大小如果**大于 MTU** 大小，则会**在 IP 层进行分片**，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

由于上述的这些不同，TCP 和 UDP 的应用场景也不同，TCP 由于可靠交付，因此经常用于：

- FTP 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 DNS  等；
- 视频、音频等多媒体通信；
- 广播通信；

### 3.2 TCP 报文段结构

TCP 报文段结构如下图所示：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329203943648.png" alt="image-20220329203943648" style="zoom:67%;" />

TCP 报文段结构相比 UDP 报文结构多了很多内容，但是前两个 16 比特的字段是一样的，它们是源端口号和目标端口号，我们知道，这两个字段是用于多路复用和多路分解的。另外，和 UDP 一样，TCP 也包含校验和。

除此之外，TCP 报文段首部还有下面这些：

- 32 比特的**序号**字段和 32 比特的**确认号**字段，这些字段被 TCP 发送方和接收方**用来实现可靠的数据传输**。

- 4 比特的**首部字段长度**字段，这个字段指示了以 32 比特的字为单位的 TCP 首部长度。

  TCP 首部的长度是可变的，但是**通常情况下，选项字段为空**，所以 **TCP 的经典首部字段的长度是 20 字节**。

- 4 比特**未使用**。

- 8 比特的**标志**字段：

  * `CWR` 和 `ECE` 用于拥塞控制。
  * `URG` 标志用来表示数据中存在需要被上层处理的紧急数据。紧急数据最后一个字节由 16 比特的紧急数据指针字段指出。

  * `ACK` 标志用于指示确认字段中的值是有效的，这个报文段包括一个对已被成功接收报文段的确认。
  * `PSH` 标志用于表示立刻将数据交给上层处理。
  * `RST`、`SYN`、`FIN` 标志用于连接的建立和关闭。

  一般情况下，`PSH` 和 `URG` 并没有使用。

- 16 比特的**接收窗口**字段，这个字段用于流量控制。它用于指示接收方能够/愿意接受的字节数量。

- 可变的**选项**字段，这个字段用于发送方和接收方协商最大报文长度，也就是协商 MSS 时使用。

TCP 的各种功能和特点都是通过 TCP 报文结构来体现的。

### 3.3 TCP 的可靠传输实现

TCP 的可靠传输包括以下几个机制：

1. **校验和**：如果校验和校验失败则接受方丢弃分组。校验和的机制和 UDP 的校验和一样，不再赘述。
2. **序号/确认号 + 重传机制**：借助 seq + ack 需要来完成分组确认，如果发送端有分组未被 ack，则可能是出现了丢包，此时重传该丢失分组，保证分组不会缺失。
3. **流量控制**：收发双方都有接收/发送窗口，如归对端窗口被填满，则本端将停止/减缓发送速度，以减少丢包。
4. **拥塞控制**：当 TCP 检测到网络发生拥塞时，则减缓数据发送数据，以减少丢包。

#### 3.3.1 序号/确认号 + 重传机制

##### 3.3.1.1 序号与确认号

TCP 报文段首部中两个最重要的字段就是**序号和确认号**，这两个字段是 **TCP 实现可靠性的基础**。

要了解可靠传输的实现，首先得知道这两个字段里面存了哪些内容。

**一个报文段的序号就是数据流的首个字节的编号**。因为 TCP 会把数据流分割成为一段一段的字节流，因为字节流本身是有序的，所以每一段的字节编号就是标示是哪一段的字节流。

比如，主机 A 要给主机 B 发送一条数据。数据经过应用层产生后会有一串数据流，数据流会经过 TCP 分割，分割的依据就是 MSS，假设数据是 10000 字节，MSS 是 2000 字节，那么 TCP 就会把数据拆分成 0 - 1999 和 2000 - 3999 的段，依次类推。所以，第一个数据 0 - 1999 的首字节编号就是 0 ，2000 - 3999 的首字节编号就是 2000...

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329210817728.png" alt="image-20220329210817728" style="zoom:67%;" />

**确认号则是期望从对方主机收到的下一个字节的序号**，由于 TCP 是一个全双工的协议，因此主机 A 在发送给主机 B 的数据的同时，也接收着来自主机 B 的数据。而从主机 B 到主机 A 的报文也会有序号，因此确认号就是主机 A 希望从主机 B 接收到的下一个字节的序号。

**TCP 在接收到数据后，会发送一个报文以确认收到**，通过在 TCP 的回复报文中设置确认号，来表示自己收到了发送的第一个字节到**确认号 - 1** 个字节，比如：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329212422478.png" alt="image-20220329212422478" style="zoom:67%;" />

**TCP 对于多个连续发送的报文段，只会确认最后一个段，这个机制被称为累积确认**。在接收方，回复报文段中确认号之前的所有字节都被接收到了。

注意，只有**当 ACK 标志位生效时，确认号才生效**，所以回复的报文也称为 ACK 报文。

累计确认也是为了接收方能够重新构建失序的字节流，比如 0 ~ 999 发送到了，由于某种原因，1000 ~ 1999 延迟到达，2000 ~ 2999 率先到达，这时该怎么办？事实上，根据累计确认的原则，我们只能确认 0 ~ 999 到达，1000 ~ 1999 并未到达，因此接收方发送的 ACK 应该是 1000，而且，**发送方会保留失序到达的报文段**，也就是 2000 ~ 2999，以便重新构建字节流。

##### 3.3.1.2 重传

TCP 使用了重传解决可靠数据传输的问题，重传也就是 TCP 发送方重新发送可能出现丢包的数据包。

###### 3.3.1.2.1 超时重传

对于发送方来说，如果一段时间没有接收到 ACK 报文，则会认为发生了**丢包**，这时它会选择重新发送该数据，也叫做**超时重传**。

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329212812802.png" alt="image-20220329212812802" style="zoom:67%;" />



当然，**ACK 也是有可能发生丢包的**，这时还是会触发重传：

![image-20220329212902318](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329212902318.png)

**对于重复的报文段，TCP 接收方一般会选择丢弃**。

对于超时重传，最重要的就是**设置超时时间**：

* 如果**超时时间过短，则会导致大量 ACK 在未到达之前就超时**，引起大量数据包重传，称之为过早超时；
* 如果**超时时间过长，则会导致一个实际丢包的数据包迟迟得不到重传**，如果频繁发生该数据包的丢失，则最后收到数据包的时间可能需要很久。

首先介绍一下 RTT 的概念，RTT 是 Round-Trip Time，也就是一次往返所需要的时间：

![image-20220329220015994](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329220015994.png)

我们使用 RTO（Retransmission Timeout）表示超时重传的时间，精确的测量 RTO 的值是非常重要的，这可让我们的重传机制更高效。我们根据 RTT，应该可以得出一个简单的结论：RTO 应该略大约 RTT。如下图所示：

![image-20220329220214843](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329220214843.png)

但是 RTT 会经常变化，所以 RTO 应该也是一个经常变化的动态值。

下面是 Linux 的 RTO 计算机制：

1. 首次计算。
   $$
   SRTT = R1 \newline
   DevRTT = \frac{R1}{2} \newline
   RTO = \mu * SRTT + \partial * DevRTT = \mu * R1 + \partial * \frac{R1}{2}
   $$
   其中 $R1$ 为首次测量的 RTT。

2. 后续计算。
   $$
   SRTT = SRTT + \alpha * (RTT - SRTT) = R1 + \alpha * (R2 - R1) \newline
   DevRTT = (1 - \beta) * DevRTT + \beta * (|RTT - SRTT|) = (1 - \beta) * \frac{R1}{2} + \beta * (|R2 - R1|) \newline
   RTO = \mu * SRTT + \partial * DevRTT
   $$
   其中， SRTT 是计算平滑的RTT ，DevRTT 是 SRTT 与 最新 RTT 的差距。


在 Linux 下，$\alpha$ = 0.125，$\beta$ = 0.25，$\mu$ = 1，$\partial$ = 4，这是经过大量实验得出的结论。

如果超时重发的数据，发生再次超时，又需要重传的时候，TCP 的策略是**超时间隔加倍**，也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。两次超时，就说明网络环境差，不宜频繁反复发送。

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？这就要介绍 TCP 的快速重传机制了。

###### 3.3.1.2.2 快速重传

当 TCP 接收到多个（一般是 3 个）一样的 ACK 时，就会触发快速重传，此时**只重传 ACK 期望接收到的包**。如下图所示：

![image-20220329222023535](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220329222023535.png)

这些重复的 ACK 也被称作**冗余 ACK**。冗余 ACK 的数量达到**重复阈值（dupthresh）**时就会触发快速重传，这个值可以设置，一般是 3。

快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题，以上面的例子为例：重传的时候，由于一直接收到的是 ACK 2，Seq 3 4 5 其实已经被接收方接收并缓存了，但是发送方并不知道到底后面的 Seq 3 4 5 是否被接收到了，此时触发快速重传机制，那么到底是只重传 ACK 2 对应的 Seq 2，还是 Seq 3 4 5 也跟着一起传过来？	

为了解决不知道该重传哪些 TCP 报文的问题，于是就有了 SACK 的方法。

###### 3.3.1.2.3 选择性确认（SACK）

这种方式需要在 TCP 头部的选项字段里加一个 `SACK`，它**可以将知道哪些数据收到了，哪些数据没收到的信息发送给发送方**，这样就可以**只重传丢失的数据**。

如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。

![选择性确认](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/11.jpg)

如果要支持 `SACK`，必须双方都要支持。在 Linux 下，可以通过 `net.ipv4.tcp_sack` 参数打开这个功能（Linux 2.4 后默认打开）。

#### 3.3.2 TCP 流量控制

如果接收方的接收速率相对缓慢，而发送方发送的比较快，就有可能导致接收方的接收缓存溢出。

TCP 提供了流量控制服务，以消除发送方使接收方缓存溢出的可能性，因此流量控制实际上是一个速度匹配服务，即发送方的写速率和接收方的读取速率相匹配。

##### 3.3.2.1 滑动窗口

TCP 通过让发送方和接收方各维护一个**窗口（window）**来提供流量控制，具体来说，**接收方维护一个接收窗口（rwnd）**，用于告诉发送方接收方还有多少可用的缓存空间，**于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来**。

由于发送方才是主要的那方，因此窗口大小是由接收方的窗口大小来决定的，发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

###### 3.3.2.1.1 发送窗口

为了方便管理，发送方也维护了一个**发送窗口（swnd）**，如下图所示：

![image-20220331152922557](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331152922557.png)

- \#1 是已发送并收到 ACK确认的数据：1~31 字节
- \#2 是已发送但未收到 ACK确认的数据：32~45 字节
- \#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
- \#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后

发送方如果收到了一个 #2 区的 ACK 后（比如 32），就说明接收方已经处理完了 32，因此整个窗口可以往后推一格，32 归到 #1，33 做为 #2 的开头，52 被纳入 #3，53 作为 #4 的开头。

假设收到了 5 个 ACK，则窗口就会变成这个样子：

![32 ~ 36 字节已确认](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/18.jpg)

由于在发送的过程中会一直重复上述过程，窗口不断地滑动，因此叫做滑动窗口。

在实际 TCP 实现，需要使用多个变量来维护窗口，如下图所示：

![SND.WND、SND.UN、SND.NXT](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/19.jpg)

- `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）
- `SND.UNA`：是一个绝对指针，它指向的是**已发送但未收到确认**的第一个字节的序列号，也就是 #2 的第一个字节
- `SND.NXT`：也是一个绝对指针，它指向**未发送但处于可发送范围内**的第一个字节的序列号，也就是 #3 的第一个字节
- 指向 #4 的第一个字节是个相对指针，它可以根据 `SND.UNA` 指针加上 `SND.WND` 大小的偏移量计算出来，即指向 #4 的第一个字节

那么，整个**可用窗口大小** = `SND.WND - (SND.NXT - SND.UNA)`。

###### 3.3.2.1.2 接收窗口

接收方的窗口示意图如下：

![接收窗口](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/20.jpg)

- \#1 + #2 是已成功接收并确认的数据（等待应用进程读取）
- \#3 是未收到数据但可以接收的数据
- \#4 未收到数据并不可以接收的数据

使用两个指针就可以划分了：

- `RCV.WND`：表示接收窗口的大小，它会通告给发送方
- `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节
- 指向 #4 的第一个字节是个相对指针，它可以根据 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量计算出来，即指向 #4 的第一个字节

接收方的滑动流程和发送方是类似的，接收方处理完毕以后就可以将窗口往右滑动。

> **接收窗口和发送窗口的大小是相等的吗？**
>
> 并不一定相等，接收窗口的大小是**约等于**发送窗口的大小的。
>
> 因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 window 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。

##### 3.3.2.2 流量控制过程

以下图为例，展示一下流量控制的过程，前提：

- 客户端是接收方，服务端是发送方
- 假设接收窗口和发送窗口大小相同，都为 `200`
- 假设两个设备在整个传输过程中都**保持相同的窗口大小**，不受外界影响

流程如下图所示：

![流量控制](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/21.jpg)

1. 客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。
2. 服务端收到请求报文后，发送确认报文和 80 字节的数据，于是可用窗口 `Usable` 减少为 120 字节，同时 `SND.NXT` 指针也向右偏移 80 字节后，指向 321，**这意味着下次发送数据的时候，序列号是 321。**
3. 客户端收到 80 字节数据后，于是接收窗口往右移动 80 字节，`RCV.NXT` 也就指向 321，**这意味着客户端期望的下一个报文的序列号是 321**，接着发送确认报文给服务端。
4. 服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0，服务端无法再继续发送数据。
5. 客户端收到 120 字节的数据后，于是接收窗口往右移动 120 字节，`RCV.NXT` 也就指向 441，接着发送确认报文给服务端。
6. 服务端收到对 80 字节数据的确认报文后，`SND.UNA` 指针往右偏移后指向 321，于是可用窗口 `Usable` 增大到 80。
7. 服务端收到对 120 字节数据的确认报文后，`SND.UNA` 指针往右偏移后指向 441，于是可用窗口 `Usable` 增大到 200。
8. 服务端可以继续发送了，于是发送了 160 字节的数据后，`SND.NXT` 指向 601，于是可用窗口 `Usable` 减少到 40。
9. 客户端收到 160 字节后，接收窗口往右移动了 160 字节，`RCV.NXT` 也就是指向了 601，接着发送确认报文给服务端。
10. 服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 `SND.UNA` 指针偏移了 160 后指向 601，可用窗口 `Usable` 也就增大至了 200。

##### 3.3.2.3 窗口关闭（零窗口）

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭，也叫做零窗口**。

窗口关闭是有潜在风险的：接收方向发送方通告窗口大小时，是通过 ACK 来通告的。那么，当发生窗口关闭时，接收方处理完数据后，会**向发送方通告一个窗口非 0 的 ACK，如果这个通告窗口的 ACK 报文在网络中丢失了，那就会造成两边互相等待，形成了类似死锁的局面**。

![窗口关闭潜在的危险](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/24.jpg)

为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

如果持续计时器超时，就会发送**窗口探测 (window probe) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

- 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
- 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

##### 3.3.2.4 小窗口

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小，到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节**，这就是小窗口的问题。

要知道，我们的 `TCP + IP` 头有 `40` 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济了。

要解决这个问题，需要解决两个问题：

- **让接收方不通告小窗口给发送方**

  当窗口大小小于 `min(MSS，缓存空间 / 2)`，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`，也就阻止了发送方再发数据过来。

  等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。

- **让发送方避免发送小数据**

  使用 **Nagle 算法**，该算法的思路是**延时处理**，Nagle 算法的策略：

  - 没有已发送未确认报文时，立刻发送数据。
  - 存在未确认报文时，暂时不发送数据，**直到没有已发送未确认报文或数据长度达到 MSS 大小时**，再发送数据。

  只要没满足上面条件中的任意一条，发送方就会一直囤积数据，直到满足上面的发送条件。

  ![image-20220424233032207](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220424233032207.png)

  上图右侧启用了 Nagle 算法，它的发送数据的过程：

  - 一开始由于没有已发送未确认的报文，所以就立刻发了 H 字符；
  - 接着，在还没收到对 H 字符的确认报文时，发送方就一直在囤积数据，直到收到了确认报文后，此时没有已发送未确认的报文，于是就把囤积后的 ELL 字符一起发给了接收方；
  - 待收到对 ELL 字符的确认报文后，于是把最后一个 O 字符发送了出去；

  可以看出，**Nagle 算法一定会有一个小报文，也就是在最开始的时候。**

  另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。

  可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）

#### 3.3.3 TCP 拥塞控制

我们之前提到 TCP 提供了流量控制，这是为了避免接收方的缓存被填满。

一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

在**网络出现拥堵**时，如果继续发送大量数据包，可能会**导致数据包时延、丢失**等，这时 TCP 就会**重传数据**，但是**重传就会导致网络的负担更重**，于是会**导致更大的延迟以及更多的丢包**，这个情况就会进入恶性循环被不断地放大....

所以，TCP 被设计成一个无私的协议，**当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量**，于是就有了**拥塞控制**，控制的目的就是**避免发送方的数据填满整个网络**。

> **区分拥塞控制和流量控制的目的**
>
> * 流量控制是为了避免接收方的缓存被填满。
> * 拥塞控制是为了避免整个网络的拥堵。

注意，TCP 的拥塞控制是针对发送方的，TCP 会在发送方维护一个**拥塞窗口**，它会根据网络的拥塞程度动态的调整。

那么如何知道网络存在拥堵？TCP 的做法很简单：只要发送方没有在规定时间内接收到 ACK 应答报文，也就是**发生了重传（超时重传或快速重传），就会认为网络出现了用拥塞**。

拥塞控制主要是基于如下算法：

- 慢启动
- 拥塞避免
- 拥塞发生
- 快速恢复

##### 3.3.3.1 慢启动

TCP 在刚建立连接完成后，首先会经历一个**慢启动**的过程。

cwnd 的长度定义为 MSS 的个数，初始时只能发送 1 个 MSS，**每当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**

- 连接建立完成后，一开始初始化 `cwnd = 1`，表示可以传一个 `MSS` 大小的数据。
- 当收到 1 个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个
- 当收到 2 个 ACK 确认应答后，cwnd 增加 2，于是就可以比之前多发 2 个，所以这一次能够发送 4 个
- 当这 4 个 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。

我们发现，慢启动过程实际上是一个**指数级的增长**。如下图所示：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331202317019.png" alt="image-20220331202317019" style="zoom:80%;" />

当然，这种增长不是永久的，**如果存在超时重传，则将会把 `cwnd` 重新置为 1，并且重新开始慢启动**，除此之外，**还会设置 `ssthresh`（慢启动阈值）的值置为上一个 cwnd 的一半**。

这一次慢启动时，当 `cwnd` < `ssthresh` 时，增长方式不变，**当 `cwnd` >= `ssthresh` 时，就会使用拥塞避免算法**。

##### 3.3.3.2 拥塞避免

前面说道，当拥塞窗口 `cwnd` 超过慢启动门限 `ssthresh` 就会进入拥塞避免算法。这意味着 cwnd 的值在上一次遇到拥塞的一半左右，也意味着离拥塞不远了，此时就要避免拥塞。

这个阶段中，**cwnd 的值一次只增加 1，无论收到多少个 ACK**，这时就会由指数级增长变为**线性增长**：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331210733130.png" alt="image-20220331210733130" style="zoom:67%;" />

##### 3.3.3.3 拥塞发生

当发生拥塞以后，就要根据重传的类型调整 ssthresh。

* 如果是**超时重传**，则和拥塞避免一样，**cwnd 变为 1，ssthresh 变为上一次 cwnd 的一半**。

  <img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331210916974.png" alt="image-20220331210916974" style="zoom:80%;" />

* 如果是**快速重传**，则意味着**存在冗余 ACK**，只丢了小部分包，此时 **cwnd 变为一半，ssthresh = cwnd，直接进入快速恢复算法**。

##### 3.3.3.4 快速恢复

快速恢复其实是可选的，具体看 TCP 的实现。

如果**没有实现快速恢复**，则在拥塞发生时触发快速重传后就会**重新开始拥塞避免**的线性增长。

而快速恢复一般的实现是：

* `cwnd = ssthresh + 3`
* 重传丢失的数据包
* 如果再收到重复的 ACK，那么 cwnd 增加 1
* 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明 冗余 ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331214520262.png" alt="image-20220331214520262" style="zoom:80%;" />

### 3.4 TCP 连接管理

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手来进行的，关闭连接则是通过四次挥手完成的**。

#### 3.4.1 三次握手

三次握手的过程如下图：

![image-20220331180713046](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331180713046.png)

1. 一开始，客户端和服务端都处于 `CLOSED` 状态。

2. 先是服务端主动监听某个端口，处于 `LISTEN` 状态。

3. 客户端随机初始化序号（`client_isn`），将此序号置于 TCP 首部的序号字段中，同时把 `SYN` 标志位置为 `1`，表示是 **SYN 报文**。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，**此报文不包含应用层数据**，之后客户端处于 `SYN-SENT` 状态。

   ![image-20220331181209195](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331181209195.png)

4. 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的序号字段中，其次把 TCP 首部的确认号字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，**该报文也不包含应用层数据**，之后服务端处于 `SYN-RCVD` 状态。

   ![image-20220331181542300](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331181542300.png)

5. 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次确认号字段填入 `server_isn + 1` ，最后把报文发送给服务端，**这次报文可以携带客户到服务器的数据**，之后客户端处于 `ESTABLISHED` 状态。

   ![image-20220331181714378](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331181714378.png)

6. 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

注意，**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**。

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。

我们可以使用 Linux 的 `netstat` 命令查看 TCP 连接状态，加上 `-napt` 选项，如图：

![image-20220707200101106](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220707200101106.png)

#### 3.4.2 三次握手相关问题

##### 3.4.2.1 为什么 TCP 每次建立连接前的序列号都要随机初始化，而不是从 0 开始？

主要原因有两个方面：

- **为了防止历史报文被下一个相同四元组的连接接收**（主要方面）；
- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

为了说明这一点，我们假设 seq 是从 0 开始的：

![image-20220424192748776](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220424192748776.png)

- 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，而此时服务端的进程重启了，于是就会发送 RST 报文来断开连接。
- 紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；
- **在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端**，刚好该数据包的**序列号正好是在服务端的接收窗口内**，所以该数据包会被服务端正常接收，就会**造成数据错乱**。

如果每次建立连接客户端和服务端的初始化序列号都不一样，就有**大概率会使得历史报文的序列号不在对方的接收窗口内**，从而很大程度上避免了历史报文。注意，是大概率，而不是一定，因为随机初始化的序列号也有极小的概率会碰到这个问题。

##### 3.4.2.2 ISN（序列号）生成算法？

ISN 的随机生成算法原理是：ISN = M + F，其中：

- M 是一个计时器，这个计时器每隔 4 毫秒加 1。
- F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值，要保证 hash 算法不能被外部轻易推算得出。

由于生成的随机数是会基于时钟计时器递增的，因此基本不可能会随机成一样的初始化序列号。

##### 3.4.2.3 为什么是三次握手？不是两次、四次？

答案：

* 三次握手才能确保连接建立，同步双方序列号

- 三次握手才可以阻止重复历史连接的初始化

不使用两次和四次握手的原因是：

- 两次握手：无法防止历史连接的建立，同时也并不能确保连接一定能成功建立，会造成双方资源的浪费，也无法可靠的同步双方序列号
- 四次握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数

###### 3.4.2.3.1 原因 1：确保连接建立

三次握手最初的目的就是为了确保连接建立。

假设两次握手就能建立一个连接，则意味着服务端发送 SYN + ACK 之后就会进入 ESTABLISHED 状态，这个时候服务器的操作系统就已经为这条连接分配资源了。

这时，假设客户端挂掉了，接下来的很长一段时间内服务器都不会收到任何消息，直到超时连接自动关闭。

要知道，**端口号的数量是有限的，如果一个 TCP 连接长期占用端口号，在高并发的情况下甚至会导致无端口号可用的情况**。

因此，必须要用三次握手确保以下三件事：

1. **SYN 确保客户端能够正常的发送消息**。
2. **SYN + ACK 确保服务器能够正常的接受和发送消息**。
3. **ACK 确保客户端能够正常的接受消息**。

如果能够确保正常接受消息，就能确保它收到了初始序列号，初始序列号也就这样同步了。

###### 3.4.2.3.2 原因 2：避免历史连接

三次握手的另一个主要原因是为了**防止旧的重复连接初始化造成混乱**。

我们考虑一个场景，客户端先发送了 SYN（seq = 90） 报文，但是被网络阻塞了，服务端并没有收到，接着客户端又重新发送了 SYN（seq = 100） 报文（注意不是重传 SYN，重传的 SYN 的序列号是一样的），但是此时 SYN（seq = 90） 报文到来了，这就会形成历史连接。

来看看三次握手是如何阻止历史连接的：

![image-20220331182605498](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331182605498.png)

客户端连续发送多次 SYN 建立连接的报文，在**网络拥堵**情况下：

- 一个旧 SYN 报文比最新的 SYN 报文早到达了服务端；
- 那么此时服务端就会回一个 `SYN + ACK` 报文给客户端；
- 客户端收到后可以根据自身的上下文，**判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 `RST` 报文给服务端**，表示中止这一次连接。

**两次握手则不能阻止历史连接，因为只有两次握手，旧 SYN 比新 SYN 到达之后，连接接收方直接进入  `ESTABLISHED` 状态**，即使后面连接发起方发送了 RST 组织本次连接，也浪费了接收方的资源（和原因 1 类似）。

##### 3.4.2.4 握手丢失会发生什么？

###### 3.4.2.4.1 第一次握手丢失

客户端第一个发的就是 SYN 报文，然后进入到 `SYN_SENT` 状态。

如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发**超时重传**机制，重传 SYN 报文。

**如果一直重传，一直收不到呢？**其实，操作系统都会给重传设置一个最大此时，超过这个最大次数就不会再重传了。在 Linux 里，客户端的 SYN 报文最大重传次数由 `tcp_syn_retries` 内核参数控制，这个参数是可以自定义的，默认值一般是 5。

通常，第一次超时重传的时间阈值是 1 秒，第二次是 2 秒，第三次是 4 秒，第四次是 8 秒，第五次是 16 秒。没错，**每次超时的时间是上一次的 2 倍**。

**当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接**。

###### 3.4.2.4.2 第二次握手丢失

当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 `SYN_RCVD` 状态。

第二次握手有两个作用：

* 第二次握手包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是**客户端就会触发超时重传机制，重传 SYN 报文**。
* 第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。如果第二次握手丢失了，服务端就收不到第三次握手，于是**服务端这边也会触发超时重传机制，重传 SYN-ACK 报文**。

在 Linux 下，SYN-ACK 报文的最大重传次数由 `tcp_synack_retries`内核参数决定，默认值是 5。

总结：**第二次握手丢失后，客户端和服务端都会重传**。

###### 2.4.2.4.3 第三次握手丢失

客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以**当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文**，直到收到第三次握手，或者达到最大重传次数。

> **注意**
>
> **ACK 报文是不会重传的**，当 ACK 丢失了，发送方会认为包丢了，于是就自己重传报文；接收方则是认为 ACK 发出去了就是确认了，因此就不管了。

##### 3.4.2.5 SYN 洪泛攻击

假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务器不能为正常用户服务。

> **提示**
>
> 半连接队列是 Linux 建立的为未完全握手的连接而建立的队列，我们会在之后详细介绍它。

解决方式：

1. 通过**修改 Linux 内核参数**，控制队列大小和当队列满时应做什么处理。
   * 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值的参数是： `net.core.netdev_max_backlog`。
   * 设置 SYN_RCVD 状态连接的最大个数的参数是：`net.ipv4.tcp_max_syn_backlog`。
   * 设置**超出处理能力时，对新的 SYN 直接回报 RST，丢弃连接**的参数是：`net.ipv4.tcp_abort_on_overflow`。
2. **使用 `tcp_syncookies`** 的方式可以应对 SYN 攻击。
   - 当  SYN 队列满之后，后续服务器收到 SYN 包，不进入 SYN 队列；
   - **计算出一个 cookie 值**，再以接下来要发送的 SYN + ACK 中的**序列号**的形式返回客户端，此时**发送回去的是 cookie - 1**。
   - 服务端接收到客户端的 ACK 时，服务器会检查这个 ACK 包中的确认号，此时应该等于上一步计算出来的 cookie 值。

#### 3.4.3 四次挥手

四次挥手的过程如下图：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331190617897.png" alt="image-20220331190617897" style="zoom:80%;" />

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态。
- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。

你可以看到，每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

#### 3.4.4 四次挥手相关问题

##### 3.4.4.1 为什么挥手需要四次？

四次挥手分别有不一样的作用：

- 关闭连接时，客户端向服务端发送 `FIN`，仅仅**表示客户端不再发送数据了但是还能接收数据**。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而**服务端可能还有数据需要处理和发送**。
- 当服务器发送 `FIN` 时，表示**服务器数据处理完毕，可以关闭连接，此后服务器不会再发送数据**。
- 客户端收到服务器的 `FIN` 报文后，回复 `ACK` 表示**同意关闭连接**。

从上面过程可知，**服务端通常需要等待完成数据的发送和处理**，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。

##### 3.4.4.2 挥手丢失会发生什么？

###### 3.4.4.2.1 第一次挥手丢失

如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会**触发超时重传机制，重传 FIN 报文**，重发次数由 `tcp_orphan_retries` 参数控制。

当客户端重传 FIN 报文的次数超过 `tcp_orphan_retries` 后，就不再发送 FIN 报文，直接进入到 `close` 状态强行关闭连接。

###### 3.4.4.2.2 第二次挥手丢失

第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。

###### 3.4.4.2.3 第三次挥手丢失

服务端发送 FIN 报文后，期望接到一个 ACK，如果 FIN 丢失，导致迟迟收不到这个 ACK，服务端就会**重传 FIN 报文**，重传次数仍然由 `tcp_orphan_retries` 参数控制，这与客户端重传 FIN 报文的重传次数控制方式是一样的。

###### 3.4.4.2.4 第四次挥手丢失

如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 `tcp_orphan_retries` 参数控制。

##### 3.4.4.3 为什么需要 `TIME_WAIT`？

当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 `TIME_WAIT` 状态。`TIME_WAIT` 状态会持续 2MSL 后才会进入关闭状态。

服务端（被动关闭方）没有收到 ACK 报文前，还是处于 `LAST_ACK` 状态。如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文。

**如果没有 `TIME_WAIT` 而是直接进入 `CLOSED`，那么就会导致第四次挥手丢失后，没办法检测超时重传，导致服务端一直处于 `LAST_ACK` 状态**。

当然，`TIME_WAIT` 不能过多，多的 `TIME_WAIT` 状态主要的危害有两种：

- 第一是内存资源占用
- 第二是对端口资源的占用，一个 TCP 连接至少消耗发起连接方的一个本地端口

##### 3.4.4.4 `TIME_WAIT` 时长为什么是 2MSL？

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 **IP 数据报可以经过的最大路由数**，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

MSL 与 TTL 的区别在于：MSL 的单位是时间，而 TTL 是经过路由跳数。

所以，**MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了。

**2MSL 时长能够至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

#### 3.4.5 TCP 半连接队列和全连接队列

这是 Linux 在实现 TCP 时引入的机制，在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列
- 全连接队列，也称 Accept 队列

服务端收到客户端发起第一次握手后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来**。

这个过程如下图所示：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220331193313347.png" alt="image-20220331193313347" style="zoom:80%;" />

具体细节如下图所示：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220424174939371.png" alt="image-20220424174939371" style="zoom:80%;" />

队列的大小非常重要，因为这决定了服务器的并发能力，幸好，Linux 为我们提供了一些参数，以调节队列的大小。

> **backlog**
>
> 在服务端 Socket 调用 `listen` 时，有一个参数名为 `backlog`，这个参数的设置对 TCP 队列来说至关重要。
>
> 在早期 Linux 的内核中，`backlog` 是 SYN 队列大小；在 Linux 内核 2.2 之后，`backlog` 变成 Accept 队列的大小，**所以现在通常认为 backlog 是与 accept 队列有关**。
>
> **但是，上限值是内核参数 somaxconn 的大小，也就说 Accpet 队列长度 = min(backlog, somaxconn)**。在设置参数时一定要注意 backlog 和 somaxconn 的取值。

#### 3.4.6 TCP Fast Open

在 Linux 3.7 内核版本中，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。

TCP Fast Open 的全流程如下图所示：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220424233303791.png" alt="image-20220424233303791" style="zoom:80%;" />

- 在第一次建立连接的时候，服务端在第二次握手产生一个 `Cookie` （已加密）并通过 SYN + ACK 包一起发给客户端，于是客户端就会缓存这个 `Cookie`，所以第一次发起 HTTP GET 请求的时候，还是需要 2 个 RTT 的时延；
- 在下次请求的时候，客户端在 SYN 包带上 `Cookie` 发给服务端，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；

### 3.5 TCP 粘包问题

TCP 协议是流式协议，会出现粘包问题。

所谓流式协议，即**协议的内容是像流水一样的字节流，内容与内容之间没有明确的分界标志**，需要我们人为地去给这些协议划分边界。

解决方式也就是划分边界，一般有三种方式分包的方式：

- **固定长度的消息**：这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。

  但是这种方式灵活性不高，实际中很少用。

- **特殊字符作为边界**：我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。

  **HTTP** 使用的方法就是设置特殊字符作为边界。

- **自定义消息结构**：我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

### 3.6 TCP 保活机制（Keep Alive）

如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

- 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端,，对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，这个工作是在内核完成的。

![image-20220424234427060](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220424234427060.png)

如果没有开启保活机制，且双方一直没有数据交互的情况下，如果客户端的主机崩溃了，会发生什么？

答案是，服务端是**无法感知到**的，没有数据交互的情况下，**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程。

### 3.7  TCP 其他问题

#### 3.7.1 已建立连接的 TCP，收到 SYN 会发生什么？

假设有如下场景：一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 Establish 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？

这个场景中，客户端的 IP、服务端的 IP、目的端口号都没有发生变化，所以这个问题关键要看客户端发送的 SYN 报文中的源端口是否和上一次连接的源端口相同：

* 如果源端口号也相同：也就是处于 Establish 状态的服务端莫名其妙收到了客户端的 SYN 报文，此时的 SYN 报文的 Seq 其实是个随机数，这意味着对于服务器来讲，Seq 是乱序的，此时服务端就会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 **Challenge ACK**。

  **客户端收到这个 Challenge ACK，发现序列号并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接**。

* 如果源端口号不同：这 TCP 认为这是一个新的连接，于是就会使用正常的三次握手来建立连接。

  此时，老的连接由于长时间没有消息交互，就会触发 TCP 保活机制。

#### 3.7.2 如果 TCP 连接已经建立了，且没有开启 Keep Alive，此时使用命令强制杀掉客户端进程，会发生什么？如果是直接断电关机呢？

如果 TCP 连接已经建立了，此时**杀掉客户端进程，操作系统是可以检测到这个情况的，会代替进程发起四次挥手**。

如果是直接断电关机，此时操作系统都来不及发起挥手，此时**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程。

#### 3.7.3 TIME_WAIT 状态下收到 SYN 会怎么样？

假如发起挥手的一方的 TIME_WAIT 比较长，另一方已经 CLOSE 掉了，并且重新发起了握手，此时会怎么样呢？

这个问题，关键是要看 SYN 的**序列号和时间戳是否合法**，因为处于 TIME_WAIT 状态的连接收到 SYN 后，会判断 SYN 的序列号和时间戳是否合法，然后根据判断结果的不同做不同的处理。

> **合法 SYN 与非法 SYN**
>
> 客户端的 SYN 的序列号比服务端期望下一个收到的序列号要**大**，**并且** SYN 的时间戳比服务端最后收到的报文的时间戳要**大**，这样的 SYN 就是合法 SYN。
>
> 客户端的 SYN 的序列号比服务端期望下一个收到的序列号要**小**，**或者** SYN 的时间戳比服务端最后收到的报文的时间戳要**小**，这样的 SYN 就是非法 SYN。
>
> 上面 SYN 合法判断是基于双方都开启了 TCP 时间戳机制的场景，如果双方都没有开启 TCP 时间戳机制，则 SYN 合法判断如下：
>
> - **合法 SYN**：客户端的 SYN 的序列号比服务端期望下一个收到的序列号要**大**。
> - **非法 SYN**：客户端的 SYN 的序列号比服务端期望下一个收到的序列号要**小**。

* 如果收到合法的 SYN，**就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程**。
* 如果处于 TIME_WAIT 状态的连接收到非法的 SYN 后，就会**再回复一个第四次挥手的 ACK 报文，**对方收到后，发现并不是自己期望收到确认号（ack num），就**回 RST 报文**，从而中断连接。

#### 3.7.4 TIME_WAIT 状态下收到 RST 会怎么样？

处于 TIME_WAIT 状态的连接，收到 RST 会断开连接吗？

会不会断开，关键看 `net.ipv4.tcp_rfc1337` 这个内核参数（默认情况是为 0）：

- 如果这个参数设置为 0， 收到 RST 报文会提前结束 TIME_WAIT 状态，释放连接。
- 如果这个参数设置为 1， 就会丢掉 RST 报文。

### 3.8  TCP 的缺陷

TCP 通过序列号、确认应答、超时重传、流量控制、拥塞控制等方式实现了可靠传输，看起来它很完美，事实真的是这样吗？TCP 就没什么缺陷吗？

答案自然是否定的，TCP 主要有四个方面的缺陷：

主要有四个方面：

- 升级 TCP 的工作很困难；
- TCP 建立连接的延迟；
- TCP 存在队头阻塞问题；
- 网络迁移需要重新建立 TCP 连接；

#### 3.8.1 升级 TCP 的工作很困难

TCP 协议是诞生在 1973 年，至今 TCP 协议依然还在实现更多的新特性。

但是 **TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核**。

而升级内核这个工作是很麻烦的事情，麻烦的事情不是说升级内核这个操作很麻烦，而是由于内核升级涉及到底层软件和运行库的更新，我们的服务程序就需要回归测试是否兼容新的内核版本，所以服务器的内核升级也比较保守和缓慢。

很多 TCP 协议的新特性，都是需要客户端和服务端同时支持才能生效的，比如 TCP Fast Open 这个特性，虽然在 2013 年就被提出了，但是 Windows 很多系统版本依然不支持它，这是因为 PC 端的系统升级滞后很严重，Windows Xp 现在还有大量用户在使用，尽管它已经存在快 20 年。

所以，即使 TCP 有比较好的特性更新，也很难快速推广，用户往往要几年或者十年才能体验到。

#### 3.8.2 TCP 建立连接的延迟

基于 TCP 实现的应用协议，都是需要先建立三次握手才能进行数据传输，比如 HTTP 1.0/1.1、HTTP/2、HTTPS。

现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，还需要经过 TLS 四次握手后，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。

![image-20220707232940374](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220707232940374.png)

TCP 三次握手的延迟可以被 TCP Fast Open 解决，但是它需要服务端和客户端的操作系统同时支持才能体验到，这一点我们刚刚已经提过了，就不再赘述了。

#### 3.8.3 TCP 存在队头阻塞问题

TCP 是字节流协议，**TCP 层必须保证收到的字节数据是完整且有序的**，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。如下图：

![image-20220707233109027](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220707233109027.png)

图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 `packet #3` 在网络中丢失了，即使 `packet #4-6` 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 `packet #3` 重传后，接收方的应用层才可以从内核中读取到数据。

#### 3.8.4 网络迁移需要重新建立 TCP 连接

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。

而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

## 4. QUIC

刚刚我们提到 TCP 其实也有比较大的缺陷，要解决 TCP 的这些缺陷，就得另起炉灶，QUIC（Quick UDP Internet Connection）就是这样一个协议，它基于 UDP 实现了可靠传输，同时还解决了 TCP 的这些缺陷。

理论上来说，QUIC 应该是应用层协议，但是它所提供的服务又是运输层的服务，所以被认为是运输层协议，但是我们更多的还是**把 QUIC 当作应用层和运输层 UDP 之间的一层协议**。

### 4.1 QUIC 的可靠传输实现

要基于 UDP 实现的可靠传输协议，那么就要在应用层下功夫，也就是要设计好协议的头部字段。

拿 HTTP/3 举例子，在 UDP 报文头部与 HTTP 消息之间，共有 3 层头部：

![image-20220708085045376](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708085045376.png)

#### 4.1.1 Packet Header

Packet Header 首次建立连接时和日常传输数据时使用的 Header 是不同的，其中：

- Long Packet Header 用于首次建立连接。
- Short Packet Header 用于日常传输数据。

如下图（只画出了重要的字段）：

![image-20220708085132473](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708085132473.png)

QUIC 也是需要**三次握手**来建立连接的，主要目的是为了**协商连接 ID**。

协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。所以，你可以看到日常传输数据的 Short Packet Header 不需要在传输 Source Connection ID 字段了，只需要传输 Destination Connection ID。

##### 4.1.1.1 Packet Number

Short Packet Header 中的 `Packet Number` 是每个报文独一无二的编号，它是**严格递增**的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。

![image-20220708085246689](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708085246689.png)

这么做有两个好处：

- **可以更加精确计算 RTT**，没有 TCP 重传的歧义性问题；
- **可以支持乱序确认**，因为丢包重传将当前窗口阻塞在原地，而 TCP 必须是顺序确认的，丢包时会导致窗口不滑动；

我们一一说明。

首先我们看看 TCP 的问题：

![image-20220708085749851](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708085749851.png)

当 TCP 发生超时重传后，客户端发起重传，然后接收到了服务端确认 ACK 。由于客户端原始报文和重传报文序列号都是一样的，那么服务端针对这两个报文回复的都是相同的 ACK。这样的话，**客户端就无法判断出是原始报文的响应还是重传报文的响应**，这样在计算 RTT（往返时间） 时应该选择从发送原始报文开始计算，还是重传原始报文开始计算呢？

- 如果算成原始报文的响应，但实际上是重传报文的响应（上图左），会导致采样 RTT 变大；
- 如果算成重传报文的响应，但实际上是原始报文的响应（上图右），又很容易导致采样 RTT 过小；

RTO 是基于 RTT 来计算的（之前的学习中说过了），那么如果 RTT 计算不精准，那么 RTO （超时时间）也会不精确，这样可能导致重传的概率事件增大。

QUIC 的 Packet Number 严格递增就解决了这个问题，这样就能更加精确计算出报文的 RTT：

![image-20220708085933332](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708085933332.png)

另外，**QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像 TCP 那样必须有序确认，QUIC 支持乱序确认，当数据包 Packet N 丢失后，只要有新的已接收数据包确认，当前窗口就会继续向右滑动**。

待发送端获知数据包 Packet N 丢失后，会将需要重传的数据包放到待发送队列，重新编号比如数据包 Packet N + M 后重新发送给接收端，对重传数据包的处理跟发送新的数据包类似，这样就不会因为丢包重传将当前窗口阻塞在原地，从而解决了队头阻塞问题。

> 那么细心的读者可能就要问了，QUIC 是如何保持包的顺序的呢？这其实要依靠 QUIC Frame Header，我们很快就会降到这一点。

#### 4.1.2 QUIC Frame Header

一个 Packet 报文中可以存放多个 QUIC Frame：

![image-20220708092115418](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708092115418.png)

每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，自然格式也不同。

我这里只举例 Stream 类型的 Frame 格式，Stream 可以认为就是一条 HTTP 请求，它长这样：

![image-20220708092131617](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708092131617.png)

- Stream ID：多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别，类似于 HTTP2 的 Stream ID；
- Offset：类似于 TCP 协议中的 Seq 序号，**保证数据的顺序性和可靠性**；
- Length：指明了 Frame 数据的长度。

在前面介绍 Packet Header 时，说到 Packet Number 是严格递增，即使重传报文的 Packet Number 也是递增的，既然重传数据包的 Packet N + M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢？

所以引入 Frame Header 这一层，**通过 Stream ID + Offset 字段信息实现数据的有序性**，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。

举个例子，下图中，数据包 Packet N 丢失了，后面重传该数据包的编号为 Packet N + 2，**丢失的数据包和重传的数据包 Stream ID 与 Offset 都一致，说明这两个数据包的内容一致**。这些数据包传输到接收端后，接收端能根据 Stream ID 与 Offset 字段信息将 Stream x 和 Stream x+y 按照顺序组织起来，然后交给应用程序处理。

![image-20220708092152334](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708092152334.png)

总的来说，**QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装**，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。

### 4.2 QUIC 是怎么样解决队头阻塞的？

#### 4.2.1 TCP 的队头阻塞

TCP 队头阻塞的问题要从两个角度看，一个是**发送窗口的队头阻塞**，另外一个是**接收窗口的队头阻塞**。

1. 发送窗口的队头阻塞。

   TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。

   比如，下图中发送窗口内所有内容都已经被发送出去了，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。

   ![image-20220709215943362](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220709215943362.png)

   此后如果发送方收到了 32 ~ 36 的 ACK，那么窗口就能往前滑动到 56，就又可以发送一些数据了。

   **但是如果某个数据报文丢失或者其对应的 ACK 报文在网络中丢失，会导致发送方无法移动发送窗口，这时就无法再发送新的数据**，只能超时重传这个数据报文，直到收到这个重传报文的 ACK，发送窗口才会移动，继续后面的发送行为。

   此时，重传的报文之前的所有报文都被 ACK 确认了，发送窗口移动到该重传的报文之前，因此重传的报文看起来像队列头部，所以叫做队头阻塞。

2. 接收窗口的队头阻塞。

   接收方收到的数据范围必须在接收窗口范围内，如果收到超过接收窗口范围的数据，就会丢弃该数据。

   比如：

   ![image-20220709220329483](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220709220329483.png)

   此时，如果窗口已满，但是收到了 52 字节的数据，那么就会将其丢弃。

   **当接收窗口收到有序数据时，接收窗口才能往前滑动**，然后那些已经接收并且被确认的有序数据就可以被应用层读取。

   所以，假设上图先收到了 33 ~ 44 字节的数据，窗口也不能滑动，因为 32 由于某种原因丢失了，只能等待重传。

   此时等待重传的报文依然在队列头部，因此也叫做队头阻塞。

HTTP/2 使用了 Stream 机制，这使得 HTTP/2 可以在一个 TCP 请求中并发多个 Stream，但是这也意味着**一旦发生了数据丢失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞**。

#### 4.2.2 没有队头阻塞的 QUIC

QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。

但是 **QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口**。

假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream，与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

![image-20220709223529280](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220709223529280.png)

### 4.3 QUIC 对拥塞控制的改进

QUIC 协议当前默认使用了 TCP 的 Cubic 拥塞控制算法，也就是我们熟知的慢开始、拥塞避免、快重传、快恢复策略，同时也支持 CubicBytes、Reno、RenoBytes、BBR、PCC 等拥塞控制算法，相当于将 TCP 的拥塞控制算法照搬过来了。

那么既然是照搬 TCP 的，QUIC 又是如何改进 TCP 的拥塞控制算法的呢？

QUIC 是处于应用层和运输层之间的，**在这个层面就能实现不同的拥塞控制算法而不需要依赖操作系统**，也就不需要内核的支持。

这是一个飞跃，因为传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果。而内核和操作系统的部署成本非常高，升级周期很长，所以 TCP 拥塞控制算法迭代速度是很慢的。而 **QUIC 可以很方便的更新，QUIC 的拥塞控制算法就可以有较快的迭代速度**。

TCP 更改拥塞控制算法是对系统中所有应用都生效，无法根据不同应用设定不同的拥塞控制策略。但是因为 QUIC 处于应用层，所以就**可以针对不同的应用设置不同的拥塞控制算法**，这样灵活性就很高了。

### 4.4 QUIC 更快的连接建立

对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手（1RTT），再 TLS 握手（2RTT），所以需要 3 RTT 的延迟才能传输数据，就算 Session 会话服用，也需要至少 2 个 RTT。

HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的连接 ID。

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是**QUIC 内部包含了 TLS**，它在自己的帧会携带 TLS 里的“记录”，再加上 **QUIC 使用的是 TLS1.3**，因此仅需 1 个 RTT 就可以同时完成建立连接与密钥协商，甚至**在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0 RTT 的效果**。

![image-20220708092449955](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220708092449955.png)

### 4.5 QUIC 是如何无损迁移连接的？

之前我们说到过，基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。

QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

### 4.6 QUIC 流量控制

TCP 流量控制是通过让接收方告诉发送方，它（接收方）的接收窗口有多大，从而让发送方根据接收方的实际接收能力控制发送的数据量。

QUIC 实现流量控制的方式：

- 通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。
- 通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。

在前面说到，TCP 的接收窗口在收到有序的数据后，接收窗口才能往前滑动，否则停止滑动；TCP 的发送窗口在收到对已发送数据的顺序确认 ACK后，发送窗口才能往前滑动，否则停止滑动。

QUIC 是基于 UDP 传输的，而 UDP 没有流量控制，因此 QUIC 实现了自己的流量控制机制，QUIC 的滑动窗口滑动的条件跟 TCP 有一点差别，但是同一个 Stream 的数据也是要保证顺序的，不然无法实现可靠传输，因此同一个 Stream 的数据包丢失了，也会造成窗口无法滑动。

**QUIC 的 每个 Stream 都有各自的滑动窗口，不同 Stream 互相独立，队头的 Stream A 被阻塞后，不妨碍 StreamB、C的读取**。而对于 HTTP/2 而言，所有的 Stream 都跑在一条 TCP 连接上，而这些 Stream 共享一个滑动窗口，因此同一个Connection内，Stream A 被阻塞后，StreamB、C 必须等待。

QUIC 实现了两种级别的流量控制，分别为 Stream 和 Connection 两种级别：

- **Stream 级别的流量控制**：Stream 可以认为就是一条 HTTP 请求，每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。

  QUIC 的滑动窗口通常是下面这样的：

  ![image-20220709224943101](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220709224943101.png)

  接收窗口右滑的条件是：当图中的绿色部分数据超过最大接收窗口的一半。此时，最大接收窗口向右移动，接收窗口的右边界也向右扩展。

  ![image-20220709225149690](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220709225149690.png)

  绿色部分的数据是已收到的顺序的数据，**如果中途丢失了数据包，导致绿色部分的数据没有超过最大接收窗口的一半，那接收窗口就无法滑动了**，这个只影响同一个 Stream，其他 Stream 是不会影响的，因为每个 Stream 都有各自的滑动窗口。

- **Connection 流量控制**：限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量。

  对于 Connection 级别的流量窗口，其接收窗口大小就是各个 Stream 接收窗口大小之和。

  ![image-20220709225315306](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220709225315306.png)
