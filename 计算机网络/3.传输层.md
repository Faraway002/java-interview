# 传输层

运输层位于应用层和网络层之间，是 OSI 分层体系中的第四层，同时也是网络体系结构的重要部分。运输层主要负责网络上的端到端通信。

运输层为运行在不同主机上的应用程序之间的通信起着至关重要的作用。

## 概述

计算机网络的运输层非常类似于高速公路，高速公路负责把人或者物品从一端运送到另一端，而计算机网络的运输层则负责把报文从一端运输到另一端，这个端指的就是端系统。

在运输层运输报文的过程中，会遵守一定的协议规范，比如一次传输的数据限制、选择什么样的运输协议等。**运输层实现了让两个互不相关的主机进行逻辑通信的功能，看起来像是让两个主机相连一样，实际上主机可能相距十万八千里**。

在数据传输到运输层后，运输层协议会为其附上首部。这个时候的分组在运输层中也称为**报文段（segment）**。运输层一般会将报文段进行分割，分割成为较小的块，为每一块加上运输层首部并将其向目的地发送。

可选的运输层协议主要有 TCP 和 UDP，关于这两种运输协议的选择及其特性也是我们着重探讨的重点。

* TCP 叫做传输控制协议（Transmission Control Protocol），通过名称可以大致知道 TCP 协议有控制传输的功能，主要体现在其可控，可控就表示着可靠，确实是这样的，TCP 为应用层提供了一种**可靠的、面向连接**的服务，它能够将分组可靠的传输到服务端。

* UDP 叫做用户数据报协议（User Datagram Protocol），通过名称可以知道 UDP 把重点放在了数据报上，它为应用层提供了一种无需建立连接就可以直接发送数据报的方法。

所以，准确来说，**TCP 的分组称作报文段，UDP 的分组称作数据报**。

### 套接字编程

在 TCP 或者 UDP 发送具体的报文信息前，需要先经过一扇“门”，这个门就是套接字（socket），**套接字向上连接着应用层，向下连接着网络层**。

使用 TCP 或 UDP 通信时，会广泛用到套接字的 API，使用这套 API 设置 IP 地址、端口号，实现数据的发送和接收。

![image-20220329151048469](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329151048469.png)

#### 套接字类型

套接字的主要类型有三种，下面我们分别介绍一下

- 数据报套接字：数据报套接字提供一种无连接的服务，而且并不能保证数据传输的可靠性。数据有可能在传输过程中丢失或出现数据重复，且无法保证顺序地接收到数据。

  数据报套接字使用 UDP 进行数据的传输。由于数据报套接字不能保证数据传输的可靠性，对于有可能出现的数据丢失情况，需要在程序中做相应的处理。

- 流套接字：流套接字用于提供面向连接、可靠的数据传输服务。能够保证数据的可靠性、顺序性。流套接字之所以能够实现可靠的数据服务，原因在于其使用了 TCP。

- 原始套接字: 原始套接字允许直接发送和接收 IP 数据包，而无需任何特定于协议的传输层格式，原始套接字可以读写内核没有处理过的 IP 数据包。

#### 套接字通信流程

在计算机网络中，要想实现通信，必须至少需要两个端系统，至少需要一对两个套接字才行。下面是套接字的通信过程。

![image-20220424174626103](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220424174626103.png)

1. 服务端和客户端初始化 `socket`，得到文件描述符；

2. 服务端调用 `bind`，将绑定在 IP 地址和端口;
3. 服务端调用 `listen`，进行监听；
4. 服务端调用 `accept`，等待客户端连接；
5. 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
6. 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
7. 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
8. 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。所以，监听的 socket 和真正用来传送数据的 socket，是两个socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

### IP 简述

在仔细探究运输层协议之前，我们先简要了解一下 IP 协议。

IP 是 Internet Protocol（网际互连协议）的缩写，是 TCP/IP 体系中的网络层协议。设计 IP 的初衷主要想解决两类问题：

- 提高网络扩展性：实现大规模网络互联。
- 对应用层和链路层进行解藕，让二者独立发展。

IP 是整个 TCP/IP 协议族的核心，也是构成互联网的基础。为了实现大规模网络的互通互联，IP 更加注重适应性、简洁性和可操作性，并在可靠性做了一定的牺牲。IP 不保证分组的**交付时限和可靠性**，所传送分组有可能出现**丢失、重复、延迟或乱序**等问题。

IP 会使用 IP 地址来标识主机，每台主机都会被分配一个唯一的 IP 地址，而端口号则是表示一台计算机中的特定进程所提供的服务，换句话说用于标识一个进程。

端口号是 16 位的非负整数，它的范围是 0 - 65535 之间，这个范围会分为三种不同的端口号段，由 Internet 号码分配机构 IANA 进行分配：

- 周知/标准端口号，它的范围是 0 - 1023
- 注册端口号，范围是 1024 - 49151
- 私有端口号，范围是 49152 - 65535

仅凭一方的 IP 地址 + 端口号来识别一个报文段是不够的，因此通常会使用 `(源 IP 地址, 源端口号, 目的 IP 地址, 目的端口号)` 的一个四元组来标识，这些也是**多路分解和多路复用**的基础。

### 多路复用与多路分解

* 将运输层报文段中的数据交付到正确的套接字的工作称为**多路分解**。
* 在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息从而生成报文段，然后将报文段传递到网络层，所有这些工作被称为**多路复用**。

多路复用和多路分解又分为无连接的多路复用/多路分解和面向连接的多路复用/多路分解。

#### 无连接的多路复用和多路分解

无连接套接字的标识是一个二元组，仅包含目的 IP 地址和目的端口号。所以，如果两个 UDP 报文段有不同的源 IP 地址和/或**相同的源端口号**，但是具有相同的目的 IP 地址和目的端口号，那么这两个报文会通过套接字定位到相同的目的进程。

源端口号也是很重要的，这是因为源端口号会作为返回地址的一部分，即当 B 需要回发一个报文段给 A 时，B 需要从 A 到 B 中的源端口号取值，如下图所示：

![image-20220329154530544](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329154530544.png)

#### 面向连接的多路复用与多路分解

如果说无连接的多路复用和多路分解指的是 UDP 的话，那么面向连接的多路复用与多路分解指的是 TCP 了，TCP 和 UDP 在报文结构上的差别是，UDP 是一个二元组而 TCP 是一个四元组，即**源 IP 地址、目标 IP 地址、源端口号、目标端口号** ，这个我们上面也提到了。当一个 TCP 报文段从网络到达一台主机时，这个主机会根据这四个值拆解到对应的套接字上。

![image-20220329154823948](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329154823948.png)

上图显示了面向连接的多路复用和多路分解的过程，图中主机 C 向主机 B 发起了两个 HTTP 请求，主机 A 向主机 C 发起了一个 HTTP 请求，主机 A、B、C 都有自己唯一的 IP 地址，当主机 C 发出 HTTP 请求后，主机 B 能够分解这两个 HTTP 连接，因为主机 C 发出请求的两个源端口号不同，所以对于主机 B 来说，这是两条请求，主机 B 能够进行分解。对于主机 A 和主机 C 来说，这两个主机有不同的 IP 地址，所以对于主机 B 来说，也能够进行分解。

## UDP

UDP 的全称是用户数据报协议，UDP 为应用程序提供了一种**无需建立连接**就可以发送封装的 IP 数据包的方法。如果应用程序开发人员选择的是 UDP 而不是 TCP 的话，那么该应用程序相当于就是和 IP 直接打交道的。

从应用程序传递过来的数据，会附加上多路复用/多路分解的源和目的端口号字段，以及其他字段，然后将形成的报文传递给网络层，网络层将运输层报文段封装到 IP 数据报中，然后尽力而为的交付给目标主机。最关键的一点就是，使用 UDP 协议在将数据报传递给目标主机时，**发送方和接收方的运输层实体间是没有握手的**。正因为如此，UDP 被称为是无连接的协议。

### UDP 的特点

UDP 协议一般作为流媒体应用、语音交流、视频会议所使用的传输层协议，DNS 协议底层也使用了 UDP 协议，这些应用或协议之所以选择 UDP 主要是因为以下这几点：

- **速度快**：采用 UDP 协议时，只要应用进程将数据传给 UDP，UDP 就会将此数据打包进 UDP 报文段并立刻传递给网络层。而 TCP 有拥塞控制的功能，它会在发送前判断互联网的拥堵情况，如果互联网极度阻塞，那么就会抑制 TCP 的发送方。使用 UDP 的目的就是希望实时性。
- **无须建立连接**：TCP 在数据传输之前需要经过三次握手的操作，而 UDP 则无须任何准备即可进行数据传输。因此 UDP 没有建立连接的时延。
- **无连接状态**：TCP 需要在端系统中维护连接状态，连接状态包括接收和发送缓存、拥塞控制参数以及序号和确认号的参数，在 UDP 中没有这些参数，也没有发送缓存和接受缓存。因此，某些专门用于某种特定应用的服务器当应用程序运行在 UDP 上，一般能支持更多的活跃用户
- **分组首部开销小**：每个 TCP 报文段都有 20 字节的首部开销，而 UDP 仅仅只有 8 字节的开销。

并不是所有使用 UDP 的应用都是不可靠的，应用程序完全可以基于 UDP 自己实现可靠的数据传输，比如 HTTP/3 使用的 QUIC 协议。

### UDP 的报文结构

每个 UDP 报文分为 UDP 报文头和 UDP 数据区两部分。报文头由 4 个 16 位长（2 字节）字段组成，分别说明该报文的源端口、目的端口、报文长度和校验和：

![image-20220329155637134](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329155637134.png)

- 源端口号：这个字段占据 UDP 报文头的前 16 位，通常包含发送数据报的应用程序所使用的 UDP 端口。接收端的应用程序利用这个字段的值作为发送响应的目的地址。

  这个字段是可选项，有时不会设置源端口号，没有源端口号就默认为 0 ，通常用于不需要返回消息的通信中。

- 目标端口号：表示接收端端口，字段长为 16 位

- 长度：该字段占据 16 位，表示 UDP 数据报长度，包含 UDP 报文头和 UDP 数据长度。因为 UDP 报文头长度是 8 个字节，所以这个值最小为 8，最大长度为 65535 字节。

- 校验和：UDP 使用校验和来保证数据安全性，UDP 的校验和也提供了差错检测功能，差错检测用于校验报文段从源到目标主机的过程中，数据的完整性是否发生了改变。

> **没有 IP 地址？**
>
> 我们在讲解多路复用与多路分解时，提到一个无连接套接字用一个目的 IP 地址和目的端口号标识，但是在 UDP 报文中，并没有看见目的 IP 地址。
>
> 事实上，TCP 报文中也没有目的 IP 地址和源 IP 地址，这是因为底层的 IP 数据报包含了源 IP 地址和目的 IP 地址，所以实际上无论是 TCP 还是 UDP 都使用四元组标识，但是 UDP 实际上在多路复用和多路分解使用的并不是完整的四元组。

### UDP 校验和

UDP 校验和提供了差错检测的功能，这就是说，校验和用于确定当 UDP 报文段从源到达目的地移动时，其中的比特是否发生了改变。

原理是：发送方对 UDP 报文段中的所有 16 比特字进行**求和**，然后进行**反码**运算，求和时遇到的任何溢出都将被**回卷**。把求出的结果放在校验和中，这样一来，接收方就多了一个 16 比特字，相加取反以后，得到的结果应该是全 1。如果不是全 1，则说明出现了差错。

 UDP 为什么提供差错检测？这其实是一种端到端的设计原则，这个原则说的是**要让传输中各种错误发生的概率降低到一个可以接受的水平**。

UDP 不可靠的原因是它虽然提供差错检测的功能，但是**对于差错没有恢复能力，更不会有重传机制**。

## TCP

UDP 是一种没有复杂的控制，提供无连接通信服务的一种协议，换句话说，它将部分控制部分交给应用程序去处理，自己只提供作为传输层协议最基本的功能。与 UDP 不同的是，同样作为传输层协议，TCP 协议要比 UDP 的功能多很多。

TCP 的全称是 Transmission Control Protocol，它被称为是一种**面向连接的协议**，这是因为一个应用程序开始向另一个应用程序发送数据之前，这两个进程必须先进行**握手**，握手是一个**逻辑连接**，并不是两个主机之间进行真实的握手。 这个**连接是指各种设备、线路或者网络中进行通信的两个应用程序为了相互传递消息而专有的、虚拟的通信链路**。

如下图所示：

![image-20220329200730415](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329200730415.png)

一旦主机 A 和主机 B 建立了连接，那么进行通信的应用程序只使用这个虚拟的通信线路发送和接收数据就可以保证数据的传输，TCP 协议负责控制连接的建立、断开、保持等工作。

TCP 连接是全双工的，所谓全双工，指的是**主机 A 与另外一个主机 B 存在一条 TCP 连接，那么应用程数据就可以从主机 B 流向主机 A 的同时，也从主机 A 流向主机 B**。

TCP 只能进行点对点连接，那么所谓的多播，即一个主机对多个接收方发送消息的情况，是不存在的，TCP 连接只能连接两个（一对）主机。

![image-20220329200817871](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329200817871.png)

TCP 会将数据临时存储到连接的**发送缓存（send buffer）**中，这个 send buffer 是握手期间设置的缓存之一，然后 TCP 在合适的时间将发送缓存中的数据发送到目标主机的**接收缓存（receive buffer）**中，实际上，每一端都会有发送缓存和接收缓存，如下图所示：

![image-20220329200914162](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329200914162.png)

**TCP 会将要传输的数据流分为多个块**（chunk），然后**向每个 chunk 中添加 TCP 标头**，这样就形成了一个 TCP 段也就是报文段。每一个报文段可以传输的长度是有限的，不能超过**最大分节长度（Maximum Segment Size，MSS）**。

在报文段向下传输的过程中，会经过链路层，链路层有一个**最大传输单元（Maximum Transmission Unit，MTU），即数据链路层上所能通过最大数据包的大小**，最大传输单元通常与通信接口有关。

**MSS 和 MTU 的关系一般是 MSS = MTU - TCP 报文段的头长度 - IP 数据报的头长度**。如果 MTU 是 1500，则 MSS = 1500 - 20 - 20 = 1460。

### TCP 和 UDP 的对比

1. **连接**。TCP 是面向连接的传输层协议，传输数据前先要建立连接；UDP 是不需要连接的，即刻传输数据。
2. **服务对象**。TCP 是一对一的两点服务，即一条连接只有两个端点；UDP 支持一对一、一对多、多对多的交互通信。
3. **可靠性**。TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达；UDP 是尽最大努力交付，不保证可靠交付数据。
4. **拥塞控制与流量控制**。TCP 有拥塞控制和流量控制机制，保证数据传输的安全性和整个网络的尽可能畅通；UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
5. **首部开销**。TCP 首部长度较长，会有一定的开销，首部在没有使用选项字段时是 `20` 个字节，如果使用了选项字段则会变长；UDP 首部只有 8 个字节，并且是固定不变的，开销较小。
6. **分片**。TCP 的数据大小如果**大于 MSS** 大小，则会**在传输层进行分片**，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片；UDP 的数据大小如果**大于 MTU** 大小，则会**在 IP 层进行分片**，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

由于上述的这些不同，TCP 和 UDP 的应用场景也不同，TCP 由于可靠交付，因此经常用于：

- FTP 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 DNS  等；
- 视频、音频等多媒体通信；
- 广播通信；

### TCP 报文段结构

TCP 报文段结构如下图所示：

![image-20220329203943648](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329203943648.png)

TCP 报文段结构相比 UDP 报文结构多了很多内容。但是前两个 16 比特的字段是一样的。它们是源端口号和目标端口号，我们知道，这两个字段是用于多路复用和多路分解的。另外，和 UDP 一样，TCP 也包含校验和。

除此之外，TCP 报文段首部还有下面这些：

- 32 比特的**序号**字段和 32 比特的**确认号**字段，这些字段被 TCP 发送方和接收方用来实现可靠的数据传输。

- 4 比特的**首部字段长度**字段，这个字段指示了以 32 比特的字为单位的 TCP 首部长度。

  TCP 首部的长度是可变的，但是**通常情况下，选项字段为空**，所以 **TCP 的经典首部字段的长度是 20 字节**。

- 4 比特**未使用**。

- 8 比特的**标志**字段：

  * `CWR` 和 `ECE` 用于拥塞控制。
  * `URG` 标志用来表示数据中存在需要被上层处理的紧急数据。紧急数据最后一个字节由 16 比特的紧急数据指针字段指出。

  * `ACK` 标志用于指示确认字段中的值是有效的，这个报文段包括一个对已被成功接收报文段的确认。
  * `PSH` 标志用于表示立刻将数据交给上层处理。
  * `RST`、`SYN`、`FIN` 标志用于连接的建立和关闭。

  一般情况下，`PSH` 和 `URG` 并没有使用。

- 16 比特的**接收窗口**字段，这个字段用于流量控制。它用于指示接收方能够/愿意接受的字节数量

- 可变的**选项**字段，这个字段用于发送方和接收方协商最大报文长度，也就是协商 MSS 时使用。

TCP 的各种功能和特点都是通过 TCP 报文结构来体现的。

### TCP 的可靠传输实现

#### 序号与确认号

TCP 报文段首部中两个最重要的字段就是序号和确认号，这两个字段是 TCP 实现可靠性的基础。要了解可靠传输的实现，首先得知道这两个字段里面存了哪些内容。

**一个报文段的序号就是数据流的首个字节的编号**。因为 TCP 会把数据流分割成为一段一段的字节流，因为字节流本身是有序的，所以每一段的字节编号就是标示是哪一段的字节流。

比如，主机 A 要给主机 B 发送一条数据。数据经过应用层产生后会有一串数据流，数据流会经过 TCP 分割，分割的依据就是 MSS，假设数据是 10000 字节，MSS 是 2000 字节，那么 TCP 就会把数据拆分成 0 - 1999 和 2000 - 3999 的段，依次类推。所以，第一个数据 0 - 1999 的首字节编号就是 0 ，2000 - 3999 的首字节编号就是 2000...

![image-20220329210817728](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329210817728.png)

**确认号则是期望从对方主机收到的下一个字节的序号**，由于 TCP 是一个全双工的协议，因此主机 A 在发送给主机 B 的数据的同时，也接收着来自主机 B 的数据。而从主机 B 到主机 A 的报文也会有序号，因此确认号就是主机 A 希望从主机 B 接收到的下一个字节的序号。

**TCP 在接收到数据后，会发送一个报文以确认收到**，通过在 TCP 的回复报文中设置确认号，来表示自己收到了发送的第一个字节到**确认号 - 1** 个字节，比如：

![image-20220329212422478](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329212422478.png)

**TCP 对于多个连续发送的报文段，只会确认最后一个段，这个机制被称为累积确认**。在接收方，回复报文段中确认号之前的所有字节都被接收到了。

注意，只有**当 ACK 标志位生效时，确认号才生效**，所以回复的报文也称为 ACK 报文。

累计确认也是为了接收方能够重新构建失序的字节流，比如 0 ~ 999 发送到了，由于某种原因，1000 ~ 1999 延迟到达，2000 ~ 2999 率先到达，这时该怎么办？事实上，根据累计确认的原则，我们只能确认 0 ~ 999 到达，1000 ~ 1999 并未到达，因此接收方发送的 ACK 应该是 1000，而且，**发送方会保留失序到达的报文段**，也就是 2000 ~ 2999，以便重新构建字节流。

#### 重传

TCP 使用了重传解决可靠数据传输的问题，重传也就是 TCP 发送方重新发送可能出现丢包的数据包。

##### 超时重传

对于发送方来说，如果一段时间没有接收到 ACK 报文，则会认为发生了**丢包**，这时它会选择重新发送该数据，也叫做**超时重传**。

![image-20220329212812802](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329212812802.png)



当然，**ACK 也是有可能发生丢包的**，这时还是会触发重传：

![image-20220329212902318](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329212902318.png)

**对于重复的报文段，TCP 接收方一般会选择丢弃**。

###### 超时时间设定

**对于超时重传，最重要的就是设置超时时间**，如果超时时间过短，则会导致大量 ACK 在未到达之前就超时，引起大量数据包重传，称之为过早超时；如果超时时间过长，则会导致一个实际丢包的数据包迟迟得不到重传，如果频繁发生该数据包的丢失，则会导致时间过长。

首先介绍一下 RTT 的概念，RTT 是 Round-Trip Time，也就是一次往返所需要的时间：

![image-20220329220015994](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329220015994.png)

我们使用 RTO（Retransmission Timeout）表示超时重传的时间，精确的测量 RTO 的值是非常重要的，这可让我们的重传机制更高效。我们根据 RTT，应该可以得出一个简单的结论：RTO 应该略大约 RTT。如下图所示：

![image-20220329220214843](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329220214843.png)

但是 RTT 会经常变化，所以 RTO 应该也是一个经常变化的动态值。

下面是 Linux 的 RTO 计算机制：

1. 首次计算。
   $$
   SRTT = R1 \newline
   DevRTT = \frac{R1}{2} \newline
   RTO = \mu * SRTT + \partial * DevRTT = \mu * R1 + \partial * \frac{R1}{2}
   $$
   其中 $R1$ 为首次测量的 RTT。

2. 后续计算。
   $$
   SRTT = SRTT + \alpha * (RTT - SRTT) = R1 + \alpha * (R2 - R1) \newline
   DevRTT = (1 - \beta) * DevRTT + \beta * (|RTT - SRTT|) = (1 - \beta) * \frac{R1}{2} + \beta * (|R2 - R1|) \newline
   RTO = \mu * SRTT + \partial * DevRTT
   $$
   其中， SRTT 是计算平滑的RTT ，DevRTT 是 SRTT 与 最新 RTT 的差距。


在 Linux 下，$\alpha$ = 0.125，$\beta$ = 0.25， $\mu$ = 1，$\partial$ = 4，这是经过大量实验得出的结论。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍**，也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？这就要介绍 TCP 的快速重传机制了。

##### 快速重传

当 TCP 接收到多个（一般是 3 个）一样的 ACK 时，就会触发快速重传，此时**只重传 ACK 期望接收到的包**。如下图所示：

![image-20220329222023535](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220329222023535.png)

这些重复的 ACK 也被称作**冗余 ACK**。冗余 ACK 的数量达到**重复阈值（dupthresh）**时就会触发快速重传，这个值可以设置，一般是 3。

快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是**重传的时候，是重传之前的一个，还是重传之前的所有**？

比如对于上面的例子，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。

根据 TCP 不同的实现，以上两种情况都是有可能的。可见，这是一把双刃剑。				

为了解决不知道该重传哪些 TCP 报文，于是就有 SACK 方法。

##### 选择性确认（SACK）

这种方式需要在 TCP 头部的选项字段里加一个 `SACK`，它**可以将知道哪些数据收到了，哪些数据没收到的信息发送给发送方**，这样就可以**只重传丢失的数据**。

如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。

![选择性确认](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/11.jpg)

如果要支持 `SACK`，必须双方都要支持。在 Linux 下，可以通过 `net.ipv4.tcp_sack` 参数打开这个功能（Linux 2.4 后默认打开）。

### TCP 流量控制

如果接收方的接收速率相对缓慢，而发送方发送的比较快，就有可能导致接收方的接收缓存溢出。

TCP 提供了流量控制服务，以消除发送方使接收方缓存溢出的可能性，因此流量控制实际上是一个速度匹配服务，即发送方的写速率和接收方的读取速率相匹配。

#### 滑动窗口

TCP 通过让发送方和接收方各维护一个**窗口（window）**来提供流量控制，具体来说，**接收方维护一个接收窗口（rwnd）**，用于告诉发送方接收方还有多少可用的缓存空间，**于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来**。

由于发送方才是主要的那方，因此窗口大小是由接收方的窗口大小来决定的，发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

##### 发送窗口

为了方便管理，发送方也维护了一个**发送窗口（swnd）**，如下图所示：

![image-20220331152922557](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331152922557.png)

- \#1 是已发送并收到 ACK确认的数据：1~31 字节
- \#2 是已发送但未收到 ACK确认的数据：32~45 字节
- \#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
- \#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后

发送方如果收到了一个 #2 区的 ACK 后（比如 32），就说明接收方已经处理完了 32，因此整个窗口可以往后推一格，32 归到 #1，33 做为 #2 的开头，52 被纳入 #3，53 作为 #4 的开头。

假设收到了 5 个 ACK，则窗口就会变成这个样子：

![32 ~ 36 字节已确认](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/18.jpg)

由于在发送的过程中会一直重复上述过程，窗口不断地滑动，因此叫做滑动窗口。

在实际 TCP 实现，需要使用多个变量来维护窗口，如下图所示：

![SND.WND、SND.UN、SND.NXT](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/19.jpg)

- `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）
- `SND.UNA`：是一个绝对指针，它指向的是**已发送但未收到确认**的第一个字节的序列号，也就是 #2 的第一个字节
- `SND.NXT`：也是一个绝对指针，它指向**未发送但处于可发送范围内**的第一个字节的序列号，也就是 #3 的第一个字节
- 指向 #4 的第一个字节是个相对指针，它可以根据 `SND.UNA` 指针加上 `SND.WND` 大小的偏移量计算出来，即指向 #4 的第一个字节

那么，整个**可用窗口大小** = `SND.WND - (SND.NXT - SND.UNA)`。

##### 接收窗口

接收方的窗口示意图如下：

![接收窗口](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/20.jpg)

- \#1 + #2 是已成功接收并确认的数据（等待应用进程读取）
- \#3 是未收到数据但可以接收的数据
- \#4 未收到数据并不可以接收的数据

使用两个指针就可以划分了：

- `RCV.WND`：表示接收窗口的大小，它会通告给发送方
- `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节
- 指向 #4 的第一个字节是个相对指针，它可以根据 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量计算出来，即指向 #4 的第一个字节

接收方的滑动流程和发送方是类似的，接收方处理完毕以后就可以将窗口往右滑动。

> **接收窗口和发送窗口的大小是相等的吗？**
>
> 并不一定相等，接收窗口的大小是**约等于**发送窗口的大小的。
>
> 因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 window 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。

#### 流量控制流程

以下图为例，展示一下流量控制的流程，前提：

- 客户端是接收方，服务端是发送方
- 假设接收窗口和发送窗口大小相同，都为 `200`
- 假设两个设备在整个传输过程中都**保持相同的窗口大小**，不受外界影响

流程如下图所示：

![流量控制](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/21.jpg)

1. 客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。
2. 服务端收到请求报文后，发送确认报文和 80 字节的数据，于是可用窗口 `Usable` 减少为 120 字节，同时 `SND.NXT` 指针也向右偏移 80 字节后，指向 321，**这意味着下次发送数据的时候，序列号是 321。**
3. 客户端收到 80 字节数据后，于是接收窗口往右移动 80 字节，`RCV.NXT` 也就指向 321，**这意味着客户端期望的下一个报文的序列号是 321**，接着发送确认报文给服务端。
4. 服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0，服务端无法再继续发送数据。
5. 客户端收到 120 字节的数据后，于是接收窗口往右移动 120 字节，`RCV.NXT` 也就指向 441，接着发送确认报文给服务端。
6. 服务端收到对 80 字节数据的确认报文后，`SND.UNA` 指针往右偏移后指向 321，于是可用窗口 `Usable` 增大到 80。
7. 服务端收到对 120 字节数据的确认报文后，`SND.UNA` 指针往右偏移后指向 441，于是可用窗口 `Usable` 增大到 200。
8. 服务端可以继续发送了，于是发送了 160 字节的数据后，`SND.NXT` 指向 601，于是可用窗口 `Usable` 减少到 40。
9. 客户端收到 160 字节后，接收窗口往右移动了 160 字节，`RCV.NXT` 也就是指向了 601，接着发送确认报文给服务端。
10. 服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 `SND.UNA` 指针偏移了 160 后指向 601，可用窗口 `Usable` 也就增大至了 200。

#### 窗口关闭（零窗口）

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭，也叫做零窗口**。

窗口关闭是有潜在风险的：接收方向发送方通告窗口大小时，是通过 ACK 来通告的。那么，当发生窗口关闭时，接收方处理完数据后，会**向发送方通告一个窗口非 0 的 ACK，如果这个通告窗口的 ACK 报文在网络中丢失了，那就会造成两边互相等待，形成了类似死锁的局面**。

![窗口关闭潜在的危险](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/24.jpg)

为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

如果持续计时器超时，就会发送**窗口探测 (window probe) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

- 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
- 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

#### 小窗口

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小，到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节**，这就是小窗口的问题。

要知道，我们的 `TCP + IP` 头有 `40` 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济了。

要解决这个问题，需要解决两个问题：

- **让接收方不通告小窗口给发送方**

  当窗口大小小于 `min(MSS，缓存空间 / 2)`，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`，也就阻止了发送方再发数据过来。

  等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。

- **让发送方避免发送小数据**

  使用 **Nagle 算法**，该算法的思路是**延时处理**，Nagle 算法的策略：

  - 没有已发送未确认报文时，立刻发送数据。
  - 存在未确认报文时，直到没有已发送未确认报文或数据长度达到 MSS 大小时，再发送数据。

  只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。

  ![image-20220424233032207](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220424233032207.png)

  上图右侧启用了 Nagle 算法，它的发送数据的过程：

  - 一开始由于没有已发送未确认的报文，所以就立刻发了 H 字符；
  - 接着，在还没收到对 H 字符的确认报文时，发送方就一直在囤积数据，直到收到了确认报文后，此时没有已发送未确认的报文，于是就把囤积后的 ELL 字符一起发给了接收方；
  - 待收到对 ELL 字符的确认报文后，于是把最后一个 O 字符发送了出去；

  可以看出，**Nagle 算法一定会有一个小报文，也就是在最开始的时候。**

  另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。

  可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）

### TCP 连接管理

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手来进行的，关闭连接则是通过四次挥手完成的**。

#### 三次握手

三次握手的过程如下图：

![image-20220331180713046](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331180713046.png)

1. 一开始，客户端和服务端都处于 `CLOSED` 状态。

2. 先是服务端主动监听某个端口，处于 `LISTEN` 状态。

3. 客户端随机初始化序号（`client_isn`），将此序号置于 TCP 首部的序号字段中，同时把 `SYN` 标志位置为 `1`，表示是 **SYN 报文**。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，**此报文不包含应用层数据**，之后客户端处于 `SYN-SENT` 状态。

   ![image-20220331181209195](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331181209195.png)

4. 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的序号字段中，其次把 TCP 首部的确认号字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，**该报文也不包含应用层数据**，之后服务端处于 `SYN-RCVD` 状态。

   ![image-20220331181542300](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331181542300.png)

5. 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次确认号字段填入 `server_isn + 1` ，最后把报文发送给服务端，**这次报文可以携带客户到服务器的数据**，之后客户端处于 `ESTABLISHED` 状态。

   ![image-20220331181714378](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331181714378.png)

6. 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

注意，**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**。

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。

我们可以使用 Linux 的 `netstat` 命令查看 TCP 连接状态，加上 `-napt` 选项，如图：

![image-20220424192610171](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220424192610171.png)

#### 三次握手相关问题

##### 为什么 TCP 每次建立连接前的序列号都要随机初始化，而不是从 0 开始？

主要原因有两个方面：

- **为了防止历史报文被下一个相同四元组的连接接收**（主要方面）；
- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

为了说明这一点，我们假设是从 0 开始的：

![image-20220424192748776](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220424192748776.png)

- 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，而此时服务端的进程重启了，于是就会发送 RST 报文来断开连接。
- 紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；
- **在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端**，刚好该数据包的**序列号正好是在服务端的接收窗口内**，所以该数据包会被服务端正常接收，就会**造成数据错乱**。

如果每次建立连接客户端和服务端的初始化序列号都不一样，就有**大概率**因为历史报文的序列号不在对方接收窗口，从而很大程度上避免了历史报文。注意，是大概率，而不是一定，因为随机初始化的序列号也有极小的概率会碰到这个问题。

##### ISN 生成算法？

ISN 的随机生成算法原理是：ISN = M + F，其中：

- M 是一个计时器，这个计时器每隔4毫秒加1。
- F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值，要保证 hash 算法不能被外部轻易推算得出。

随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。

##### 为什么是三次握手？不是两次、四次？

答案：

- 三次握手才可以阻止重复历史连接的初始化（主要原因）
- 三次握手才可以同步双方的初始序列号
- 三次握手才可以避免资源浪费

总结原因：

- 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号
- 四次握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数

###### 原因 1：避免历史连接（首要原因）

三次握手的**首要原因是为了防止旧的重复连接初始化造成混乱。**

我们考虑一个场景，客户端先发送了 SYN（seq = 90） 报文，但是被网络阻塞了，服务端并没有收到，接着客户端又重新发送了 SYN（seq = 100） 报文，注意不是重传 SYN，重传的 SYN 的序列号是一样的，但是此时 SYN（seq = 90） 报文到来了，这就会形成历史连接。

来看看三次握手是如何阻止历史连接的：

![image-20220331182605498](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331182605498.png)

客户端连续发送多次 SYN 建立连接的报文，在**网络拥堵**情况下：

- 一个旧 SYN 报文比最新的 SYN 报文早到达了服务端；
- 那么此时服务端就会回一个 `SYN + ACK` 报文给客户端；
- 客户端收到后可以根据自身的上下文，**判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 `RST` 报文给服务端**，表示中止这一次连接。

**两次握手则不能阻止历史连接，因为只有两次握手，旧 SYN 比新 SYN 到达之后，连接接收方直接进入  `ESTABLISHED` 状态**，即时后面连接发起方发送了 RST 组织本次连接，也浪费了接收方的部分资源。

###### 原因 2：同步双方的初始序列号

TCP 协议的通信双方， 都必须维护一个序列号， 序列号是可靠传输的一个关键因素。

在三次握手中，发起方初始化 ISN 后，跟随 SYN 报文一起发给接收方；接收方也初始化 ISN 后，跟随 SYN-ACK 一起发回给发起方，这样一来一回确定初始序列号。

而**两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收**。

四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了三次握手，也算是一种避免资源浪费。如下图所示：

![image-20220331185030586](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331185030586.png)

###### 原因 3：避免资源浪费

如果只有两次握手，当客户端的 `SYN` 请求连接在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 `ACK` 确认信号，所以每收到一个 `SYN` 就只能先主动建立一个连接，这会造成什么情况呢？

如果客户端的 `SYN` 阻塞了，重复发送多次 `SYN` 报文，那么服务器在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

##### 握手丢失会发生什么？

###### 第一次握手丢失

客户端第一个发的就是 SYN 报文，然后进入到 `SYN_SENT` 状态。

如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发**超时重传**机制，重传 SYN 报文。

**如果一直重传，一直收不到呢**？

在 Linux 里，客户端的 SYN 报文最大重传次数由 `tcp_syn_retries` 内核参数控制，这个参数是可以自定义的，默认值一般是 5。

通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，**每次超时的时间是上一次的 2 倍**。

**当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接**。

总耗时大约一分钟左右。

###### 第二次握手丢失

当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 `SYN_RCVD` 状态。

第二次握手有两个作用，一是确认，二是表示服务端建立连接。

* 因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是**客户端就会触发超时重传机制，重传 SYN 报文**。
* 因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。如果第二次握手丢失了，服务端就收不到第三次握手，于是**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。

在 Linux 下，SYN-ACK 报文的最大重传次数由 `tcp_synack_retries`内核参数决定，默认值是 5。

总结：**第二次握手丢失后，客户端和服务端都会重传**。

###### 第三次握手丢失

客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以**当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文**，直到收到第三次握手，或者达到最大重传次数。

注意，**ACK 报文是不会有重传的，当 ACK 丢失了，发送方会认为包丢了，于是就自己重传报文；接收方认为发出去了，由于 ACK 不用再 ACK，因此就不管了**。

##### SYN 洪泛攻击

假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务器不能为正常用户服务。

> 半连接队列是 Linux 建立的为未完全握手的连接而建立的队列。

解决方式：

1. 通过**修改 Linux 内核参数**，控制队列大小和当队列满时应做什么处理。
   * 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值的参数是： `net.core.netdev_max_backlog`。
   * 设置 SYN_RCVD 状态连接的最大个数的参数是：`net.ipv4.tcp_max_syn_backlog`。
   * 设置**超出处理能力时，对新的 SYN 直接回报 RST，丢弃连接**的参数是：`net.ipv4.tcp_abort_on_overflow`。
2. 使用 `tcp_syncookies` 的方式可以应对 SYN 攻击。
   - 当  SYN 队列满之后，后续服务器收到 SYN 包，不进入 SYN 队列；
   - 计算出一个 `cookie` 值，再以接下来要发送的 SYN + ACK 中的**序列号**的形式返回客户端，
   - 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性，如果合法，直接放入到 Accept 队列。
   - 最后应用通过调用 `accpet()` socket 接口，从 Accept 队列取出的连接。

#### 四次挥手

四次挥手的过程如下图：

![image-20220331190617897](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331190617897.png)

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- **客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态**
- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。

你可以看到，每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

这里一点需要注意是：**主动关闭连接的，才有 `TIME_WAIT` 状态。**

#### 四次挥手相关问题

##### 为什么挥手需要四次？

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅**表示客户端不再发送数据了但是还能接收数据**。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而**服务端可能还有数据需要处理和发送**，**等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接**。

从上面过程可知，**服务端通常需要等待完成数据的发送和处理**，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。

##### 挥手丢失会发生什么？

###### 第一次挥手丢失

如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会**触发超时重传机制，重传 FIN 报文**，重发次数由 `tcp_orphan_retries` 参数控制。

当客户端重传 FIN 报文的次数超过 `tcp_orphan_retries` 后，就不再发送 FIN 报文，直接进入到 `close` 状态。

###### 第二次挥手丢失

第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。

###### 第三次挥手丢失

服务端发送 FIN 报文后，期望接到一个 ACK，如果 FIN 丢失，导致迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 `tcp_orphan_retries` 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。

###### 第四次挥手丢失

如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 `tcp_orphan_retries` 参数控制。

##### 为什么需要 `TIME_WAIT`？

当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 `TIME_WAIT` 状态。`TIME_WAIT` 状态会持续 2MSL 后才会进入关闭状态。

服务端（被动关闭方）没有收到 ACK 报文前，还是处于 `LAST_ACK` 状态。如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文。

如果没有 `TIME_WAIT` 而是直接进入 `CLOSED`，那么就会导致第四次挥手丢失后，没办法检测超时重传，导致服务端一直处于 `LAST_ACK` 状态。

当然，`TIME_WAIT` 不能过多，多的 `TIME_WAIT` 状态主要的危害有两种：

- 第一是内存资源占用
- 第二是对端口资源的占用，一个 TCP 连接至少消耗发起连接方的一个本地端口

##### `TIME_WAIT` 时长为什么是 2MSL？

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 **IP 数据报可以经过的最大路由数**，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

MSL 与 TTL 的区别：MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

**2MSL 时长能够至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

#### TCP 半连接队列和全连接队列

这是 Linux 在实现 TCP 时引入的机制，在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列
- 全连接队列，也称 accept 队列

服务端收到客户端发起的 SYN 请求后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来**。

![image-20220331193313347](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331193313347.png)

##### backlog

在服务端 `listen` 时，有一个参数名为 `backlog`，这个参数的设置对 TCP 队列来说至关重要。

Linux 内核中会维护两个队列：

- 半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 `SYN_RCVD` 状态；
- 全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 `ESTABLISHED` 状态；

![image-20220424174939371](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220424174939371.png)

在早期 Linux 的内核中，`backlog` 是 SYN 队列大小，也就是未完成的队列大小。

在 Linux 内核 2.2 之后，`backlog` 变成 accept 队列的大小，也就是已完成连接建立的队列长度，**所以现在通常认为 backlog 是与 accept 队列有关。**

**但是，上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。**

#### Fast Open

在 Linux 3.7 内核版本中，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。

![image-20220424233303791](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220424233303791.png)

- 在第一次建立连接的时候，服务端在第二次握手产生一个 `Cookie` （已加密）并通过 SYN、ACK 包一起发给客户端，于是客户端就会缓存这个 `Cookie`，所以第一次发起 HTTP GET 请求的时候，还是需要 2 个 RTT 的时延；
- 在下次请求的时候，客户端在 SYN 包带上 `Cookie` 发给服务端，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；

### TCP 拥塞控制

我们之前提到 TCP 提供了流量控制，这是为了避免接收方的缓存被填满。

一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....**

所以，TCP 被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量，于是就有了**拥塞控制**，控制的目的就是**避免发送方的数据填满整个网络。**

* **流量控制是为了避免接收方的缓存被填满**。
* **拥塞控制是为了避免整个网络的拥堵**。

注意，TCP 的拥塞控制是针对发送方的，TCP 会在发送方维护一个**拥塞窗口**。

#### 拥塞窗口

拥塞窗口（cwnd）是发送方维护的一个变量，它会根据网络的拥塞程度动态的调整。

那么如何知道网络存在拥堵？TCP 的做法很简单：只要发送方没有在规定时间内接收到 ACK 应答报文，也就是**发生了重传（超时重传或快速重传），就会认为网络出现了用拥塞。**

拥塞控制主要是基于如下算法：

- 慢启动
- 拥塞避免
- 拥塞发生
- 快速恢复

#### 慢启动

TCP 在刚建立连接完成后，首先会经历一个**慢启动**的过程。

cwnd 的长度定义为 MSS 的个数，初始时只能发送 1 个 MSS，**每当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**

- 连接建立完成后，一开始初始化 `cwnd = 1`，表示可以传一个 `MSS` 大小的数据。
- 当收到 1 个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个
- 当收到 2 个 ACK 确认应答后，cwnd 增加 2，于是就可以比之前多发 2 个，所以这一次能够发送 4 个
- 当这 4 个 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。

我们发现，**慢启动过程实际上是一个指数级的增长**。如下图所示：

![image-20220331202317019](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331202317019.png)

当然，这种增长不是永久的，**如果存在超时重传，则将会把 `cwnd` 重新置为 1，并且重新开始慢启动**，除此之外，**还会设置 `ssthresh`（慢启动阈值）的值置为上一个 cwnd 的一半**。

这一次慢启动时，当 `cwnd` < `ssthresh` 时，增长方式不变，**当 `cwnd` >= `ssthresh` 时，就会使用拥塞避免算法**。

#### 拥塞避免

前面说道，当拥塞窗口 `cwnd` 超过慢启动门限 `ssthresh` 就会进入拥塞避免算法。这意味着 cwnd 的值在上一次遇到拥塞的一半左右，也意味着离拥塞不远了，此时就要避免拥塞。

这个阶段中，cwnd 的值一次只增加 1，无论收到多少个 ACK，这时就会由指数级增长变为线性增长：

![image-20220331210733130](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331210733130.png)

#### 拥塞发生

当发生拥塞以后，就要根据重传的类型调整 ssthresh。

**如果是超时，则和拥塞避免一样，cwnd 变为 1，ssthresh 变为上一次 cwnd 的一半。**

![image-20220331210916974](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331210916974.png)

**如果是快速重传，则意味着存在冗余 ACK，只丢了小部分包，此时 cwnd 变为一半，ssthresh = cwnd，直接快速恢复算法。**

#### 快速恢复

快速恢复其实是可选的，具体看 TCP 的实现。

如果没有实现快速恢复，则在拥塞发生时触发快速重传后就会重新开始拥塞避免的线性增长。

而快速恢复一般的实现是：

* `cwnd = ssthresh + 3`
* 重传丢失的数据包
* 如果再收到重复的 ACK，那么 cwnd 增加 1
* 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明 冗余 ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态

![image-20220331214520262](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220331214520262.png)

### TCP 粘包问题

TCP 协议是流式协议，会出现粘包问题。

所谓流式协议，即**协议的内容是像流水一样的字节流，内容与内容之间没有明确的分界标志**，需要我们人为地去给这些协议划分边界。

解决方式也就是划分边界，一般有三种方式分包的方式：

- 固定长度的消息：这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。

  但是这种方式灵活性不高，实际中很少用。

- 特殊字符作为边界：我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。

  HTTP 就是一个非常好的例子。

- 自定义消息结构：我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

### TCP 保活机制

如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

- 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端,，对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，这个工作是在内核完成的。

![image-20220424234427060](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220424234427060.png)

如果没有开启保活机制，且双方一直没有数据交互的情况下，如果客户端的主机崩溃了，会发生什么？

答案是，服务端是**无法感知到**的，没有数据交互的情况下，**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程。
