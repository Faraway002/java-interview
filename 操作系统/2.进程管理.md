# 进程管理

操作系统中最核心的概念是进程，进程是对正在运行的程序的一个抽象，操作系统的其他所有内容都是围绕着进程的概念展开的。

进程是操作系统提供的最古老的也是最重要的抽象概念之一，即使可以利用的 CPU 只有一个，它也支持（伪）并发操作的能力。

本章将探究进程，以及它的一个亲戚——线程。

## 程序与进程

**程序是 CPU 指令的集合。**由高级语言编写的程序无法被 CPU 直接识别，需要被编译器翻译为 CPU 可以识别的二进制指令序列，也叫做可执行文件。

操作系统执行一个可执行文件，本质上是把它内部的二进制序列装载到内存中，CPU 取指令然后执行。

运行中的程序称为**进程**，进程可访问的内存称之为地址空间，我们将在第三章内存管理中详细的介绍。

CPU 的每个核心在任意时间只有一个进程正在执行，因此，即使你的 CPU 是 8 核的，那么最多也只有 8 个进程在同时执行。

但是，由于 CPU 切换到其他进程执行的速度很快，即使这些进程是有顺序执行的，但是给人们一种假象是有多个进程同时运行。CPU 在多个可运行的进程间切换执行叫做**上下文切换**。

进程和程序最大的**区别在于进程具有运行状态**，这个状态包括 CPU 寄存器的状态，以及它的地址空间状态。

### 并发与并行

**并发指的是 CPU 以很快的速度进行上下文切换，导致的多个进程正在同时运行的假象，本质上是串行执行的；而并行指的是多核 CPU 分别同时执行多个进程，是真正的同时执行。**

下图是一个示意图：

![image-20220121102223328](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220121102223328.png)

## 进程的生命周期

### PCB（Process Control Block）

在操作系统中，会通过 PCB（Process Control Block），也就是进程控制块，来描述和管理进程。

PCB 是进程存在的唯一标识，如果一个进程结束，那么它的 PCB 也会随之被回收。

在 Linux 上，PCB 对应的数据结构是 `task_struct`，一般包含了如下信息：

* 进程描述信息：用于描述进程的信息。

  * 进程标识符（PID）：唯一标识一个进程，在 Linux 上是一个整数。
  * 用户标识符：进程归属的用户。

* 进程控制和管理信息：主要包括进程当前所处的状态，调度优先级等等。

  * 进程当前状态：表示进程当前所处的状态，如 new、ready、running、waiting 或 blocked 等。

  * 进程优先级：进程抢占 CPU 时的优先级。

* 资源分配信息：描述给当前进程分配的资源。

  * 文件系统信息：对进程使用文件情况的记录。
  * 虚拟内存信息：描述每个进程拥有的地址空间。

* CPU 相关信息：CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

PCB 是每进程的，在 Linux 中，PCB 存放在进程地址空间的内核空间的内核栈中，这样放的好处在于，可以快速的找到 PCB 的位置，而且避免了额外给 PCB 分配空间。

#### PCB 的组织形式

在 Linux 中，通常使用链表把 PCB 组织起来，形成各种队列：

* 将所有处于就绪状态的进程链在一起，称为**就绪队列**。

  就绪队列中的进程都有可能被 OS 调度。

* 把所有因等待某事件而处于等待状态的进程链在一起就组成各种**等待队列**，也叫阻塞队列。

  只有当进程因某种原因阻塞时，才会从就绪队列中移除然后加入到阻塞队列中。当阻塞解除时，进程又会被移除出阻塞队列，然后加入到就绪队列中。

进程调度算法会依赖于这些队列完成调度。

如下图所示：

![image-20220316175301701](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220316175301701.png)

### 进程创建

在操作系统上，一般都会提供方法在运行时按需创建进程。

启动操作系统时，通常会创建若干个进程，其中有些是前台进程，也就是同用户（人类）交互并且替他们完成工作的那些进程。其他的是后台进程，这些进程与特定的用户没有关系，相反，却具有某些专门的功能。

停留在后台具有专门功能的进程称之为**守护进程**。

除了在启动操作系统时会创建进程，进程在运行时也会通过操作系统提供的接口申请创建进程。由进程创建的进程称为其**子进程**。所以进程间通常存在一些亲属关系，包括父子关系，兄弟关系等等。

在 Linux 系统上，提供了著名的 `fork` 系统调用用于创建进程，子进程具有和父进程完全相同的**拷贝**（注意不是共享），但是更多时候不需要一份父进程的拷贝，而是要执行其他程序，因此，Linux 还提供了 `exec` 系列系统调用来加载其他程序并执行。

创建进程（fork）的过程如下：

1. 为新进程分配一个唯一的进程标识号（PID），并申请一个空⽩的 PCB，PCB 是有限的，若申请失败则创建失败

2. 复制父进程的 PCB，具体来说：
   1. 复制父进程打开的文件描述符。

   2. 复制地址空间，但是并不立即执行对地址空间内容的复制，而是暂时**让父子进程共享部分内存，待子进程需要写入时，再执行复制，这种技术叫做 Copy-On-Write（写时复制）**。

      写时复制是一种很重要的技术，在并发编程中也十分常见。

3. 将新进程状态设为就绪状态。

#### 写时复制

主进程在通过 `fork` 系统调用生成子进程时，操作系统会把主进程的**页表**复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个：

![image-20220510163235837](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220510163235837.png)

这样一来，子进程就共享了父进程的物理内存数据了，这样能够**节约物理内存资源**，页表对应的页表项的属性会标记该物理内存的权限为**只读**。

不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发**缺页中断**，这个缺页中断是由于**违反权限**导致的，然后操作系统会在缺页异常处理函数里进行**物理内存的复制**，并重新设置其内存映射关系，将父子进程的内存读写权限设置为**可读写**，最后才会对内存进行写操作，这个过程被称为写时复制。如下图所示：

![image-20220510200229817](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220510200229817.png)

写时复制顾名思义，**在发生写操作的时候，操作系统才会去复制物理内存**，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。

当然，**操作系统复制父进程页表的时候，父进程也是阻塞中的**，不过页表的大小相比实际的物理内存小很多，所以通常复制页表的过程是比较快的。

不过，如果父进程的内存数据非常大，那自然页表也会很大，这时父进程在通过 fork 创建子进程的时候，阻塞的时间也越久。

所以，有两个阶段会导致阻塞父进程：

- 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
- 创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；

### 进程终止

进程通常在以下几种情况下会终止：

1. 进程完成了其任务，正常退出。
2. 进程主动调用退出的系统调用。
3. 进程执行出现错误，异常退出。
4. 被其他进程杀死。

多数进程是由于完成了它们的工作而终止，也有系统调用能够提前终止进程，在 Linux 中，这个系统调用是 `exit`。

终止进程的过程如下：

1. 查找需要终止的进程的 PCB。

2. 如果处于执行状态，则立即终止该进程的执行。

3. 如果其还有子进程，则应将其所有⼦进程终止。

4. 将该进程所拥有的全部资源都归还给父进程或操作系统。

5. 将其从 PCB 所在队列中删除，回收其内存空间。

### 进程阻塞与唤醒

当进程需要**等待某一事件完成**时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。

阻塞进程的过程如下：

1. 找到将要被阻塞进程的 PCB。

2. 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行。
3. 将该 PCB 插入到阻塞队列中去。

唤醒的过程如下：

1. 在该事件的阻塞队列中找到相应进程的 PCB。
2. 将其从阻塞队列中移出，并置其状态为就绪状态。
3. 把该 PCB 插入到就绪队列中，等待调度程序调度。

### 上下文切换

各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个**一个进程切换到另一个进程运行，称为进程的上下文切换**。

通常，会把交换的信息保存在进程的 PCB 中，当要运行另外一个进程时，从 PCB 中取出上下文，然后恢复到 CPU 中。

![image-20220316200901749](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220316200901749.png)

需要注意的是，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。

### 进程状态

进程通常有三种状态：

* 运行（**running**）：在运行状态下，进程正在处理器上运行。这意味着它正在执行指令。
* 就绪（**ready**）：在就绪状态下，进程已准备好运行，但由于某种原因，操作系统选择不在此时运行。
* 阻塞（**blocked**）：在阻塞状态下，一个进程执行了某种操作，直到发生其他事件时才会准备运行。一个常见的例子是，当进程向磁盘发起 I/O 请求时，它会被阻塞，因此其他进程可以使用处理器。

它们之间的转换如图所示：

![image-20220121102245097](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220121102245097.png)



在一般的操作系统中，还有更为详细的状态，比如进程刚刚新建以及进程生命即将消亡，因此有一个更完整的进程状态转换图：

![image-20220121102407076](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220121102407076.png)



**如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间**，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。

所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。那么就需要一个新的状态来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。

挂起状态也可以分为两种：

* 就绪挂起状态：虽然进程被换到硬盘上，但是一旦被换到内存中，就进入到就绪队列中，随时可以被调度。
* 阻塞挂起状态：进程被换到硬盘上，并且阻塞（等待某个事件）。

![image-20220316201949238](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220316201949238.png)

## 线程

在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面，计算机科学家们又提出了更小的能独立运行的基本单位，也就是**线程。**

为什么使用线程？因为**线程更加轻量级**，它的开销没有进程那么大，而且**线程之间可以共享数据**，减少了线程间通信的成本。

准确来说，**线程是进程当中的一条执行流程**。

**同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈**，这样可以确保线程的控制流是相对独立的。

线程的模型如下图所示：

![image-20220316203234981](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220316203234981.png)

线程与进程的比较如下：

* **进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位**。

* 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈。

* 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系。

* 线程能减少并发执行的时间和空间开销。

  具体体现在：

  * **线程的创建所需要的时间比进程快**，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们。
  * **线程的终止所需要的时间比进程快**，因为线程释放的资源相比进程少很多。
  * **同一个进程内的线程切换比进程切换快**，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的。
  * 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得**线程之间的数据交互效率更高**了

现代操作系统中，**进程至少拥有一条线程**，称为主线程，而由主线程创建其他子线程。

### 线程的上下文切换

线程的上下文切换主要是看它们是否属于同一进程：

* 如果多个线程属于同一进程，由于内存等资源共享，因此只需要保存 CPU 的寄存器，线程的栈等线程私有数据即可。
* 如果不属于同一进程，则切换就像进程的上下文切换一样。

### 线程实现

主要有三种线程的实现方式：

* 用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理。
* 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程。
* 轻量级进程（LightWeight Process）：在内核中来支持用户线程。

#### 用户线程

用户线程是基于用户态的线程管理库来实现的，线程控制块（Thread Control Block, TCB） 也是在库里面来实现的。

对于操作系统而⾔，操作系统看不到 TCB，它只能看到整个进程的 PCB。所以，**用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。**

优点：

* 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息，TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统。
* 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快。

缺点：

* 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。
* 当一个线程开始运行后，除⾮它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。
* 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢。

由于用户线程并非是操作系统的调度单位，因此一个用户线程要执行，本质上是通过线程库将用户级线程映射到内核级线程，再由操作系统调度。当然，如果操作系统连内核级线程都不支持，那么操作系统就只能调度进程。

![image-20220317143950010](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317143950010.png)

#### 内核线程

**内核线程是由操作系统管理的，线程对应的** **TCB** **自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。**

优点：

* 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行。
* 时间片是分配给线程的，因此多线程的进程获得更多的 CPU 运行时间。

缺点：

* 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，需要额外资源来维护。
* 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大。

![image-20220317144757229](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317144757229.png)

#### 轻量级进程

轻量级进程（Light Weight Process，LWP）是**内核支持的用户线程**，一个进程可有一个或多个 LWP，**每个 LWP 都由一个内核线程支持**。

在大多数系统中，LWP 与普通进程的区别在于：**LWP 只有一个最小的执行上下文和调度程序所需的统计信息**。

轻量级进程和用户线程的组合被视作加强版的用户线程，LWP 作为用户线程与内核线程之间的桥梁，用户线程库将建立的用户线程关联到 LWP 上，当内核调度到某个 LWP 上时，此时与该 LWP 关联的用户线程就被执行。

由于用户线程关联到 LWP 的数量不一定，因此可以产生多种对应模式：

![image-20220317150818215](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317150818215.png)

总体大概可以分为：

* 一对一模式：一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4 和 进程 1 就属于此模型。

  * 优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP。
  * 缺点：每一个用户线程，就产⽣一个内核线程，创建线程的开销较大。

* 多对一模式：多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可⻅。

  * 优点：用户线程开销比较小，而且上下文切换发⽣在用户空间，切换的效率较高。
  * 缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞。

* 多对多模式：首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。

  优点：综合了前两种优点，大部分的线程上下文切换发⽣在用户空间，效率高，开销小，且可以充分利用多核 CPU 的资源。

* 组合模式：结合一对一和多对多模型，开发⼈员可以针对不同的应用特点调节内核线程的数⽬来达到物理并行性和逻辑并行性的最佳方案。上图中的进程 5 就属于此模型。

## 调度

当计算机系统是多道程序设计系统时，**通常就会有多个进程或线程同时竞争 CPU**。只要有两个或更多的进程处于就绪状态，这种情形就会发生。

如果只有一个 CPU 可用，那么操作系统就必须选择下一个要运行的进程。完成选择工作的这一部分称为**调度程序**（scheduler），该程序使用的算法称为**调度算法**。

### 调度时机

当进程的状态发生转换时，有很大的可能会触发一次调度：

* 就绪态到运行态：当进程被创建时，处于就绪状态，进入就绪队列中，操作系统就会在就绪队列中选择一个进行调度。
* 运行态到阻塞态：当进程发⽣ I/O 事件而阻塞时，操作系统必须选择另外一个进程运行。
* 运行态到结束态：当进程结束时，操作系统必须选择另外一个进程运行。

另外，在发生中断时，如果进程响应中断，则中断结束后操作系统也要选择一个进程进行调度。

#### 进程行为

几乎所有进程的（磁盘）I/O 请求或计算都是交替突发的。典型地，CPU 不停顿地运行一个进程一段时间，然后进程发出一个系统调用以便进行 I/O。在完成系统调用之后，CPU 又开始计算，直到它需要读更多的数据或写更多的数据为止。

![image-20220317154344005](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317154344005.png)

我们注意到，a 进程花费绝大多数时间在计算上，而 b 进程花费绝大多数时间在 I/O 上，前者称之为**计算密集型程序**，后者称之为 **I/O 密集型程序**。

随着 CPU 越来越快，更多的进程倾向为 I/O 密集型，在现代应用程序中，对 I/O 密集型进程的调度处理更为重要。

### 调度原则

根据上述内容，我们可以得到以下调度原则：

1. 如果运行的程序，发⽣了 I/O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，为了提高 CPU 利用率，**在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。**
2. 有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，**要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。**
3. 进程的周转时间（运行时间和阻塞时间的总和）越小越好，**如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的**，调度程序应该避免这种情况发⽣。
4. **对于交互式比较强的应用，我们当然希望它的响应时间越快越好**，否则就会影响用户体验。所以，对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。
5. 对于同处于就绪状态的进程来说，**进程希望自己的等待时间不能太长**，所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。

### 调度指标

根据上面介绍的原则，总结出五条指标：

1. **CPU** **利用率**：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率。
2. **系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量。
3. **周转时间**：周转时间是进程运行和阻塞时间总和，一个进程的周转时间越小越好。
4. **响应时间**：用户提交请求到系统第一次产⽣响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。
5. **等待时间**：处于就绪状态下的进程等待自己被调度所花费的时间。

### 调度算法

#### 先来先服务（FCFS）

先来先服务（First Come First Serve）是最简单的调度算法，思想是：**每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**

![image-20220317161101700](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317161101700.png)

上图中，CPU 会按照 ABCD 的顺序运行。

优点：实现简单，适用于计算密集型程序。

缺点：容易导致饥饿问题，如果一个长作业先运行了，那么后面的短作业等待时间就会很长，不利于短作业。

#### 最短作业优先（SJF）

最短作业优先（Shortest Job First）算法会**优先选择运行时间最短的进程来运行**，这可以很好的提高系统的吞吐量。

![image-20220317161517069](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317161517069.png)

优点：短作业将被优先执行，一定程度上减少了饥饿问题。

缺点：**作业运行时长很难估计**，如果短作业过多，长作业反而会有饥饿问题。

当然，它虽然一定程度上能够减少饥饿问题，但是还是有可能会导致短作业饥饿，如果 D 先来到就绪队列，且是当时唯一一个进程，那么操作系统就会执行它。如果这时 A 到来，那么 A 还是要等待 D 执行完毕，饥饿问题又出现了。

因此，需要有一种**抢占式的 SJF**，每当一个任务来到队列中，操作系统重新从队列中选出剩余完成时间最短的那个进行调度，这样就完全避免了短作业的饥饿问题，这种算法也叫做**最短完成时间优先（STCF）**。

#### 时间片轮转（RR）

最古⽼、最公平且使用最⼴的算法就是**时间片轮转（Round Robin）算法**。

它的思想很简单：**每个进程被分配一个时间段，称为时间片，每个进程都只允许在这一时间片内运行。如果这一时间片内运行没有结束，则把进程移动到队列尾部，然后队列头部的进程运行一个时间片**。

![image-20220317162605289](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317162605289.png)

当然，如果进程在时间片内结束了，则也可以立即开始下一个进程的调度。

#### 最高优先级优先（HPF）

在 RR 中，所有进程被视为具有同等优先级，但是往往现代操作系统中，需要为进程设置不同的优先级，优先级高的进程需要被优先运行。

**从队列中每次选择优先级最高的进程调度**，这就是最高优先级优先（Highest Priority First）。

进程的优先级可以分为静态优先级和动态优先级：

* 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化。
* 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级；如果进程等待时间增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。

使用静态优先级可能会导致饥饿问题（最低优先级的进程可能永远无法执行），因此一般使用动态优先级。

该算法也分为抢占式和非抢占式。

#### 多级反馈队列（MLFQ）

多级反馈队列（Multi Level Feedback Queue）是 HPF 和 RR 的集大成者，是许多操作系统采用的调度算法。

MLFQ 不仅优化了周转时间，同时它还可以给交互型应用良好的响应时间，除此之外，MLFQ 还具有优先级机制，解决了饥饿问题。

**MLFQ 中有许多独立的队列，每个队列有不同的优先级，任何时刻，一个工作只能存在于一个队列中，MLFQ 总是优先执行较高优先级的工作。**

![image-20220317164310505](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317164310505.png)

MLFQ 的规则：

1. 总是运行最高优先级队列中的进程。
2. 对于同优先级的进程，采取时间片轮转调度。
3. 任务刚进入队列时，处于最高优先级。
4. 任务用完整个时间片后，降低其优先级。
5. 经过一段时间后，把所有进程都放入最高优先级队列中。

## 线程同步

在多线程的程序中，线程之间共享进程的资源，比如代码段、堆空间、数据段、打开的文件等，这种共享造就了线程的轻量级，但是也带来了问题。

假设进程中有两个线程，共享一个 i 变量，两个线程都对 i 自增 10000，最后我们期望得到的结果是 20000，C++ 代码实现如下所示：

![image-20220317165644238](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317165644238.png)

按理来说，结果应该就是 20000，但是很不幸，事实并不是如此：

![image-20220317165742666](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317165742666.png)

多次执行后，你会发现很少有结果能达到 20000，大部分情况都是 10000 到 20000 之间的一个数，并且每次执行结果都基本上不同。

造成这种情况的原因是：**线程被调度的时机是不确定的**。上面的代码中，对于共享变量 i 的操作是 `i = i + 1`，它实际上对应三条指令：

![image-20220317171643113](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317171643113.png)

设想线程 1 进入这个代码区域，它将 i 的值（假设此时是 50 ）从内存加载到它的寄存器中，然后它向寄存器加 1，此时在寄存器中的 i 值是 51。假设此时线程 1 用完了它的时间片，线程 2 被调度，执行了多次 `i = i + 1`，最后它用完时间片时，i 的值是 90，并且写入到了内存中。这时，线程 1 被重新调度，把 50 写入到了内存中，此时之前线程 2 加的 40 就被覆盖掉了。

我们把**对共享内存进行访问的程序片段称为竞态条件**，当多线程竞争操作共享资源时，由于 CPU 的调度导致了上下文切换，最终导致线程读取/写入资源的结果不一致。

由于多线程执行操作共享变量的这段代码可能会导致竞态条件，因此我们将此段代码称为**临界区**，它是访问共享资源的代码片段。

我们希望在任一时刻，只有一个线程能够进入临界区，即我们希望它是**互斥**的：**以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作**。如下图所示：

![image-20220317172527029](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220317172527029.png)

操作系统提供的互斥的方案有：

* 锁
* 条件变量
* 信号量

### 锁

类似于现实世界的锁，**任何想进入临界区的线程，必须先执行加锁操作，若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。**

![image-20220318153148255](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220318153148255.png)

根据锁的实现的不同，锁又分为忙等待锁（自旋锁）和无等待锁。

#### 硬件同步原语

在介绍锁的实现前，我们仔细思考一下如何实现一个锁？没有硬件的支持能否做到？答案是否定的，如果一行代码不能被 CPU 一次性执行完，而是要拆分成多条指令执行，那么这行代码就会有并发的风险。

相反，如果一行甚至一段代码的执行过程中不会被打断，那么我们就称它是**原子性的**（原子是最小的，不可再分的物质）。无论采用何种思路来实现锁，由于这些指令不是原子性的，因此它们就无法真正起到锁的作用。

好在 CPU 为我们提供了几条**原子指令**，能够帮助我们实现同步。

最常见的两条指令如下：

1. 测试并设置（TestAndSet，TAS）：对一个内存单元返回其旧值，同时更新为指定的新值。

   用如下 C 代码表示测试并设置的流程：

   ```c
   int TestAndSet(int*  old_ptr, int new) {
       int old = *old_ptr; // 取 old_ptr 内存单元中的值
       *old_ptr = new; // 把 new 值设置到 old_ptr 内存单元中
       return old; // 返回旧值
   }
   ```

2. 比较并交换（CompareAndSwap，CAS）：对一个内存单元的值进行测试，如果和期望值一样，就更新为指定的新值；否则什么都不做。

   用如下 C 代码表示比较并交换的流程：

   ```c
   int CompareAndSwap(int *ptr, int expected, int new) { 
       int actual = *ptr; 
       if (actual == expected) 
           *ptr = new; 
       return actual; 
   }
   ```

这些原子指令是由硬件确保原子性的，我们可以放心大胆的使用这些指令。

#### 忙等待锁（自旋锁）

我们使用 TAS 可以实现一个简单的锁：

```c
typedef struct lock_t { 
    int flag; 
} lock_t; 

void init(lock_t *lock) { 
    // 0 indicates that lock is available, 1 that it is held 
    lock->flag = 0; 
} 

void lock(lock_t *lock) { 
    while (TestAndSet(&lock->flag, 1) == 1) 
        ; // spin-wait (do nothing) 
} 

void unlock(lock_t *lock) { 
    lock->flag = 0; 
}
```

这个锁真的能工作吗？我们看一下它的流程：

1. 首先假设一个线程在运行，调用 `lock()`，假设此时没有其他线程持有锁，所以 flag 是 0。

   此时调用 `TestAndSet(flag, 1)` 方法，返回旧值 0，设置新值 1，而旧值为 0 显然是不等于 1 的，因此会跳出循环，成功获取到锁。

2. 现在，有一个线程也进入临界区，尝试 `lock()`，由于 flag 已经被上面的线程置为 1，`TestAndSet(flag, 1)` 就会一直返回 1，这时，这个线程就会一直处于循环中，这就叫**自旋**。

3. 轮到刚刚获取锁的线程执行了，此时线程执行完毕， `unlock()` 将 flag 置为 0。
4. 最后，刚刚一直处于循环的线程发现 flag 竟然变为了 0，返回 0，设置新值 1，这个线程获取到了锁，脱离循环，进入临界区。

当线程获取不到锁时，线程就会一直循环，所以就被称为忙等待锁，也被称为**自旋锁（spin lock）**。

比较并增加（CAS）通常比 TAS 更好，我们用它实现一个自旋锁：

```c
typedef struct lock_t { 
    int flag; 
} lock_t; 

void init(lock_t *lock) { 
    // 0 indicates that lock is available, 1 that it is held 
    lock->flag = 0; 
} 

void lock(lock_t *lock) { 
    while (CompareAndSwap(&lock->flag, 0, 1) == 1) 
        ; // spin-wait (do nothing) 
} 

void unlock(lock_t *lock) { 
    lock->flag = 0; 
}
```

请读者自行分析这个锁的原理。

#### 无等待锁（互斥锁）

无等待锁和自旋锁相反，在线程获取不到锁时，不自旋，而是进入阻塞状态，表明自己在等待锁。

无等待锁在加锁时，如果不能立即获取到锁，则将自己放入阻塞队列中；释放锁时，则从队列中唤醒一个线程。伪代码如下：

![image-20220318170003472](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220318170003472.png)

#### 自旋锁和互斥锁的适用情况

自旋锁和互斥锁是构建高级锁的基石，它们的适用情况有所不同：

* **自旋锁适用于短时间等待资源的情况**：线程在获取自旋锁失败后，会进入无限循环等待，这时会一直占用 CPU，而不是阻塞。

  如果在很短的时间内线程就能获取到锁，那么就没有必要让自己阻塞。操作系统进行线程上下文切换时的开销比较大，如果临界区的代码执行时间很短的话，那么上下文切换的时间可能比执行临界区的时间还要短。

* **互斥锁适用于长时间等待资源的情况**：当互斥锁获取失败后，就会进入阻塞状态。CPU 首先会进行一次上下文切换，切换到其他线程执行；然后，锁可用时，CPU 又会执行一次上下文切换。一共两次上下文切换，开销是不容小觑的。

#### 乐观锁和悲观锁

前面提到的所有锁，包括后面涉及到的读写锁，其实都是悲观锁。

悲观锁和乐观锁是一种锁的思想：

* 悲观锁认为**多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁**。
* 乐观锁假定**冲突的概率很低，如果根本没有发生冲突，那么就没必要加锁，自然也没有锁的开销**。

乐观锁的工作方式是：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成；如果发现有其他线程已经修改过这个资源，就放弃本次操作**。

至于放弃本次操作之后如何重新尝试，这和具体业务息息相关，虽然重试的成本可能比较高，但是如果冲突的概率足够低的话，乐观锁的性能会更好。

> 乐观锁是无锁编程，只是为了和悲观锁对应才起了乐观锁的名字，这点一定要注意。

我们常常使用的在线文档，其实就是使用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。那么服务器如何检测冲突呢？通常使用的方案是这样的：

* 打开文档时，浏览器会记录下服务端返回的文档版本号。
* 当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号一致则修改成功，否则提交失败。

事实上，我们熟悉的 Git 也是这个工作原理。

### 条件变量

线程可以使用条件变量（condition variable），来等待一个条件变成真。

条件变量是一个**显式队列**，当某些执行状态（即条件，condition）不满足时，线程可以把自己加入队列，等待（waiting）该条件；另外某个线程，当它改变了上述状态时，就可以唤醒一个或者多个等待线程（通过在该条件上发信号），让它们继续执行。

使用条件变量可以很好的解决生产者/消费者问题。

#### 生产者/消费者问题

生产者/消费者问题也叫有界缓冲区问题：假设有一个或多个生产者线程和一个或多个消费者线程，生产者把生成的数据项放入有界的缓冲区中；消费者从缓冲区中取走数据项，以某种方式消费。

很多实际的系统中都会有这种场景。例如，在多线程的网络服务器中，一个生产者将 HTTP 请求放入工作队列（即有界缓冲区），消费线程从队列中取走请求并处理。

我们将使用 Java 语言配合条件变量解决这一问题，代码是完全可以执行的：

```java
public class ProducerAndConsumer {
    private static final int QUEUE_SIZE = 10;
    
    // 用一个队列模拟有界缓冲区，界限为 10
    private static Queue<Integer> queue = new ArrayDeque<>();
    
    // 锁
    private static Lock lock = new ReentrantLock();
    
    // 生产者条件
    private static Condition produceCond = lock.newCondition();
    
    // 消费者条件
    private static Condition consumeCond = lock.newCondition();

    public static void main(String[] args) {
        new Producer("生产者A").start();
        new Producer("生产者B").start();
        new Consumer("消费者A").start();
        new Consumer("消费者B").start();
    }

  	// 消费者
    static class Consumer extends Thread {
        public Consumer(String name) {
            super(name);
        }

        @Override
        public void run() {
            while (true) {
                // 取数据前先上锁
                lock.lock();
                // 如果队列空，就要等待数据，此时通过生产者条件唤醒生产者
                while (queue.size() == 0) {
                    try {
                        System.out.println("队列空，等待数据");
                        produceCond.signalAll();
                        consumeCond.await();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                        produceCond.signalAll();
                    }
                }
                // 队列不空了，取走数据
                queue.poll();
                try {
                    Thread.sleep(500);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + " 从队列取走一个元素，队列当前有：" + queue.size() + "个元素");
                // 解锁
                lock.unlock();
            }
        }
    }

    static class Producer extends Thread {
        public Producer(String name) {
            super(name);
        }

        @Override
        public void run() {
            produce();
        }

        public void produce() {
            while (true) {
                lock.lock();
                while (queue.size() == QUEUE_SIZE) {
                    try {
                        System.out.println("队列满，等待有空余空间");
                        consumeCond.signalAll();
                        produceCond.await();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                        consumeCond.signalAll();
                    }
                }
                queue.offer(1);
                try {
                    Thread.sleep(500);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + " 向队列中插入一个元素，队列当前有：" + queue.size() + "个元素");
                lock.unlock();
            }
        }
    }
}
```

### 信号量

信号量是有一个整数值（sem）的对象，可以用两个函数来操作它。

* **P 操作**：将 sem 减 1，完成后，如果 sem < 0，则进程/线程进入阻塞等待，否则继续。
* **V 操作**：将 sem 加 1，完成后，如果 sem <= 0，则唤醒一个等待中的进程/线程。

P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。

信号量数据结构与 PV 操作的算法描述如下所示：

![image-20220318195229505](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220318195229505.png)

PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原⼦性的。

#### 二值信号量（锁）

如果一个信号量的初始值为 1，那么它实际上就是一个锁。

看下面的 C 语言代码：

```c
sem_t t;
init(&t, 1);

// ...
P(t);
// 临界区
V(t);
```

当一个进程进入临界区之前，会执行 P 操作，信号量的值变为 0，则进入临界区，相当于获取到了锁；此时，另一个线程也来到临界区，执行 P 操作，信号量变为 -1，该线程阻塞；当第一个线程执行完毕以后，执行 V 操作，信号量重新变为 0，唤醒线程二；线程二执行完毕以后，执行 V 操作，信号量重新变为 1，也就是恢复到了最初的状态。

所以，二值信号量和锁是等价的。

#### 使用信号量实现条件变量

由于信号量小于 0 时，线程会进入阻塞，因此完全可以用来实现条件变量。

下面是信号量版本的生产者/消费者问题，使用 Java 实现：

```java
public class ProducerAndConsumer3 {
    private static Semaphore full = new Semaphore(0);
    private static Semaphore empty = new Semaphore(10);
    private static Semaphore lock = new Semaphore(1);

    private static Queue<Integer> queue = new ArrayDeque<>();

    public static void main(String[] args) {
        new Producer("生产者A").start();
        new Producer("生产者B").start();
        new Consumer("消费者A").start();
        new Consumer("消费者B").start();
    }

    static class Producer extends Thread {
        public Producer(String name) {
            super(name);
        }

        @Override
        public void run() {
            while (true) {
                produce();
            }
        }

        private void produce() {
            try {
                empty.acquire();

                lock.acquire(); // 锁住
                queue.offer(1);
                System.out.println(Thread.currentThread().getName() + " 向队列中插入一个元素，队列当前有：" + queue.size() + "个元素");
                Thread.sleep(500);
                full.release();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                lock.release();
            }
        }
    }

    static class Consumer extends Thread {
        public Consumer(String name) {
            super(name);
        }

        @Override
        public void run() {
            while (true) {
                consume();
            }
        }

        private void consume() {
            try {
                full.acquire();

                lock.acquire(); // 锁住
                queue.poll();
                System.out.println(Thread.currentThread().getName() + " 从队列取走一个元素，队列当前有：" + queue.size() + "个元素");
                Thread.sleep(500);
                empty.release();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                lock.release();
            }
        }
    }
}
```

要点：

1. 由于信号量只能在 0 这个点唤醒/阻塞线程，因此需要两个信号量模拟两个条件，请注意信号量的初始值设定。
2. 由于信号量并不保证原子性，因此还需要一个锁，可以使用信号量或真正的锁。

### 经典同步问题

#### 哲学家就餐问题

哲学家就餐问题是一个著名的并发问题，这个问题之所以出名，是因为它很有趣，引人入胜，但其实用性却不强。

这个问题简单描述如下：

1. 五个哲学界围坐在一张圆桌周围

2. 每个哲学家面前都有一盘通心粉，由于通心粉很滑，所以需要两把叉子才能夹住。

3. 相邻两个盘子之间放有一把叉子。

   如下图所示：

   ![image-20220319145536286](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220319145536286.png)

4. 哲学家的生活中有两种交替活动时段：即吃饭和思考。当一个哲学家觉得饿了时，他就试图分两次去取其左边和右边的叉子，每次拿一把，但不分次 

   序。如果成功地得到了两把叉子，就开始吃饭，吃完后放下叉子继续思考。

首先，我们抽象一下哲学家的动作：

```java
while (true) {
    think(); // 思考
    getfork(i); // 拿到左手叉子
    getfork((i + 1) % 5); // 拿到右手叉子
    eat(); // 进食
    putfork(i); // 放下左手叉子
    putfork(i); // 放下右手叉子
}
```

你现在可能会想：假设 getfork 和 putfork 都是原子操作，并且 getfork(i) 以后，i 号叉子不会再被其他人拿到，那么我们的问题就得到了解决。事实真的如此吗？

假设所有哲学家同时开始拿左手边的叉子，那么会造成所有人只拿一把叉子而拿不到第二把，从而导致死锁！看下面的图示：

![image-20220319145556847](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220319145556847.png)

这个问题很简单，我们只要破坏拿叉子的顺序就可以解决了，比如让奇数号的哲学家先拿右边的叉子，而偶数号的哲学家先拿左边的叉子，代码实现如下：

```java
public class Philosopher {
    // 信号量就可以确保原子操作，信号量的初始值必须都为 1
    private static Semaphore[] forks = new Semaphore[5];

    static {
        for (int i = 0; i < forks.length; i++) {
            forks[i] = new Semaphore(1);
        }
    }

    public static void main(String[] args) throws InterruptedException {
        new Thread(() -> {
            try {
                philosopher(0);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                philosopher(1);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                philosopher(2);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                philosopher(3);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                philosopher(4);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();
    }

    public static void philosopher(int i) throws InterruptedException {
        while (true) {
            think();

            if (i % 2 == 0) {
                forks[i].acquire();
                forks[(i + 1) % 5].acquire();
            } else {
                forks[(i + 1) % 5].acquire();
                forks[i].acquire();
            }

            eat();

            forks[i].release();
            forks[(i + 1) % 5].release();
        }
    }

    public static void think() throws InterruptedException {
        System.out.println(Thread.currentThread().getName() + "正在思考");
        Thread.sleep(2000);
        System.out.println(Thread.currentThread().getName() + "思考结束");
    }

    public static void eat() throws InterruptedException {
        System.out.println(Thread.currentThread().getName() + "正在就餐");
        Thread.sleep(2000);
        System.out.println(Thread.currentThread().getName() + "就餐结束");

    }
}
```

这个问题由迪杰斯特拉所提出并解决，事实上他也是使用类似这种方式解决的。

除此之外，你还可以使用一个数组来记录每个哲学家的状态，表示正在思考或就餐，对于任意一位哲学家来说，只有他身边的两个哲学家不在就餐时，他才能就餐。

#### 生产者/消费者问题

我们在条件变量一节和信号量一节中详细的展示了，这里就不再赘述了。

#### 读者/写者问题

读者/写者问题也是经常会使用的模型，常见于数据库和文件 I/O 中。

读者只能读取数据，而不能修改数据；写者既可以修改数据也可以读取数据。也就是我们常说的读锁和写锁，也叫共享锁和排它锁（独享锁）。

通过分析问题，我们可以得到以下几个结论：

1. 读者之间不阻塞：同一时刻，允许多个读者读取数据。
2. 读者写者之间互斥：没有写者时读者才能读，没有读者时写者才能写。
3. 写者之间互斥：如果存在自己之外的比自己先来的写者，则只有这个先来的写者可以写。

解决代码如下：

```java
public class ReaderWriter {
    private static Semaphore writeLock = new Semaphore(1);
    private static Semaphore readLock = new Semaphore(1);
    private static Semaphore flag = new Semaphore(1);
    private static int readers = 0;

    public static void writeLock() throws InterruptedException {
        flag.acquire();
        writeLock.acquire();
        write();
        writeLock.release();
        flag.release();
    }

    private static void write() throws InterruptedException {
        System.out.println(Thread.currentThread().getName() + "正在写入");
        Thread.sleep(2000);
        System.out.println(Thread.currentThread().getName() + "写入完毕");
    }

    public static void readLock() throws InterruptedException {
        flag.acquire();
        readLock.acquire();
        if (readers == 0) {
            writeLock.acquire();
        }
        readers++;
        readLock.release();
        flag.release();

        read();

        readLock.acquire();
        readers--;
        if (readers == 0) {
            writeLock.release();
        }
        readLock.release();
    }

    private static void read() throws InterruptedException {
        System.out.println(Thread.currentThread().getName() + "正在读取");
        Thread.sleep(2000);
        System.out.println(Thread.currentThread().getName() + "读取完毕");
    }

    public static void main(String[] args) {
        new Thread(() -> {
            try {
                readLock();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                readLock();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                readLock();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                readLock();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                writeLock();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(() -> {
            try {
                writeLock();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();
    }
}
```

要点：

1. 使用两个信号量表示读锁和写锁，并使用一个变量记录读者数量。

   读锁并不是真正锁住读者，而是为了保证在修改读者数量时能原子性修改。

   写锁是用于锁住其他读者或写者。

2. 在读锁内部修改完读者数量后，需要释放读锁，因为读操作不会被阻塞。

3. 使用 flag 信号量可以实现一个较为公平的读写锁。

   具体来说，如果没有 flag，且读者先到来，则写者将被阻塞；此时，如果写者到来之后还有多个读者到来，则读者可以一直进入临界区，写者将会一直被阻塞，直到所有读者离开。

   而加上了 flag，上面的情况将不会发生，写者只会等待在它前面到来的读者，因为写者执行了 flag 的 P 操作，后到来的读者再执行 P 操作就会进入阻塞，直到写者写完释放掉信号量。 

## 并发问题

### 死锁

在多线程编程中，我们为了防止多线程竞争共享资源而导致数据错乱，都会在操作共享资源之前加上互斥锁，只有成功获得到锁的线程，才能操作共享资源，获取不到锁的线程就只能等待，直到锁被释放。

那么，当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成**两个线程都在等待对方释放锁**，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了**死锁**。

![image-20220319155452302](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220319155452302.png)

死锁的规范定义：**如果一个线程集合中的每个线程都在等待只能由该线程集合中的其他线程才能引发的事件，那么，该线程集合就是死锁的。**由于所有的线程都在等待，所以没有一个线程能引发可以唤醒该线程集合中的其他线程的事件，这样，所有的线程都只好无限期等待下去。

#### 死锁的条件

死锁的出现必须满足以下四个条件：

* 互斥：线程对于需要的资源进行互斥的访问。
* 持有并等待：线程持有了资源，同时又在等待其他资源。
* 非抢占：线程获得的资源不能被抢占。
* 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的。

如果这 4 个条件的任何一个没有满足，死锁就不会产生。

#### 解决死锁的办法

##### 死锁检测与死锁恢复

这种方式的思想是：**并不阻止死锁，而是让死锁发生；当检测到死锁发生后，采取措施修复死锁。**

检测死锁的简单思想是：构造一张资源分配图，使用检测有向图是否存在环路的算法来检测死锁。

检测死锁的方法多种多样，这里就不再深入讲解如何检测死锁，有大量专门的，现成的工具来帮助我们检测死锁。我们的重点在于死锁恢复。

> **死锁检测工具**
>
> 如果你使用 Java 写程序，你可以使用 `jstack` 工具，它是 jdk 自带的线程堆栈分析工具。
>
> 如果你使用 C/C++，且在 Linux 系统上，你可以使用 `pstack` 命令。

###### 死锁恢复

一般来说，死锁恢复并没有特别完美的办法，总是会存在一些令人不满意的点。下面是常见的死锁恢复方法：

1. **利用抢占恢复**。在不通知原进程的情况下，将某一资源从一个进程强行取走给另一个进程使用，接着又送回去。这种做法主要取决于资源本身的特性。

   用这种方法恢复通常比较困难或者说不太可能。若选择挂起某个进程，则在很大程度上取决于哪一个进程拥有比较容易收回的资源。

2. **利用回滚恢复**。如果系统设计人员以及主机操作员了解到死锁有可能发生，他们就可以周期性地对进程进行检查点检查，然后备份。死锁发生后，将系统恢复到最近的一次备份，然后通过检查点分析资源的分配，通过人工分配资源来恢复。

3. **通过杀死进程恢复。**最直接也是最简单的解决死锁的方法是杀死一个或若干个进程。一种方法是杀掉环中的一个进程。如果走运的话，其他进程将可以继续。如果这样做行不通的话，就需要继续杀死别的进程直到打破死锁环。

##### 死锁预防

死锁预防指的是**破坏死锁产生的四个条件，从而在根本上预防死锁**。

* 破坏互斥条件：破坏互斥条件就是使用无锁编程，比如使用乐观锁机制。最常见的乐观锁机制就是 CAS。
* 破坏持有并等待条件：对于持有并等待条件，可以采取在请求资源统计所有需要资源的方式，一次性的分配所有资源；除此之外，还可以要求进程在获取新资源之前，先释放已经持有的资源。
* 破坏非抢占条件：当获取不到资源时，多数进程会选择阻塞；然而进程可以选择尝试获取资源，获取不到的时候不阻塞，而是做其他事情。这样就破坏了非抢占条件。
* 破坏循环等待条件：破坏循环等待是最常用的方法，一般可以让限定让线程统一按照同一个顺序获取资源，如果按照此规则获取资源，则一定不会出现死锁。

##### 死锁避免

如果我们能了解全局的信息，包括不同线程在运行中对锁的需求情况，就能使得后续的调度能够避免产生死锁。

###### 银行家算法

银行家算法是操作系统的经典算法之一，用于避免死锁情况的出现。

它最初是为银行设计的（因此得名），通过判断借贷是否安全，然后决定借不借。在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。

用在操作系统中，**银行家、出借资金、客户**，就分别对应**操作系统、资源、申请资源的进程**。

每一个新进程进入系统时，必须声明需要每种资源的最大数目，其数目不能超过系统所拥有的的资源总量。当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程，若有，再进一步计算在将这些资源分配给进程后，是否会使系统处于不安全状态如果不会才将资源分配给它，否则让进程等待。

为了实现银行家算法，在系统中必须设置这样四个数据结构：

1. **Available 向量**：系统中可利用的资源数目
2. **Max 矩阵**：每个进程对每种资源的最大需求
3. **Allocation 矩阵**：每个进程已分配的各类资源的数目
4. **Need 矩阵**：每个进程还需要的各类资源数

其中三个矩阵间存在下述关系：**`Need[i, j] = Max[i, j] - Allocation[i, j]`**。

同时，$Request_i$ 向量为进程 $P_i$ 的请求资源的向量，如果 $Request_i$[j] = K，表示进程 $P_i$ 需要 K 个 j 类型的资源，算法流程如下：

1. 若 $Request_i$[j] <= Need[i, j]，执行第二步；否则认为出错，因为它请求的已经超过了它所宣布的值。
2. 若 $Request_i$[j] <= Available[j]，执行第三步；否则认为出错，因为它请求的已经超过了系统中的可用值。
3. 系统尝试把资源分配给进程 $P_i$，并修改下面数据结构中的数值：
   * Available[j] = Available[j] – $Request_i$[j]
   * Allocation[i,j] = Allocation[i,j] + $Request_i$[j]
   * Need[i,j] = Need[i,j] – $Request_i$[j]
4. 试分配后，执行安全性算法，检查此次分配后系统是否处于安全状态。若安全，才正式分配；否则，此次试分配作废，进程 $P_i$ 阻塞。

安全性算法需要额外两个数据结构

1. Work 向量：它表示系统可提供给进程继续运行所需的各类资源数目，在执行安全算法开始时，Work = Available。
2. Finish 向量：它表示系统是否有足够的资源分配给进程，使之运行完成，初始化应该是全设为 false。

流程如下：

1. 初始化向量，Word = Available，Finish 全部置为 false。

2. 从进程集合中找到一个能满足下述条件的进程：

   1. Finish[i] = false
   2. Need[i,j] <= Work[j]

   若找到， 执行步骤 3；否则，执行步骤 4。

3. 当进程 $P_i$ 获得资源后，假设它能顺利执行，直至完成，并释放出分配给它的资源，故应执行：

   1. Work[j] = Work[i] + Allocation[i, j]
   2. Finish[i] = true
   3. 回到第 2 步

4. 如果所有进程的 Finish[i] 都为 true， 则表示系统处于安全状态；否则，系统处于不安全状态。

### 活锁

活锁指的是任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。 

活锁和死锁的区别在于：处于活锁的实体是在不断的改变状态。

**活锁是有可能自行解开的，死锁则不行。**

### 饥饿

饥饿，与死锁和活锁非常相似，是指一个可运行的进程尽管能继续执行，但被调度器无限期地忽视，而不能被调度执行的情况。

饥饿可以通过修改调度策略来避免。

## 进程间通信（IPC）

进程间有时需要一种消息传递机制，能够传递消息，被称作进程间通信（Inter Process Communication）机制。

我们知道，进程有自己的内存空间，因此一般来说，是不能随便访问的。但是我们即将会讲到，进程的内存空间分为用户空间和内核空间，内核空间是所有进程共享的。

但是，内核空间也是不能随便访问的，需要借助系统调用，所以**进程间通信必须通过内核**。

![image-20220319194210943](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220319194210943.png)

本节以 Linux 系统为例，讲一下常见的进程通信方式。

### 管道

管道（Pipe）本质上是一个文件，**管道一端的进程以写方式打开，另一端的进程以读方式打开**，于是就可以实现通信。

虽然管道实现形态上是文件，但是管道本身并不占用磁盘或者其他外部存储的空间。在 Linux 的实现上，它占用的是内存空间。所以，**Linux 上的管道就是一个操作方式为文件的内存缓冲区**。

Linux 上的管道分为匿名管道和命名管道：

1. 匿名管道就是指**没有名字的管道**。

   在 Linux 系统中，会以 `|` 连接两个命令，前一个命令的输出会作为后一个命令的输入，而一个命令就是一个实际的进程，`|` 就代表一个匿名管道，用于进程间通信。

   `|` 两边的进程实际上都是 shell 的子进程，shell 首先打开一个管道文件，获取一个文件描述符，然后通过 fork 产生两个子进程，子进程都有管道描述符的拷贝，因此两边可以进行通信。

   **子进程通过复制父进程的地址空间获取到该管道的描述符**，然后通过 exec 执行其他进程。这样一来，该管道的文件描述符只有父子进程能够获取到，因此没有名字，匿名管道就是这么来的。

   **匿名管道保证了数据传输的安全性，但是却无法保证通用性，因此命名管道就出现了**。

2. 命名管道是指用显式命令创建的管道，创建时需要起一个名字，因此称作命名管道。

   可以使用 `mkfifo` 或 `mknod` 创建一个命名管道：

   ```shell
   $> mkfifo pipe
   ```

   这和创建一个文件没有什么区别。

无论是命名管道还是匿名管道，Linux 系统底层都一视同仁，使用的都是 pipefs 文件系统。

**往管道中写入数据后，写进程会阻塞直到有读进程读取管道中的内容。**

Linux 提供了系统调用 `int pipe(int fd[2])` 来在编程中使用匿名管道，并返回了两个描述符，一个是管道的读取端描述符 fd[0] ，另一个是管道的写入端描述符 fd[1] 。然后，调用 fork，使得子进程也有 fd[0] 和 fd[1]：

![image-20220319201329740](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220319201329740.png)

但是，由于**管道只能一端写，一端读**，因此一般父进程关闭写入/读取，而子进程关闭读取/写入。

### 消息队列

管道通信效率比较低，因此管道不适合进程间频繁地交换数据。

而使用消息队列就可以解决这个问题，比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。

**消息队列是保存在内核中的消息链表**，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块）。

消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。

**如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。**

消息队列的生命周期和内核一致，如果没有释放消息队列或者关闭操作系统，那么它会一直存在。

消息队列的通信模式就像邮件一样，一方只需要发出去就够了，另一方只需要去信箱中拿就够了。

消息队列也有不足，一是**通信不够及时**，二是**消息体大小有限制**。

### 共享内存

消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷⻉过程，这个开销是比较大的。共享内存能很好地解决这个问题。

**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写入的东西，另外一个进程马上就能看到了，就不需要拷贝，大大的提升了进程间通信的速度。

### 信号量

信号量并不是传统意义上的通信，它并不能缓存消息，但是能够协调进程间的同步和互斥。详见信号量一节。

### 信号

上述方式都是正常模式下的进程间通信，而异常状态下的进程间通信就要通过**信号**来通信。

信号跟信号量虽然名字相似度 66.67%，但两者用途完全不一样，就好像 Java 和 JavaScript 的区别。

在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 `kill -l` 命令，查看所有的信号：

![image-20220319203044388](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220319203044388.png)

运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如

* Ctrl+C 产⽣ SIGINT 信号，表示终止该进程

* Ctrl+Z 产⽣ SIGTSTP 信号，表示停止该进程，但还未结束

如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程的 PID 号。

信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产⽣，我们就有下面这几种用户进程对信号的处理方式：

1. **执行默认操作**。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。
2. **捕捉信号**。我们可以定义一个信号处理函数专门处理一种信号，收到信号时，就会调用该函数来处理。
3. **忽略信号**。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。

有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。

### 套接字（Socket）

**套接字用于不同主机上的进程间的通信**，也就是所谓的网络通信；当然，Socket 也可以用于同一主机上的进程间通信。

我们来看看创建 socket 的系统调用：

```c
int socket(int domain, int type, int protocol);
```

三个参数分别代表：

* domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机；

* type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；
* protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol ⽬前一般写成 0 即可；

#### TCP 通信

在 TCP 模式下，通信模式如下：

![image-20220319204937657](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220319204937657.png)

* 服务端和客户端初始化 socket ，得到文件描述符；

* 服务端调用 bind ，将绑定在 IP 地址和端⼝;

* 服务端调用 listen ，进行监听；

* 服务端调用 accept ，等待客户端连接；

* 客户端调用 connect ，向服务器端的地址和端⼝发起连接请求；

* 服务端 accept 返回用于传输的 socket 的文件描述符；

* 客户端调用 write 写入数据；服务端调用 read 读取数据；

* 客户端断开连接时，会调用 close ，那么服务端 read 读取数据的时候，就会读取到了 EOF ，待处理完数据后，服务端调用 close ，表示连接关闭。

这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是**两个** socket。

#### UDP 通信

在 UDP 模式下，通信模式如下：

![image-20220319210409429](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220319210409429.png)

UDP 是没有连接的，所以不需要三次握⼿，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端⼝号，因此也需要 bind。另外，每次通信时，调用 sendto 和 recvfrom，都要传入⽬标主机的 IP 地址和端⼝。

#### 本地通信

本地 socket 被用于在**同一台主机上进程间通信**的场景：

* 本地 socket 的编程接⼝和 IPv4 、IPv6 套接字编程接⼝是一致的
* 本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现

对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM；对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。

本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是**绑定一个本地文件**，这也就是它们之间的最大区别。
