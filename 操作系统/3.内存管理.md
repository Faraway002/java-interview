[TOC]

# 内存管理

内存管理是操作系统设计中最重要和最复杂的内容之一。虽然计算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。

## 1. 历史发展

> **OS 不能脱离硬件**
>
> 作为 OS 的基础，CPU 能支持什么样的内存访问模型，OS 就必须遵守该模型。

早期的 CPU 设计是让 CPU 直接访问物理内存。这种机制的好处在于不需要额外的开销；但是坏处也显而易见：程序中的地址必须硬编码，CPU 才能够访问到。试想有两个进程硬编码到同一地址，第二个进程在运行时很有可能会覆盖掉第一个进程占用的地址，导致第一个进程直接崩溃。

早期，CPU 还受到成本的限制，经常会出现 CPU 是 16 位，而地址总线是 20 位，那么如何让 16 位的 CPU 访问 20 位的地址？答案就是引入**段**，通过`基址 + 偏移量`的方式访问地址，从而访问更大的地址空间。

至于为什么称之为段，其实就是因为寄存器只有 16 位，一次性最多只能访问 64 KB，所以需要移动基地址，一段一段的去访问所有的内存空间。

为此，Intel 还引入了**段寄存器**，可以说这类寄存器是专门为分段而生，它存放了段的基地址，进程中的地址实际上是在该段的偏移量，

那么有人就会问：`基址 + 偏移量`最多也就是两个 16 位的数相加，最大也就是 17 位，怎么能访问到 20 位的地址？

其实，具体的计算规则是：真实地址 = 段基地址左移 4 位+ 段内偏移，假设要访问 0x05808，那么基地址就是 0x0580，偏移量是 0x0008，这样就能够访问到 0x05808 了。

![image-20220316144301039](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220316144301039.png)

不过，分段仍然没有解决进程之间可以随意相互访问地址的问题，为此，Intel 又提出了**保护模式**，设置一个 GDT（全局描述符表）记录所有的`段属性 + 段基地址 + 段界限`，在 CPU 访问地址时，做一个边界检查以及权限检查（DPL >= CLP 才允许访问），从而限制非法访问。

这样很好的限制了用户进程，用户进程不能轻易的覆盖操作系统的系统进程，因此操作系统得到了保护。

> 没有判断权限的访问内存的模式称之为**实模式**，我们在前置知识中已经了解过这些知识点。

分段虽然解决了上述问题，但是随着时代的发展，分段的用处没有那么大了，以 32 位 CPU 为例，单单段内偏移就可以访问到 4GB 空间，因此这意味着访问更大空间的段机制几乎没有用了（事实上 Linux 就是这么干的）。但是为了**向前兼容**，Intel 将分段机制保留了下来。

分段的一个最大的缺点就是分段的粒度比较粗，容易产生内存碎片，也不方便管理，因此**分页**应运而生，把内存分为一页一页，每一页大小固定（比如 4 KB），以页为单位来管理内存。

即使有了分段和分页机制，用户进程和用户进程之间（同一权限）还是存在覆盖的风险。这时就必须靠操作系统提供一种抽象，让每个进程拥有自己独立的**内存空间**，程序内编码的地址是在自己内存空间内的相对地址，由操作系统把这个相对地址翻译成绝对的物理内存地址。这就是**虚拟内存**，进程拥有的内存空间也叫做**地址空间**。

## 2. 虚拟内存

为了给**每个进程**一个独立的环境，操作系统将内存虚拟化，为每个进程分配独立的**地址空间**。

**进程在代码中涉及到的地址都是虚拟地址，从虚拟地址到物理地址的转换由操作系统来处理**，这样既可以保证程序的简单性，又能够确保内存空间都由操作系统统一管理。

虚拟内存还为进程提供了一个假象：**进程独享整个内存空间**，这就为大型的应用程序提供了支持。操作系统可以先为大型应用程序分配虚拟地址空间，但是虚拟内存空间并不立即和物理地址空间进行映射，而是按需映射，内存分配的灵活性更高了。

虚拟内存必须能够**高效地把虚拟地址转换为物理地址**，为此，需要借助硬件地支持，同时，操作系统必须正确地设置硬件，保证能够得到正确的地址。

### 2.1 进程地址空间的组成

我们知道，地址总线决定了 CPU 的寻址能力，在 32 位的机器上，配上 32 位的 CPU，最大能够寻址 4 GB 的内存空间，为了能够给进程一个独享整个内存空间的假象，地址空间的大小就定为 4 GB。

Linux 把这 4 GB 分为两部分，最高的 1 GB 供内核使用，称为**内核空间**，剩余的是**用户空间**。因为进程可以通过陷阱指令陷入内核，因此内核空间实际上是所有进程共享的。

示意图如下：

![image-20220321172635246](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321172635246.png)

在 64 位 Linux 系统中，内核空间有 128 T，用户空间也有 128 T，中间剩余的是未定义的：

![image-20220321192137996](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321192137996.png)

当然，现在没有硬件能够达到 128 T 的内存，因此是完全够用的。

内核空间主要存放内核的代码以及数据，它们是所有进程共享的，为了达到最高速度，但是又要保证内存虚拟化，Linux 就把内核空间直接和物理内存的最开始部分（0 ~ 0x3FFFFFFF）进行映射，如下图所示：

![image-20220321193012162](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321193012162.png)

注意，这里物理内存并不一定是 0 ~ 1G，因为物理内存的大小不能确定，所以操作系统会进行等比收缩，但 32 位系统最大也就是 1G。

接下来，我们看一下用户空间内部的结构是怎样的：

![image-20220321193603611](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321193603611.png)

我们看到，一个进程的用户空间被分为代码段（程序文件）、已初始化数据段、未初始化数据段、堆、文件映射段（库函数等）、栈。

堆从低地址向高地址正向增长，而栈是从高地址向低地址反向增长，文件映射段也是可以动态分配的。

使用 C 语言的 `malloc` 就可以在堆中分配内存，而使用 `mmap` 则可以在文件映射段分配内存。

> 至于用户空间为什么要分为这么多段，我们很快就能在内存分段中见到答案。

## 3. 内存分段

进程的地址空间被分为若干个逻辑段，比如代码段，数据段，堆，栈等等，这其实是为了更好的利用内存而出现的。

举个例子，假设一个进程的地址空间大小是 16 KB，物理地址空间为 64 KB，如果没有分段，那么这个进程的地址空间将被一整个放进内存中，假设这个进程被放在如下图所示的位置处：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321200901581.png" alt="image-20220321200901581" style="zoom:67%;" />

如果此时有一个 32 KB 的进程需要分配内存，那么虽然物理内存足够，但是却并不能成功的分配内存。

当物理内存支持分段以后，进程空间也分段，此时就把某一段的内容放到对应的物理段中：

<img src="https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321200711009.png" alt="image-20220321200711009" style="zoom:67%;" />

这样一来，就能够合理的利用内存。

### 3.1 机制

在内存分段中，每一个物理段都由基址和偏移量索引，使用`基址 + 偏移量`的方式就可以很快定位到一个具体的物理内存单元。

虚拟地址中，至少需要两部分，即段选择符 + 段内偏移量。如下图所示：

![image-20220321201155869](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321201155869.png)

* **段选择因子**保存在段寄存器里面。段选择因子里最重要的是**段号**，用作段表的索引。**段表**里保存的是这个**段的基地址、段的界限和特权等级**等。

  特权级非常重要，保护模式规定特权级有四级，绝大多数操作系统都只使用了最低的一级和最高的一级（用户态和内核态），**高特权级可以随意访问低特权级，但是反过来则不行**。

* **段内偏移量**应该位于 0 和段界限之间。

段表是为了加快索引速度而设置的，同时也是为了解决段寄存器和段偏移寄存器不够的问题。

### 3.2 缺陷

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有⼀些不足之处：

1. 很容易产生**内存碎片**。

   假设有 1 G 的物理内存，用户执行了多个程序，其中：

   * 游戏占用了 512MB 内存。
   * 浏览器占用了 128MB 内存。
   * 音乐占用了 256 MB 内存。

   这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。

   如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开⼀个 200MB 的程序：

   ![image-20220321210542316](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321210542316.png)

   这⾥的内存碎片的问题共有两处地⽅：

   * 外部内存碎片（外碎片），也就是产生了多个不连续的小物理内存，导致新的程序⽆法被装载。

   * 内部内存碎片（内碎片），程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费。

   内碎片几乎是难以完全避免的，我们不讨论内碎片的解决办法；外碎片需要使用一些机制来避免，主要是**内存交换**以及使用更好的**物理内存分配策略**。

   **内存交换指的是把一个进程临时存放在硬盘上，然后再从硬盘上读回来到内存里；不过再读回的时候，我们不能装载回原来的位置，而是紧跟上一个进程占用的内存空间的后面**，这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。

   Linux 专门有一块区域用于交换进程，也就是所谓的**交换空间**。

   **使用更好的物理内存分配策略则是在源头上解决这个问题**，在内存分配的时候就找到一个合适的位置，这样就能极大的减少外碎片的产生（这是一个比较重要的主题，将额外使用一节的篇幅来讲解）。

2. 内存交换的效率低。

   这是因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。所以，**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿**。我们一般会采取二者结合的方式来解决外碎片的问题。

## 4. 内存分页

### 4.1 基本机制

分段的好处就是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。

要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是**内存分页**（paging）。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（Page）。在 32 位的 Linux 下，每一页的大小为 `4KB`。

虚拟地址与物理地址之间通过**页表**来映射，如下图：

![image-20220322143831154](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322143831154.png)

页表需要存放每一个虚拟页映射到的物理页的映射关系，而由于一页的大小远超一个字节，当需要在一页中取出某个地址的数据时，需要提供页内偏移量。

因此**虚拟内存地址至少需要包括页号和页内偏移量两部分**。由此，我们得到一个更详细的转换关系：

![image-20220322144604270](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322144604270.png)

虚拟页号我们称之为 VPN（Virtual Page Number），物理页号则是 PPN（Physical Page Number）。

**页表是每进程的数据结构**，每个进程的地址空间的页都会映射到一个物理页中，因此每个进程都需要一个页表。操作系统在调度该进程时，会从它的页表中寻找映射。

由于内存空间都是预先划分好的，也就不会像分段机制一样会产生间隙非常小的内存。**采用了分页，释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存碎片。**

#### 4.1.1 页的换入换出（Swap 机制）

如果物理内存空间不够，操作系统会把其他正在运行的进程中的**应该换出**的内存页面暂时写在硬盘上，称为**换出**（Swap Out）。

当再次需要的时候，再加载进来，称为**换入**（Swap In）。

通常来说，换入换出涉及到的页面不会太多，因此不会像分段一样把整个地址空间都写到磁盘上，提高了内存交换的效率。

示意图如下：

![image-20220322151414597](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322151414597.png)

更进一步，**分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中**。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去**。

Linux 专门为换入换出提供了一块磁盘空间，称作**交换空间**，在 Windows 上，叫做虚拟内存。

### 4.2 缺页异常

由于换入换出的机制，因此一个进程的物理页有可能并不在物理内存中，此时 CPU 未访问到该物理页，从而引发一个**缺页异常**。

根据我们之前了解到的中断知识，有一个缺页异常处理程序被提前设置到内存中，处理缺页异常时就会执行该处理程序。

缺页处理程序所做的事基本上就是把页从磁盘中换入到内存中，但是和其他异常不同的事，换入完毕之后，**CPU 的 PC 会继续指向上一次发生缺页异常的指令，继续执行**。而一般的异常是返回到**发生错误的下一条指令**执行。

整个缺页异常的处理流程如下：

![image-20220322154849497](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322154849497.png)

1. 在 CPU 里执行一条 Load M 的加载指令，然后 CPU 会去找 M 所对应的页表项。
2. **如果该页表项的状态位是有效的，那 CPU 就可以直接去访问物理内存了；如果状态位是无效的，则 CPU 则会发送缺页中断请求。**
3. 操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。
4. 找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，**需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。**
5. 页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为有效的。
6. 最后，CPU 重新执行导致缺页异常的指令。

我们之前看到的页表项仅涉及 VPN 和 PPN，事实上，页表项的内容含有更多的信息，如下图所示：

![image-20220322155058233](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322155058233.png)

上面的流程还有一个问题，如果在物理内存中没有找到空闲的页面，该怎么办？这个时候，就**不得不从内存中找一个页面换出，然后把我们需要的页面换入**。

该换出什么页面？这就涉及到**页面置换策略**，策略**要尽可能的减少页面换入换出的次数**，以提高性能。

### 4.3 页面置换策略

#### 4.3.1 最佳页面置换

最佳页面置换算法基本思路是，**置换在未来最长时间不访问的页面**。

所以，该算法实现需要计算内存中每个逻辑页面的下一次访问时间，然后比较，选择未来最长时间不访问的页面。

我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：

![image-20220322190201815](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322190201815.png)

在这个请求的页面序列中，缺页共发生了 `7` 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 `4` 次。

**这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在下一次访问前的等待时间。**

所以，**最佳页面置换算法作用是为了衡量你的算法的效率**，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

#### 4.3.2 先进先出置换

先进先出（FIFO）是最简单的策略，它总是替换最先来到内存中的页面。整个过程如下图所示：

![image-20220322173642237](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322173642237.png)

在这个例子中，页面经常被换入换出，我们称之为**抖动**。

#### 4.3.3 最近最少使用置换

最近最少使用（Least Recently Used，LRU）的基本思路是**发生缺页时，选择最长时间没有被访问的页面进行置换**，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

这种算法近似最优置换算法，最优置换算法是通过**未来**的使用情况来推测要淘汰的页面，而 LRU 则是通过**历史**的使用情况来推测要淘汰的页面。

![lru](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/lru.png)

在这个请求的页面序列中，缺页共发生了 `9` 次，页面置换共发生了 `6` 次，跟 FIFO 比较起来，性能提高了一些。

LRU 是很常用的缓存机制，而不仅仅是运用在操作系统中，高层次的应用程序也会使用 LRU 缓存。

为了实现 LRU，需要**维护一个所有缓存的链表，最近最多使用的缓存内容在表头，最近最少使用的缓存内容在表尾**。如果链表中有一个缓存最近被使用了，则需要在链表中找到这个缓存的位置，然后将它移动到表头。为了加快索引，还可以使用哈希表，哈希表的键是缓存的 key，值则是链表节点。

下面是一个 LRU 缓存的 Java 实现，其中链表是自己实现的（因为本段代码是面试常考，在这里做详细讲解），实现思路请参见代码注释：

```java
public class LRUCache<K, V> {
    private Map<K, Node<K, V>> cache = new HashMap<>();

    // 链表节点，也可以使用自带的链表
    private static class Node<K, V> {
        K key;
        V value;
        Node<K, V> prev;
        Node<K, V> next;
    }

    // 设定一个虚拟头节点和虚拟尾节点
    private Node<K, V> head, tail;

    private int size;

    private int capacity;

    public LRUCache(int capacity) {
        this.capacity = capacity;
        head = new Node<>();
        tail = new Node<>();
        head.next = tail;
        tail.prev = head;
    }
    
    public V get(K key) {
        // 在哈希表中找，如果找到了则把它移动到链表头部，然后返回
        // 否则，返回 null
        Node<K, V> cur = cache.get(key);
        if (cur == null) {
            return null;
        }
        moveToHead(cur);
        return cur.value;
    }
    
    public void put(K key, V value) {
        // 如果链表中未缓存此键值对
        if (cache.get(key) == null) {
            // 构建一个新节点
            Node<K, V> cur = new Node<>();
            cur.key = key;
            cur.value = value;
            // 哈希表的 put
            cache.put(key, cur);
            // 新加的缓存表示是最近使用的，放到头部
            addFirst(cur);
            size++;

            // size 已经超过了容量，移除最少使用的
            if (size > capacity) {
                Node<K, V> tail = removeLast();
                cache.remove(tail.key);
                --size;
            }
        } else {
            // 覆盖原有的值
            Node<K, V> cur = cache.get(key);
            cur.value = value;
            // 新加的缓存表示是最近使用的，移动到头部
            moveToHead(cur);
        }
    }

    private void moveToHead(Node<K, V> cur) {
        cur.prev.next = cur.next;
        cur.next.prev = cur.prev;

        cur.next = head.next;
        cur.prev = head;

        head.next.prev = cur;
        head.next = cur;
    }

    private void addFirst(Node<K, V> cur) {
        cur.next = head.next;
        cur.prev = head;
        head.next.prev = cur;
        head.next = cur;
    }

    private Node<K, V> removeLast() {
        Node<K, V> ret = tail.prev;
        ret.prev.next = tail;
        tail.prev = ret.prev;
        return ret;
    }
}
```

请参见[[146. LRU 缓存 - 力扣（LeetCode）](https://leetcode-cn.com/problems/lru-cache/)。

#### 4.3.4 最不常用置换

最不常用（Least Frequently Used，LFU）算法的意思不是指这个算法不常用，而是**当发生缺页中断时，选择访问次数最少的那个页面，并将其淘汰**。

它的实现方式是，**对每个页面设置一个访问计数器，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。**

看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。

要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。

除此之外，LFU 算法只考虑了频率问题，没考虑时间的先后性的问题，比如**有些页面在过去时间里访问的频率很高，但是现在已经没有访问了**，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。

解决的办法是**定期减少访问的次数**，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。

### 4.4 更快的分页——TLB

如果只让操作系统在软件层面实现分页，实际上是很慢的，因为要使用分页，就要将内存地址空间切分成大量固定大小的单元（页），并且需要记录这些单元的地址映射信息。因为这些映射信息一般存储在物理内存中，所以在转换虚拟地址时，分页逻辑上需要一次额外的内存访问。**每次指令获取、显式加载或保存，都要额外读一次内存以得到转换信息**。连一个页表都需要这么高的开销，那么我们即将介绍的多级页表则开销会更大。

既然很慢，就要考虑加上缓存，并且这个缓存一定要加在硬件中，才能保证其速度。

地址转换旁路缓冲存储器（Translation Lookaside Buffer，TLB）是频繁发生的虚拟到物理地址转换的**硬件缓存**，通常也被叫做快表：

![image-20220322221209495](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322221209495.png)

> **MMU**
>
> MMU 是 CPU 的内存管理单元，CPU 访问的其实是虚拟地址，CPU 把这个地址交给 MMU 以后，由 MMU 转换为真实物理地址，然后驱动地址总线去物理地址空间中取数据。
>
> 既然 MMU 负责地址的转换，自然要与 TLB 进行交互。

TLB 的容量也是有限的，未命中时则需要直接去页表中取，然后进行替换，这又涉及到一个替换的策略的应用。

### 4.5 更小的表——多级页表

现在我们来考虑页表的大小，假设在 32 位的地址空间中，页的大小为 4 KB，一个页表项是 4 字节，那么一个进程的页表大小就等于 $2^{32}/(4 * 2^{10}) * 4 = 4MB$。假设一个操作系统中有一百个进程在运行，那么操作系统不得不在内存中为这些进程维护 400 MB 的页表，32 位支持的最大物理地址空间也不过 4096 MB，页表就占了十分之一。

因此，我们迫切的需要一项技术缩小页表的大小。一种简单的解决办法是把页的大小设置的更大一点，但是大页面毫无疑问会带来更多内碎片。

更好的解决方式是多级页表，通过设置一个页表的页表，把单级页表转换为类似树的树形结构：

![2](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/2.jpg)

这样做其实并没有减少页表的总大小，反而还加大了，但是，**这是完全映射的情况，我们只需要映射已经使用过的虚拟内存页**。就像下面这样：

![image-20220322224807167](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322224807167.png)

左边是传统的非多级页表，中间的页都没有使用，但是仍然在页表中占位；如果使用多级页表，则一级页表中可以不用分配那两个未使用的二级页表。

假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= `0.804MB`，这是一个巨大的节约。

Linux 中，使用的是三级分页模式，分别是：

- 全局页目录项 PGD（Page Global Directory）
- 上层页目录项 PUD（Page Upper Directory）
- 中间页目录项 PMD（Page Middle Directory）
- 页表项 PTE（Page Table Entry）

![14](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/14.jpg)

## 5. 内存的分配与回收

应用程序要正常执行，肯定是需要申请虚拟内存的。我们知道，进程的地址空间大小取决于计算机的位数，这就导致进程能看到的地址空间很大，但是实际物理内存却没有那么大（比如 64 位的计算机，能访问 TB 级别的空间，但是一般物理内存范围为 1 GB ~ 128 GB）。

这就会导致进程申请的虚拟内存有大有小，可能会很大，大到超过物理内存，但是**操作系统会允许进程申请一块很大的虚拟内存**，这是由于 swap 机制的存在，操作系统认为只要 swap 空间够大，申请那么大的虚拟内存也是没问题的。

那么，如果一个进程申请了超过物理内存大小的虚拟内存，其他进程是不是就没有空间了？其实不是，**当应用程序申请了一块虚拟内存，但是没有真正访问的话，那么操作系统实际上是不会给进程分配物理内存的**，也就是惰性分配的策略。但是，当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生**缺页异常**，并交由中断服务例程处理。

中断处理函数会看是否有空闲的物理内存，如果有，就按照一定策略直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系；否则就进行回收。

整体流程就是上述内容了，接下来我们讨论一下细节。

### 5.1 内存分配策略

通常来说，操作系统会在物理内存的空闲区域的内部维护一个链表，来追踪空闲和已分配的空间。

具体来说，一个链表只需要保存空闲的内存块，每个内存块需要两个基本信息：起始地址和长度。假设有这样一块内存：

![image-20220321222309369](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321222309369.png)

那么它维护的一个链表可能是这样的：

![image-20220321222334230](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220321222334230.png)

空闲空间管理算法会根据当前空闲块状况，选择一块何时的空闲块给进程。

**回收空间时，如果碰到两块连在一起的空闲空间，则还要进行合并，以获得更大的空闲块**。

#### 5.1.1 最优匹配

最优匹配（best fit）策略非常简单：首先遍历整个空闲列表，找到和请求大小一样或更大的空闲块，然后返回这组候选者中最小的一块。这就是所谓的最优匹配（也可以称为最小匹配）。只需要遍历一次空闲列表，就足以找到正确的块并返回。

最优匹配背后的想法很简单：选择最接近它用户请求大小的块，从而尽量避免空间浪费。然而，这有代价。简单的实现在遍历查找正确的空闲块时，要付出较高的性能代价。

可行的优化方法是：对空闲块链表进行从小到大排序，找到的第一个符合要求的空闲块就是最合适的空闲块。

这种匹配方式的**优点就是能够尽可能多的留下大片空间**，有大进程到来的时候能够有空间分配。

**缺点**就是**容易产生小的外碎片**。

#### 5.1.2 最差匹配

最差匹配（worst fit）则和最优匹配相反，每次总是选择候选者中最大的一块，这样分配后剩余的空闲区就不会太小，更方便使用。

优化方法就是将链表从大到小排序，找到的第一个符合要求的空闲块就是最合适的空闲块。

缺点：每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式**会导致较大的连续空闲区被迅速用完**。如果之后**有“大进程”到达，就没有内存分区可用了**。

#### 4.1.3 首次匹配

首次匹配（first fit）的思想是：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。

首次匹配有速度优势（不需要遍历所有空闲块），但有时会让空闲列表开头的部分有很多小块。

#### 5.1.4 邻近匹配

首次匹配每次都从链表的头部开始查找的，这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次**都从上次查找结束的位置开始检索**，就能解决上述问题。

**空闲分区以地址递增的顺序排列**（可使用循环链表）。每次分配内存时**从上次查找结束的位置开始查找空闲分区链表**，找到大小能满足要求的第一个空闲分区。要记录上次查找结束的位置，就需要一个额外的指针来记录。

#### 5.1.5 伙伴算法

伙伴算法是 Linux 采用的策略，很好的解决了外碎片的问题。

Linux 把所有的空闲块按大小分为 **10 个块链表**，**每个链表的一个块大小都为 2 的幂次方，且块大小随链表编号递增而递增**。比如第 0 个链表的块大小是 4 KB，第一个链表的块大小是 8 KB，...，第 9 个链表的块大小是 2 MB。

> 实际上，一个块含有 $2^n$ 个页面，这是分页的知识点，我们很快就会讲到。现在至少需要知道：
>
> 1. 一个页面的大小在不同的机器上是不同的，32 位的机器上一般是 4 KB，64 位机器上一般是 8 KB。
> 2. 我们知道内存的一个地址表示一个字节，事实上**在分页以后，对于虚拟内存来说，内存的最小单位是一页，32 位系统上也就是 4096 字节**。

数据结构如下：

```C
struct free_area_struct {
    struct page* next;
    struct page* prev;
    
    // ...
} free_area[10];
```

我们发现，数组的每一个元素都是一个链表项，链表项和其他链表项相连形成了 10 个双向链表。

伙伴算法的思想是：**对于申请的内存大小 k，找到块大小 >= k 的链表，如果该链表恰有一个块能够分配，就直接分配；如果该链表没有空闲块了，则往后继续寻找，直到找到一个空闲块。假如这个空闲块的大小超过 k，则把 k 的部分分配出去，剩下的部分按照 $2^n$ 分解，插到前面的链表中去**。

以分配一个 512 KB 的内存为例：

1. 首先找到下标为 7 的链表，因为它的块大小恰为 512 KB。
2. 找到链表以后，在该链表中搜索一个空闲块，如果存在一块，则直接将这块分配出去，算法结束。
3. 如果不存在，则在下标为 8 的链表中搜索，找到一块空闲块，如果还未找到，则重复此步骤，直到找到一块空闲块；否则返回错误。
4. 如果在更高级别的链表中找到了块，比如找到了 2048 KB 的块，则分配 512 KB 出去以后，还剩下 1536 KB，这时将它拆分为 1024 KB + 512 KB 的两块，分别插入到下标为 7 和下标为 8 的链表中，算法结束。

从这里我们可以看出，虽然用了部分额外空间来维护一个链表数组，但是内存的利用率和分配效率都是很不错的。

那么伙伴算法的名字从何而来呢？实际上是在回收空间的时候，该算法会把“伙伴”递归的合并到一起。伙伴的需要满足以下两个性质：

1. 两个块的大小相同。
2. 两个块的地址连续。

注意，合并时是递归的合并，也就是说如果两个块合并为一个大的块，大的块和其他大的块还有可能合并为一个更大的块。

### 5.2 虚拟内存分配

在 Java 等程序中，内存是由 JVM 去申请的，而 C/C++ 作为内存的皇帝，它可以自己主动申请内存，其主要就是依靠 `malloc` 库函数。

`malloc` 申请内存的时候，会有两种方式向操作系统申请堆内存。

- 方式一：通过 `brk()` 系统调用从堆分配内存。

  这种方式其实很简单，`brk()` 系统调用就是将堆顶地址往上移动：

  ![image-20220706001317773](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220706001317773.png)

- 方式二：通过 `mmap()` 系统调用在文件映射区域分配内存；

  `mmap()` 我们应该很了解，它可以用于共享内存，它的实现方式就是在文件映射区域分配内存，如下图所示：

  ![image-20220706001414963](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220706001414963.png)

`malloc()` 源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 `brk()` 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 `mmap()` 申请内存；

这个阈值取决于 C 库函数的具体实现。

`malloc()` 在分配内存的时候，并不是老老实实按用户预期申请的字节数来分配内存空间大小，而是**会预分配更大的空间作为内存池**，以防接下来用户再申请内存时还需要再次进行系统调用，提高性能。

### 5.3 虚拟内存回收

与 `malloc()` 对应的是 `free()`，它用于回收虚拟内存。

通过 `free()` 释放内存后，**堆内存并没有归还给操作系统，这是因为进程还没有结束，不如先重新放进 `malloc()` 的内存池里，当进程再次申请内存时就可以直接复用**，这样速度快了很多。

当然，当进程退出后，操作系统就会回收进程的所有资源。

上述内容只对 `brk()` 方式有效，如果**使用 `mmap()`，则直接归还给操作系统了**。

### 5.4 物理内存回收策略

如果没有空闲的物理内存，那么内核就会开始进行**回收内存**的工作，回收的方式主要是两种：**直接内存回收**和**后台内存回收**。

- **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
- **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会触发一个 OOM Killer 机制，它会根据算法**选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源**，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。

#### 5.4.1 后台内存回收何时开始？

内核定义了三个内存阈值（watermark，也称为水位），用来衡量当前剩余内存（pages_free）是否充裕或者紧张，分别是：

- 页最小阈值（pages_min）；
- 页低阈值（pages_low）；
- 页高阈值（pages_high）；

![image-20220706002336984](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220706002336984.png)

kswapd 会定期扫描内存的使用情况，根据剩余内存（pages_free）的情况来进行内存回收的工作。

- 图中绿色部分：如果剩余内存（pages_free）大于页高阈值（pages_high），说明剩余内存是充足的；
- 图中蓝色部分：如果剩余内存（pages_free）在页高阈值（pages_high）和页低阈值（pages_low）之间，说明内存有一定压力，但还可以满足应用程序申请内存的请求；
- 图中橙色部分：如果剩余内存（pages_free）在页低阈值（pages_low）和页最小阈值（pages_min）之间，说明内存压力比较大，剩余内存不多了。**这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值（pages_high）为止**。虽然会触发内存回收，但是不会阻塞应用程序，因为两者关系是异步的。
- 图中红色部分：如果剩余内存（pages_free）小于页最小阈值（pages_min），说明用户可用内存都耗尽了，此时就会**触发直接内存回收**，这时应用程序就会被阻塞，因为两者关系是同步的。

## 6. 段页式内存管理

内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为**段页式内存管理**。

段页式内存管理实现的方式如下：

- 将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制
- 接着再**把每个段都划分为多个页**，也就是对分段划分出来的连续空间，再划分固定大小的页

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。

用于段页式内存管理的数据结构是**每一个程序一张段表，每个段又建立一张页表**，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：

![image-20220322160310735](https://cdn.jsdelivr.net/gh/Faraway002/typora/images/image-20220322160310735.png)

