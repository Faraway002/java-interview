# Redis 分布式锁

## 什么是分布式锁？为什么需要分布式锁？

与分布式锁相对应的是单机锁，我们在写多线程程序时，避免同时操作一个共享变量产生数据问题，通常会使用一把锁来进行互斥，以保证共享变量的正确性，其使用范围是在同一个进程/线程中。

如果换做是**多个进程，需要同时操作一个共享资源，如何互斥呢**？

例如，现在的业务应用通常都是微服务架构，这也意味着一个应用会部署多个进程，那这多个进程如果需要修改 MySQL 中的同一行记录时，为了避免操作乱序导致数据错误，此时，我们就需要引入分布式锁来解决这个问题了：

![image-20220512181521199](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220512181521199.png)

**想要实现分布式锁，必须借助一个外部系统，所有进程都去这个系统上申请加锁；而这个外部系统，必须要实现互斥的能力**，即两个请求同时进来，只会给一个进程返回成功，另一个返回失败（或等待）。

这个外部系统，可以是 MySQL，也可以是 Redis 或 Zookeeper。但为了追求更好的性能，我们通常会选择使用 Redis 或 Zookeeper 来做。

## 分布式锁怎么实现？

想要实现分布式锁，必须要求 Redis 有互斥的能力，我们**可以使用 `SETNX` 命令**，这个命令表示 `SET if not exists`，即**如果 key 不存在，才会设置它的值，否则什么也不做**。

两个客户端进程可以执行这个命令，达到互斥，就可以实现一个分布式锁。

客户端 1 申请加锁，加锁成功：

```bash
127.0.0.1:6379> SETNX lock 1
(integer) 1     # 客户端1，加锁成功
```

客户端 2 申请加锁，因为它后到达，加锁失败：

```bash
127.0.0.1:6379> SETNX lock 1
(integer) 0     # 客户端2，加锁失败
```

此时，加锁成功的客户端，就可以去操作共享资源，例如修改 MySQL 的某一行数据，或者调用一个 API 请求。

操作完成后，还要及时释放锁，给后来者让出操作共享资源的机会。释放锁也很简单，**直接使用 `DEL` 命令删除这个 key 即可**：

```bash
127.0.0.1:6379> DEL lock # 释放锁
(integer) 1
```

这个逻辑非常简单，整体的流程就是这样：

![image-20220512181831843](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220512181831843.png)

但是，这种方式存在死锁风险：

1. 拿到锁的进程处理业务逻辑异常，没及时释放锁
2. 进程因异常而退出，没机会释放锁

这时，这个客户端就会一直占用这个锁，而其它客户端就永远拿不到这把锁了。

## 如何避免死锁？

我们很容易想到的方案是，在申请锁时，给这把锁设置一个过期时间。

这里我们假设，操作共享资源的时间不会超过 10s，那么在加锁时，给这个 key 设置 10s 过期即可：

```bash
127.0.0.1:6379> SETNX lock 1    # 加锁
(integer) 1
127.0.0.1:6379> EXPIRE lock 10  # 10s 后自动过期
(integer) 1
```

这样一来，无论客户端是否异常，这个锁都可以在 10s 后被自动释放，其它客户端依旧可以拿到锁。

但这样真的没问题吗？还是有问题：现在的操作，加锁、设置过期是 2 条命令，有没有可能只执行了第一条，第二条却来不及执行的情况发生呢？例如：

1. SETNX 执行成功，执行 EXPIRE 时由于网络问题，执行失败
2. SETNX 执行成功，Redis 异常宕机，EXPIRE 没有机会执行
3. SETNX 执行成功，客户端异常崩溃，EXPIRE 也没有机会执行

总之，**只要这两条命令不能保证是原子操作（一起成功），就有潜在的风险导致过期时间设置失败**，依旧发生死锁问题。

在 Redis 2.6.12 之后，Redis 扩展了 SET 命令的参数，用这一条命令就可以了：

```bash
# 一条命令保证原子性执行
127.0.0.1:6379> SET lock 1 EX 10 NX
OK
```

这样就解决了死锁问题，也比较简单。

事实上，它还有一些问题，看下面的场景：

1. 客户端 1 加锁成功，开始操作共享资源；但是客户端 1 操作共享资源的时间超过了锁的过期时间，锁被自动释放
2. 客户端 2 加锁成功，开始操作共享资源；客户端 1 操作共享资源完成，释放锁（但释放的是客户端 2 的锁）

看到了么，这里存在两个严重的问题：

1. **锁过期**：客户端 1 操作共享资源耗时太久，导致锁被自动释放，之后被客户端 2 持有

   这种情况大多是对操作共享资源的时长估计错误，导致过期时间设置的太短了，解决这个问题只需要增大过期时间即可。但是这种方法**不能彻底解决这个问题**，原因在于，客户端在拿到锁之后，在操作共享资源时，遇到的场景有可能是很复杂的，例如，程序内部发生异常、网络请求超时等等。

   既然是预估时间，也只能是**大致估计**，除非你能预料并覆盖到所有导致耗时变长的场景，但这其实很难。

2. **释放别人的锁**：客户端 1 操作共享资源完成后，却又释放了客户端 2 的锁.

   这个错误的原因在于，每个客户端在释放锁时，并**没有检查这把锁是否还归自己持有**，所以就会发生释放别人锁的风险，这样的解锁流程很不严谨。

对于第一个问题，我们稍后再介绍解决办法，因为比较复杂。

### 锁被其他进程释放怎么办？

解决办法是：客户端在加锁时，设置一个只有自己知道的唯一标识进去。

例如，可以是自己的线程 ID，也可以是一个 UUID（随机且唯一），这里我们以 UUID 举例：

```bash
# 锁的 VALUE 设置为 UUID
127.0.0.1:6379> SET lock $uuid EX 20 NX
OK
```

之后，在释放锁时，要先判断这把锁是否还归自己持有，伪代码可以这么写：

```java
// 锁是自己的，才释放
if (redis.get("lock") == uuid)
    redis.del("lock")
```

这里释放锁使用的是 GET + DEL 两条命令，这时，又会遇到我们前面讲的原子性问题了。除了上面 SET 的额外参数之外，还能用什么方式原子执行呢？答案是**使用 Lua 脚本**，我们可以把这个逻辑，写成 Lua 脚本，让 Redis 来执行。因为 Redis 处理每一个请求是单线程执行的，**在执行一个 Lua 脚本时，其它请求必须等待，直到这个 Lua 脚本处理完成**，这样一来，GET + DEL 之间就不会插入其它命令了。

<img src="https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220512204913671.png" alt="image-20220512204913671" style="zoom:67%;" />

安全释放锁的 Lua 脚本如下：

```lua
// 判断锁是自己的，才释放
if redis.call("GET", KEYS[1]) == ARGV[1]
then
    return redis.call("DEL", KEYS[1])
else
    return 0
end
```

### 锁过期时间不好评估怎么办？

前面我们提到，锁的过期时间如果评估不好，这个锁就会有提前过期的风险。

我们其实可以设计这样的方案：加锁时，**先设置一个过期时间，然后我们启一个守护线程，定时去检测这个锁的失效时间，如果锁快要过期了，操作共享资源还未完成，那么就自动对锁进行续期，重新设置过期时间**。

如果你是 Java 技术栈，幸运的是，已经有一个库把这些工作都封装好了：Redisson。

Redisson 是一个 Java 语言实现的 Redis SDK 客户端，在使用分布式锁时，它就采用了自动续期的方案来避免锁过期，这个守护线程我们一般也把它叫做**看门狗线程**。

<img src="https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220512205448435.png" alt="image-20220512205448435" style="zoom: 67%;" />

除此之外，这个 SDK 还封装了很多易用的功能：

- 可重入锁
- 乐观锁
- 公平锁
- 读写锁
- Redlock（红锁，下面会详细讲）

这个 SDK 提供的 API 非常友好，它可以像操作本地锁的方式，操作分布式锁。如果你是 Java 技术栈，可以直接把它用起来。

## 主从发生切换时，这个分布式锁依旧安全吗？

上面我们提到实现一个分布式锁的比较完整的方案，但是通常情况下，一般会采用**主从集群 + 哨兵**的模式部署，这样做的好处在于，当主库异常宕机时，哨兵可以实现故障自动切换，把从库提升为主库，继续提供服务，以此保证可用性。

试想这样的场景：

1. 客户端 1 在主库上执行 SET 命令，加锁成功
2. 此时，主库异常宕机，SET 命令还未同步到从库上（主从复制是异步的）
3. 从库被哨兵提升为新主库，这个锁在新的主库上就这样丢失了

<img src="https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220512205944579.png" alt="image-20220512205944579" style="zoom: 80%;" />

当引入 Redis 副本后，分布式锁还是可能会受到影响，为此，Redis 的作者提出一种解决方案，就是我们经常听到的 **Redlock（红锁）**。

### Redlock

Redlock 的方案基于 2 个前提：

1. 不再需要部署从库和哨兵实例，**只部署主库**
2. 但**主库要部署多个**，官方推荐至少 5 个实例

也就是说，想用使用 Redlock，你至少要部署 5 个 Redis 实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例。

注意，Redlock 并不是要求部署 Redis Cluster，只是 5 个简单的 Redis 实例。

整体的流程是这样的，一共分为 5 步：

1. 客户端先获取**当前时间戳 T1**
2. 客户端**依次向这 5 个 Redis 实例发起加锁请求**（用前面讲到的 SET 命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁
3. **如果客户端从 >= 3 个（大多数）以上 Redis 实例加锁成功，则再次获取当前时间戳 T2，如果 T2 - T1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败**
4. 加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）
5. 加锁失败，向全部节点发起释放锁请求（前面讲到的 Lua 脚本释放锁）

接下来我们详细介绍一下为什么 Redlock 这样做，且这样做为什么能够有效。

1. **为什么要在多个实例上加锁？**

   本质上是为了**容错**，部分实例异常宕机，剩余的实例加锁成功，整个锁服务依旧可用。

2. **为什么大多数加锁成功，才算成功？**

   多个 Redis 实例一起来用，其实就组成了一个分布式系统。

   在分布式系统中，总会出现异常节点，所以，在**谈论分布式系统问题时，需要考虑异常节点达到多少个，也依旧不会影响整个系统的正确性**。

   这是一个分布式系统容错问题，这个问题的结论是：**如果只存在故障节点，只要大多数节点正常，那么整个系统依旧是可以提供正确服务的**。

   > 这个问题的模型，就是我们经常听到的拜占庭将军问题，感兴趣可以去看算法的推演过程。

3. **为什么步骤 3 加锁成功后，还要计算加锁的累计耗时？**

   因为操作的是多个节点，所以耗时肯定会比操作单个实例耗时更久，而且，因为是网络请求，网络情况是复杂的，有可能存在延迟、丢包、超时等情况发生，网络请求越多，异常发生的概率就越大。

   所以，即使大多数节点加锁成功，但**如果加锁的累计耗时已经超过了锁的过期时间，那此时有些实例上的锁可能已经失效了，这个锁就没有意义了**。

4.  **为什么释放锁，要操作所有节点？**

   在某一个 Redis 节点加锁时，可能因为网络原因导致加锁失败。

   例如，客户端在一个 Redis 实例上加锁成功，但在读取响应结果时，网络问题导致**读取失败**，那这把锁其实已经在 Redis 上加锁成功了。

   所以，释放锁时，不管之前有没有加锁成功，需要释放所有节点的锁，以保证清理节点上残留的锁。

## Zookeeper 分布式锁

Zookeeper 的分布式锁原理如下：

1. 客户端 1 和 2 都尝试创建临时节点，例如 /lock
2. 假设客户端 1 先到达，则加锁成功，客户端 2 加锁失败
3. 客户端 1 操作共享资源
4. 客户端 1 删除 /lock 节点，释放锁

Zookeeper 不像 Redis 那样，需要考虑锁的过期时间问题，它是采用了临时节点，保证客户端 1 拿到锁后，只要连接不断，就可以一直持有锁。而且，如果客户端 1 异常崩溃了，那么这个临时节点会自动删除，保证了锁一定会被释放。

**没有锁过期的烦恼，还能在异常时自动释放锁，是不是觉得很完美？**其实不然。

客户端 1 创建临时节点后，Zookeeper 是如何保证让这个客户端一直持有锁呢？

原理是：客户端 1 此时会与 Zookeeper 服务器维护一个 Session，这个 Session 会依赖客户端**定时心跳**来维持连接，**如果 Zookeeper 长时间收不到客户端的心跳，就认为这个 Session 过期了，也会把这个临时节点删除**。

![image-20220512223648009](https://fastly.jsdelivr.net/gh/Faraway002/typora/images/image-20220512223648009.png)

我们可以得到一个结论：**一个分布式锁，在极端情况下，不一定是安全的。**

Zookeeper 的优点：

1. 不需要考虑锁的过期时间
2. watch 机制，加锁失败，可以 watch 等待锁释放，实现乐观锁

但它的劣势是：

1. 性能不如 Redis
2. 部署和运维成本高
3. 客户端与 Zookeeper 的长时间失联，锁被释放问题